
Returned ESE function. Lanczos order (m) is 36 .










Epoch: 1, Loss: 1.1076:   3%|â–ˆâ–ˆâ–Ž                                                                                | 57/1999 [00:19<09:32,  3.39it/s]
lambda_max: 22.381547927856445 lrs: tensor([0.1346, 0.1255, 0.1194, 0.1137, 0.1101, 0.0855, 0.0705, 0.0599, 0.0447]) eigenvals: tensor([ 7.4268,  7.9663,  8.3738,  8.7939,  9.0813, 11.6980, 14.1847, 16.7043,











Epoch: 1, Loss: 0.6799:   6%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                             | 115/1999 [01:24<11:28,  2.74it/s]
lambda_max: 114.833984375 lrs: tensor([0.0550, 0.0544, 0.0478, 0.0448, 0.0261, 0.0226, 0.0197, 0.0158, 0.0087]) eigenvals: tensor([ 18.1952,  18.3846,  20.9305,  22.2998,  38.2949,  44.2600,  50.7161,










Epoch: 1, Loss: 1.2948:   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                           | 173/1999 [02:22<09:50,  3.09it/s]
lambda_max: 36.465362548828125 lrs: tensor([0.1979, 0.1845, 0.1790, 0.1634, 0.1611, 0.1513, 0.1313, 0.1099, 0.0274]) eigenvals: tensor([ 5.0522,  5.4210,  5.5852,  6.1207,  6.2072,  6.6081,  7.6144,  9.0979,













Epoch: 1, Loss: 0.4437:  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                        | 231/1999 [03:33<12:53,  2.29it/s]
lambda_max: 29.7280216217041 lrs: tensor([0.1836, 0.1688, 0.1589, 0.1524, 0.1331, 0.1309, 0.0852, 0.0611, 0.0336]) eigenvals: tensor([ 5.4470,  5.9252,  6.2937,  6.5603,  7.5131,  7.6369, 11.7354, 16.3636,













Epoch: 1, Loss: 0.2392:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                      | 289/1999 [04:38<11:28,  2.48it/s]
lambda_max: 30.200069427490234 lrs: tensor([0.2105, 0.1899, 0.1851, 0.1776, 0.1725, 0.1633, 0.1428, 0.1337, 0.0331]) eigenvals: tensor([ 4.7498,  5.2648,  5.4026,  5.6308,  5.7982,  6.1250,  7.0010,  7.4776,













Epoch: 1, Loss: 1.0507:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                   | 347/1999 [05:44<11:44,  2.35it/s]
lambda_max: 30.850360870361328 lrs: tensor([0.2233, 0.2081, 0.1941, 0.1820, 0.1778, 0.1758, 0.1724, 0.1483, 0.0324]) eigenvals: tensor([ 4.4792,  4.8062,  5.1524,  5.4932,  5.6247,  5.6876,  5.7996,  6.7428,













Epoch: 1, Loss: 0.8962:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                 | 405/1999 [06:52<11:04,  2.40it/s]
lambda_max: 29.439929962158203 lrs: tensor([0.2591, 0.2445, 0.2109, 0.1972, 0.1946, 0.1854, 0.1788, 0.1766, 0.0340]) eigenvals: tensor([ 3.8601,  4.0897,  4.7419,  5.0705,  5.1376,  5.3930,  5.5926,  5.6611,












Epoch: 1, Loss: 1.2139:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                               | 463/1999 [07:58<10:48,  2.37it/s]
lambda_max: 28.36331558227539 lrs: tensor([0.2381, 0.2199, 0.2078, 0.1959, 0.1915, 0.1645, 0.1626, 0.1365, 0.0353]) eigenvals: tensor([ 4.1994,  4.5470,  4.8118,  5.1037,  5.2232,  6.0784,  6.1484,  7.3254,








Epoch: 1, Loss: 0.3827:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                             | 498/1999 [08:59<10:40,  2.35it/s]
An exception occurred:
'Tensor' object has no attribute 'astype'
Returning None...
Epoch: 1, Loss: 0.3528:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                             | 499/1999 [09:00<27:05,  1.08s/it]
[33m[W 2024-05-08 08:41:10,235][39m Trial 0 failed with parameters: {'learning_rate': 5.663727595698064e-05, 'k_approx': 9, 'num_of_fosi_iterations': 58} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-08 08:41:10,236][39m Trial 0 failed with value None.




Epoch: 1, Loss: 0.3922:   1%|â–ˆ                                                                                  | 25/1999 [00:09<12:31,  2.63it/s]
[33m[W 2024-05-08 08:41:19,933][39m Trial 1 failed with parameters: {'learning_rate': 2.9204273139286986e-05, 'k_approx': 8, 'num_of_fosi_iterations': 122} because of the following error: KeyboardInterrupt().
Traceback (most recent call last):
  File "/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/optuna/study/_optimize.py", line 196, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/home/pavlospoulos/nlp-optimizers/beta-4-fosi-adam/optimize.py", line 96, in objective
    result = trainer.fine_tune(trial=trial, optuna=optuna)  # Return the metric you want to optimize
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pavlospoulos/nlp-optimizers/beta-4-fosi-adam/trainer.py", line 160, in fine_tune
    self.params, self.opt_state, loss, logits = self.step(self.params, self.buffers, batch, self.opt_state)
                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pavlospoulos/nlp-optimizers/beta-4-fosi-adam/trainer.py", line 258, in step
    updates, opt_state = self.optimizer.update(grads, opt_state, params)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pavlospoulos/nlp-optimizers/beta-4-fosi-adam/fosi/torch_optim/fosi_optimizer.py", line 100, in update_fn
    base_opt_deltas = _orthogonalize_vector_wrt_eigenvectors(base_opt_deltas, state.k_eigenvecs)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pavlospoulos/nlp-optimizers/beta-4-fosi-adam/fosi/torch_optim/fosi_optimizer.py", line 54, in _orthogonalize_vector_wrt_eigenvectors
    v = v - torch.matmul(torch.matmul(k_eigenvecs, v), k_eigenvecs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
[33m[W 2024-05-08 08:41:19,935][39m Trial 1 failed with value None.
Traceback (most recent call last):
  File "/home/pavlospoulos/nlp-optimizers/beta-4-fosi-adam/optimize.py", line 122, in <module>
    study.optimize(objective, n_trials=30)  # Adjust n_trials as needed
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/optuna/study/study.py", line 451, in optimize
    _optimize(
  File "/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/optuna/study/_optimize.py", line 62, in _optimize
    _optimize_sequential(
  File "/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/optuna/study/_optimize.py", line 159, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/optuna/study/_optimize.py", line 247, in _run_trial
    raise func_err
  File "/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/optuna/study/_optimize.py", line 196, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/home/pavlospoulos/nlp-optimizers/beta-4-fosi-adam/optimize.py", line 96, in objective
    result = trainer.fine_tune(trial=trial, optuna=optuna)  # Return the metric you want to optimize
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pavlospoulos/nlp-optimizers/beta-4-fosi-adam/trainer.py", line 160, in fine_tune
    self.params, self.opt_state, loss, logits = self.step(self.params, self.buffers, batch, self.opt_state)
                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pavlospoulos/nlp-optimizers/beta-4-fosi-adam/trainer.py", line 258, in step
    updates, opt_state = self.optimizer.update(grads, opt_state, params)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pavlospoulos/nlp-optimizers/beta-4-fosi-adam/fosi/torch_optim/fosi_optimizer.py", line 100, in update_fn
    base_opt_deltas = _orthogonalize_vector_wrt_eigenvectors(base_opt_deltas, state.k_eigenvecs)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/pavlospoulos/nlp-optimizers/beta-4-fosi-adam/fosi/torch_optim/fosi_optimizer.py", line 54, in _orthogonalize_vector_wrt_eigenvectors
    v = v - torch.matmul(torch.matmul(k_eigenvecs, v), k_eigenvecs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt