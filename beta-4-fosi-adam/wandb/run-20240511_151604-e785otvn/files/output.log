
Returned ESE function. Lanczos order (m) is 40 .



























Epoch: 1, Loss: 0.5758:  12%|â–ˆâ–‰              | 147/1209 [00:55<06:50,  2.59it/s]
lambda_max: 5.482504844665527 lrs: tensor([0.3527, 0.3186, 0.3012, 0.2921, 0.2761, 0.2684, 0.2588, 0.2266, 0.2227,
        0.1824]) eigenvals: tensor([2.8355, 3.1385, 3.3201, 3.4234, 3.6225, 3.7256, 3.8638, 4.4124, 4.4908,





























Epoch: 1, Loss: 0.4267:  24%|â–ˆâ–ˆâ–ˆâ–‰            | 295/1209 [02:49<05:27,  2.79it/s]
lambda_max: 4.397280693054199 lrs: tensor([0.3812, 0.3515, 0.3209, 0.3191, 0.2867, 0.2765, 0.2713, 0.2613, 0.2294,
        0.2274]) eigenvals: tensor([2.6230, 2.8449, 3.1158, 3.1335, 3.4875, 3.6160, 3.6865, 3.8269, 4.3585,






























Epoch: 1, Loss: 0.5963:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 443/1209 [04:41<05:06,  2.50it/s]
lambda_max: 6.093392372131348 lrs: tensor([0.3716, 0.3551, 0.3135, 0.2899, 0.2810, 0.2735, 0.2641, 0.2358, 0.2094,
        0.1641]) eigenvals: tensor([2.6910, 2.8163, 3.1895, 3.4492, 3.5587, 3.6563, 3.7860, 4.2414, 4.7744,












Epoch: 1, Loss: 0.5448:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 499/1209 [05:57<04:38,  2.55it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(


[38mic| total_loss: 76.47258216142654[39malidation Loss: 0.3992:  99%|â–‰| 120/121 [00:03<
An exception occurred:
Returning None...
Returned ESE function. Lanczos order (m) is 8 .
[38mic| metrics: {'ACCURACY': 0.6728778467908902,
[38m              'F1_Macro': 0.8044554455445545,
[38m              'LOSS': 0.632004811251459,
[38m              'MAE': 0.32712215320910976,
[38m              'MCC': 0.0,
[38m              'PRECISION': 0.6728778467908902,
[38m              'RECALL': 1.0}
Epoch: 1, Loss: 0.5448:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 499/1209 [06:08<08:43,  1.36it/s]
[33m[W 2024-05-11 15:22:15,647][39m Trial 34 failed with parameters: {'learning_rate': 6.492749173107246e-05, 'k_approx': 10, 'num_of_fosi_iterations': 148} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-11 15:22:15,647][39m Trial 34 failed with value None.



















Epoch: 1, Loss: 0.5946:  11%|â–ˆâ–‹              | 129/1209 [00:38<05:36,  3.21it/s]





















Epoch: 1, Loss: 0.8828:  21%|â–ˆâ–ˆâ–ˆâ–            | 259/1209 [01:28<05:22,  2.94it/s]

Epoch: 1, Loss: 0.1023:  22%|â–ˆâ–ˆâ–ˆâ–            | 263/1209 [01:36<15:58,  1.01s/it][34m[1mwandb[39m[22m: [33mWARNING[39m Step only supports monotonically increasing values, use define_metric to set a custom x axis. For details see: https://wandb.me/define-metric
[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0995202362537384, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715441021.4756634}).


















Epoch: 1, Loss: 0.6232:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 389/1209 [02:14<04:03,  3.36it/s]


















Epoch: 1, Loss: 0.7600:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 499/1209 [02:54<03:34,  3.31it/s]


[38mic| total_loss: 100.18935395777225[39mlidation Loss: 1.5633:  99%|â–‰| 120/121 [00:03<
An exception occurred:
Returning None...
Returned ESE function. Lanczos order (m) is 40 .
[38mic| metrics: {'ACCURACY': 0.6024844720496895,
[38m              'F1_Macro': 0.7055214723926381,
[38m              'LOSS': 0.828011189733655,
[38m              'MAE': 0.39751552795031053,
[38m              'MCC': 0.0940783933448601,
[38m              'PRECISION': 0.7033639143730887,
[38m              'RECALL': 0.7076923076923077}
Epoch: 1, Loss: 0.7600:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 499/1209 [03:05<04:23,  2.69it/s]
[33m[W 2024-05-11 15:25:21,101][39m Trial 35 failed with parameters: {'learning_rate': 3.648093758270467e-05, 'k_approx': 2, 'num_of_fosi_iterations': 130} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-11 15:25:21,102][39m Trial 35 failed with value None.




























Epoch: 1, Loss: 0.0519:  12%|â–ˆâ–Š              | 140/1209 [00:56<07:19,  2.43it/s]
lambda_max: 31.52640724182129 lrs: tensor([0.3833, 0.3774, 0.3716, 0.3474, 0.1708, 0.1243, 0.0887, 0.0756, 0.0464,
        0.0317]) eigenvals: tensor([ 2.6090,  2.6496,  2.6909,  2.8784,  5.8541,  8.0429, 11.2707, 13.2330,



























Epoch: 1, Loss: 0.2574:  23%|â–ˆâ–ˆâ–ˆâ–‹            | 275/1209 [02:45<05:58,  2.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0772053524851799, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715441277.389563}).

Epoch: 1, Loss: 0.2578:  23%|â–ˆâ–ˆâ–ˆâ–‹            | 281/1209 [02:48<05:58,  2.59it/s]
lambda_max: 148.87533569335938 lrs: tensor([0.0533, 0.0400, 0.0380, 0.0338, 0.0328, 0.0281, 0.0257, 0.0204, 0.0162,
        0.0067]) eigenvals: tensor([ 18.7457,  24.9722,  26.3210,  29.5761,  30.4609,  35.5336,  38.9364,





























Epoch: 1, Loss: 0.4476:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 422/1209 [04:34<05:01,  2.61it/s]
lambda_max: 137.20399475097656 lrs: tensor([0.0899, 0.0866, 0.0845, 0.0693, 0.0566, 0.0472, 0.0450, 0.0243, 0.0134,
        0.0073]) eigenvals: tensor([ 11.1243,  11.5490,  11.8363,  14.4222,  17.6556,  21.2007,  22.2045,
















Epoch: 1, Loss: 0.1876:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 499/1209 [05:53<04:32,  2.61it/s]


[38mic| total_loss: 105.14662745594978[39mlidation Loss: 0.4780:  99%|â–‰| 120/121 [00:03<00:00, 33.88it/s
An exception occurred:
Returning None...
Returned ESE function. Lanczos order (m) is 56 .
[38mic| metrics: {'ACCURACY': 0.6335403726708074,
[38m              'F1_Macro': 0.7230046948356808,
[38m              'LOSS': 0.8689803921979321,
[38m              'MAE': 0.36645962732919257,
[38m              'MCC': 0.18242963282023197,
[38m              'PRECISION': 0.7356687898089171,
[38m              'RECALL': 0.7107692307692308}
Epoch: 1, Loss: 0.1876:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 499/1209 [06:04<08:39,  1.37it/s]
[33m[W 2024-05-11 15:31:26,174][39m Trial 36 failed with parameters: {'learning_rate': 7.133181709891912e-06, 'k_approx': 10, 'num_of_fosi_iterations': 141} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-11 15:31:26,174][39m Trial 36 failed with value None.









































Epoch: 1, Loss: 0.1625:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 175/1209 [01:22<08:12,  2.10it/s]
lambda_max: 218.71908569335938 lrs: tensor([0.1211, 0.1175, 0.1115, 0.0966, 0.0861, 0.0837, 0.0813, 0.0666, 0.0650,
        0.0568, 0.0524, 0.0443, 0.0336, 0.0046]) eigenvals: tensor([  8.2568,   8.5096,   8.9660,  10.3504,  11.6179,  11.9489,  12.3026,




















Epoch: 1, Loss: 0.1613:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 250/1209 [03:25<25:58,  1.63s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.16129598021507263, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715441691.8390455}).
























Epoch: 1, Loss: 1.0966:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 351/1209 [04:15<06:59,  2.04it/s]
lambda_max: 33.9212646484375 lrs: tensor([0.1971, 0.1868, 0.1680, 0.1623, 0.1601, 0.1535, 0.1424, 0.1284, 0.1169,
        0.1154, 0.0791, 0.0559, 0.0513, 0.0295]) eigenvals: tensor([ 5.0726,  5.3526,  5.9532,  6.1600,  6.2452,  6.5151,  7.0208,  7.7893,


































Epoch: 1, Loss: 0.0515:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [06:46<04:44,  2.50it/s]

[38mic| total_loss: 138.28103246353567[39mlidation Loss: 2.0502:  99%|â–‰| 120/121 [00:03<00:00, 33.79it/s
[38mic| metrics: {'ACCURACY': 0.5797101449275363,
[38m              'F1_Macro': 0.6599664991624791,
[38m              'LOSS': 1.142818450111865,
[38m              'MAE': 0.42028985507246375,
[38m              'MCC': 0.1243575634718508,
[38m              'PRECISION': 0.7242647058823529,
[38m              'RECALL': 0.6061538461538462}
Epoch: 1, Loss: 0.0515:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [06:57<09:53,  1.20it/s]
[33m[W 2024-05-11 15:38:23,706][39m Trial 37 failed with parameters: {'learning_rate': 4.4061160991331943e-05, 'k_approx': 14, 'num_of_fosi_iterations': 176} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-11 15:38:23,707][39m Trial 37 failed with value None.
Epoch: 1, Loss: 0.4352:   0%|                                  | 1/1209 [00:00<06:06,  3.30it/s]
An exception occurred:
Returning None...




















Epoch: 1, Loss: 0.0872:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 134/1209 [00:39<05:08,  3.49it/s]





















Epoch: 1, Loss: 0.7351:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 269/1209 [01:35<04:13,  3.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5248022675514221, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.6666666666666666, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715441994.167869}).
Epoch: 1, Loss: 0.6022:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 272/1209 [01:50<37:34,  2.41s/it]




















Epoch: 1, Loss: 0.4914:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 404/1209 [02:29<04:01,  3.33it/s]












Epoch: 1, Loss: 1.0207:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [03:10<03:11,  3.70it/s]


[38mic| total_loss: 87.82471776008606[39malidation Loss: 0.4480:  99%|â–‰| 120/121 [00:03<00:00, 32.41it/s
[38mic| metrics: {'ACCURACY': 0.6045548654244306,
[38m              'F1_Macro': 0.7372764786795049,
[38m              'LOSS': 0.7258241137197196,
[38m              'MAE': 0.39544513457556935,
[38m              'MCC': -0.0294931763654906,
[38m              'PRECISION': 0.6666666666666666,
[38m              'RECALL': 0.8246153846153846}
Epoch: 1, Loss: 1.0207:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [03:22<04:47,  2.47it/s]
[33m[W 2024-05-11 15:41:46,021][39m Trial 38 failed with parameters: {'learning_rate': 4.553579453832035e-05, 'k_approx': 4, 'num_of_fosi_iterations': 135} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-11 15:41:46,021][39m Trial 38 failed with value None.
Epoch: 1, Loss: 0.6616:   0%|                                  | 1/1209 [00:00<06:07,  3.29it/s]
An exception occurred:
Returning None...




























Epoch: 1, Loss: 0.7668:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 182/1209 [00:55<05:04,  3.38it/s]
















Epoch: 1, Loss: 0.8948:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 276/1209 [01:35<04:32,  3.42it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.4017910361289978, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715442194.4328063}).












Epoch: 1, Loss: 0.2119:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 365/1209 [02:02<04:09,  3.38it/s]




















Epoch: 1, Loss: 0.3503:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [02:51<03:23,  3.49it/s]


[38mic| total_loss: 78.48190227150917[39malidation Loss: 0.7351:  99%|â–‰| 120/121 [00:03<00:00, 32.88it/s
An exception occurred:
Returning None...
Returned ESE function. Lanczos order (m) is 40 .
[38mic| metrics: {'ACCURACY': 0.660455486542443,
[38m              'F1_Macro': 0.7859007832898173,
[38m              'LOSS': 0.6486107625744559,
[38m              'MAE': 0.33954451345755693,
[38m              'MCC': 0.066731549082672,
[38m              'PRECISION': 0.6825396825396826,
[38m              'RECALL': 0.9261538461538461}
Epoch: 1, Loss: 0.3503:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [03:03<04:20,  2.73it/s]
[33m[W 2024-05-11 15:44:49,149][39m Trial 39 failed with parameters: {'learning_rate': 7.855441719937628e-05, 'k_approx': 3, 'num_of_fosi_iterations': 183} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-11 15:44:49,149][39m Trial 39 failed with value None.





























Epoch: 1, Loss: 0.6101:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 142/1209 [00:58<08:04,  2.20it/s]
lambda_max: 7770.29345703125 lrs: tensor([0.1197, 0.0896, 0.0756, 0.0676, 0.0105, 0.0020, 0.0004, 0.0003, 0.0003,
        0.0001]) eigenvals: tensor([   8.3552,   11.1572,   13.2193,   14.7901,   95.1195,  502.8305,






















Epoch: 1, Loss: 0.6486:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [02:37<06:21,  2.52it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(



Epoch: 1, Loss: 0.8690:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 265/1209 [02:47<06:41,  2.35it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5340813994407654, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715442450.7983527}).



Epoch: 1, Loss: 0.8348:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 285/1209 [02:55<06:09,  2.50it/s]
lambda_max: 45.7783317565918 lrs: tensor([0.2427, 0.2218, 0.2100, 0.2054, 0.1992, 0.1837, 0.1784, 0.1580, 0.0914,
        0.0218]) eigenvals: tensor([ 4.1202,  4.5088,  4.7619,  4.8693,  5.0199,  5.4441,  5.6060,  6.3273,






























Epoch: 1, Loss: 0.5022:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 428/1209 [04:44<05:08,  2.53it/s]
lambda_max: 40.388118743896484 lrs: tensor([0.2918, 0.2617, 0.2413, 0.2391, 0.2282, 0.2215, 0.1913, 0.1796, 0.1304,
        0.0248]) eigenvals: tensor([ 3.4271,  3.8208,  4.1443,  4.1824,  4.3825,  4.5141,  5.2268,  5.5665,















Epoch: 1, Loss: 0.6131:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [06:06<04:40,  2.53it/s]


[38mic| total_loss: 75.96754425764084[39malidation Loss: 0.4254: 100%|â–ˆ| 121/121 [00:03<00:00, 29.34it/s
[38mic| metrics: {'ACCURACY': 0.6728778467908902,
[38m              'F1_Macro': 0.8044554455445545,
[38m              'LOSS': 0.6278309442780234,
[38m              'MAE': 0.32712215320910976,
[38m              'MCC': 0.0,
[38m              'PRECISION': 0.6728778467908902,
[38m              'RECALL': 1.0}
Epoch: 1, Loss: 0.6131:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [06:17<08:57,  1.32it/s]
[33m[W 2024-05-11 15:51:07,113][39m Trial 40 failed with parameters: {'learning_rate': 5.174338585754398e-05, 'k_approx': 10, 'num_of_fosi_iterations': 143} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-11 15:51:07,113][39m Trial 40 failed with value None.
An exception occurred:
Returning None...
Returned ESE function. Lanczos order (m) is 68 .
















Epoch: 1, Loss: 0.7284:   5%|â–ˆâ–Œ                             | 60/1209 [02:47<9:17:34, 29.12s/it]
lambda_max: 37.91775131225586 lrs: tensor([0.2774, 0.2762, 0.2544, 0.2443, 0.2400, 0.2374, 0.2278, 0.2172, 0.2092,
        0.2000, 0.1940, 0.1940, 0.1898, 0.1877, 0.1856, 0.1701, 0.0264]) eigenvals: tensor([ 3.6050,  3.6203,  3.9313,  4.0928,  4.1668,  4.2118,  4.3893,  4.6043,
         4.7811,  4.9993,  5.1537,  5.1556,  5.2686,  5.3284,  5.3866,  5.8784,
















Epoch: 1, Loss: 0.8020:  10%|â–ˆâ–ˆâ–ˆ                             | 117/1209 [03:19<10:11,  1.79it/s]
lambda_max: 27.133756637573242 lrs: tensor([0.2733, 0.2706, 0.2541, 0.2420, 0.2377, 0.2309, 0.2278, 0.2213, 0.2192,
        0.2021, 0.2018, 0.1965, 0.1898, 0.1781, 0.1684, 0.1438, 0.0369]) eigenvals: tensor([ 3.6592,  3.6961,  3.9360,  4.1323,  4.2067,  4.3314,  4.3908,  4.5177,
         4.5621,  4.9468,  4.9558,  5.0887,  5.2695,  5.6145,  5.9391,  6.9549,

















Epoch: 1, Loss: 0.7486:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 176/1209 [06:17<09:33,  1.80it/s]
lambda_max: 27.942773818969727 lrs: tensor([0.2675, 0.2611, 0.2574, 0.2479, 0.2354, 0.2340, 0.2271, 0.2193, 0.2170,
        0.2157, 0.2106, 0.2068, 0.2006, 0.1883, 0.1758, 0.1286, 0.0358]) eigenvals: tensor([ 3.7381,  3.8293,  3.8851,  4.0342,  4.2485,  4.2735,  4.4039,  4.5599,
         4.6084,  4.6357,  4.7491,  4.8361,  4.9857,  5.3101,  5.6893,  7.7754,


















Epoch: 1, Loss: 0.5291:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 236/1209 [11:09<10:37:22, 39.30s/it]
lambda_max: 21.857452392578125 lrs: tensor([0.2698, 0.2638, 0.2503, 0.2443, 0.2367, 0.2224, 0.2186, 0.2104, 0.2067,
        0.2057, 0.2026, 0.1999, 0.1956, 0.1932, 0.1899, 0.1848, 0.0458]) eigenvals: tensor([ 3.7070,  3.7909,  3.9951,  4.0932,  4.2253,  4.4967,  4.5755,  4.7537,
         4.8372,  4.8611,  4.9363,  5.0023,  5.1134,  5.1769,  5.2655,  5.4109,









Epoch: 1, Loss: 0.5345:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 266/1209 [11:29<09:03,  1.74it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5732349157333374, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715443348.4647613}).







Epoch: 1, Loss: 0.8043:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 294/1209 [11:44<08:31,  1.79it/s]
lambda_max: 20.533308029174805 lrs: tensor([0.2754, 0.2728, 0.2584, 0.2435, 0.2346, 0.2284, 0.2250, 0.2206, 0.2162,
        0.2048, 0.2042, 0.2009, 0.1994, 0.1941, 0.1805, 0.1419, 0.0487]) eigenvals: tensor([ 3.6306,  3.6658,  3.8698,  4.1072,  4.2632,  4.3774,  4.4441,  4.5341,
         4.6247,  4.8828,  4.8965,  4.9781,  5.0140,  5.1523,  5.5415,  7.0451,
















Epoch: 1, Loss: 0.7296:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 353/1209 [14:21<07:24,  1.92it/s]
lambda_max: 19.139867782592773 lrs: tensor([0.3551, 0.3232, 0.3153, 0.3094, 0.3021, 0.2881, 0.2833, 0.2812, 0.2773,
        0.2719, 0.2650, 0.2640, 0.2575, 0.2490, 0.2021, 0.1468, 0.0522]) eigenvals: tensor([ 2.8163,  3.0943,  3.1719,  3.2321,  3.3102,  3.4709,  3.5292,  3.5560,
         3.6061,  3.6772,  3.7738,  3.7877,  3.8838,  4.0160,  4.9486,  6.8129,

















Epoch: 1, Loss: 0.6433:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 415/1209 [19:06<4:09:33, 18.86s/it]
lambda_max: 19.424283981323242 lrs: tensor([0.2865, 0.2764, 0.2714, 0.2502, 0.2458, 0.2432, 0.2400, 0.2276, 0.2214,
        0.2190, 0.2167, 0.2094, 0.2062, 0.2052, 0.1986, 0.1805, 0.0515]) eigenvals: tensor([ 3.4906,  3.6184,  3.6852,  3.9969,  4.0680,  4.1116,  4.1660,  4.3929,
         4.5164,  4.5656,  4.6138,  4.7749,  4.8492,  4.8735,  5.0348,  5.5389,















Epoch: 1, Loss: 0.7489:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 471/1209 [19:35<06:19,  1.94it/s]
lambda_max: 18.61065673828125 lrs: tensor([0.2898, 0.2817, 0.2763, 0.2629, 0.2580, 0.2399, 0.2372, 0.2337, 0.2323,
        0.2279, 0.2197, 0.2149, 0.2118, 0.2109, 0.1990, 0.1472, 0.0537]) eigenvals: tensor([ 3.4509,  3.5504,  3.6188,  3.8044,  3.8756,  4.1683,  4.2157,  4.2796,
         4.3039,  4.3888,  4.5520,  4.6529,  4.7215,  4.7427,  5.0250,  6.7940,








Epoch: 1, Loss: 0.8288:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [21:59<06:09,  1.92it/s]

[38mic| total_loss: 77.49895322322845[39malidation Loss: 0.5825:  99%|â–‰| 120/121 [00:03<00:00, 33.68it/s
[38mic| metrics: {'ACCURACY': 0.6708074534161491,
[38m              'F1_Macro': 0.8029739776951673,
[38m              'LOSS': 0.6404872167208964,
[38m              'MAE': 0.32919254658385094,
[38m              'MCC': -0.03175874585178891,
[38m              'PRECISION': 0.6721991701244814,
[38m              'RECALL': 0.9969230769230769}
Epoch: 1, Loss: 0.8288:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [22:09<31:32,  2.67s/it]
[33m[W 2024-05-11 16:13:17,443][39m Trial 41 failed with parameters: {'learning_rate': 9.23931725424358e-06, 'k_approx': 17, 'num_of_fosi_iterations': 59} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-11 16:13:17,443][39m Trial 41 failed with value None.
Epoch: 1, Loss: 0.4427:   0%|                                  | 1/1209 [00:00<10:12,  1.97it/s]
An exception occurred:
Returning None...
Epoch: 1, Loss: 0.1896:   0%|â–                                 | 5/1209 [00:02<09:49,  2.04it/s]
Epoch: 1, Loss: 0.4456:   1%|â–Ž                                 | 9/1209 [00:04<09:35,  2.09it/s]
Epoch: 1, Loss: 0.1170:   1%|â–Ž                                | 13/1209 [00:06<09:25,  2.11it/s]
Epoch: 1, Loss: 0.1005:   1%|â–                                | 17/1209 [00:08<10:13,  1.94it/s]
Epoch: 1, Loss: 1.1012:   2%|â–Œ                                | 21/1209 [00:10<09:50,  2.01it/s]
Epoch: 1, Loss: 0.5635:   2%|â–‹                                | 25/1209 [00:12<09:26,  2.09it/s]
Epoch: 1, Loss: 0.3192:   2%|â–Š                                | 30/1209 [00:14<09:22,  2.10it/s]
Epoch: 1, Loss: 0.6724:   3%|â–‰                                | 34/1209 [00:16<09:20,  2.10it/s]
Epoch: 1, Loss: 0.7018:   3%|â–ˆ                                | 38/1209 [00:18<09:21,  2.09it/s]
Epoch: 1, Loss: 0.6182:   3%|â–ˆâ–                               | 42/1209 [00:20<09:39,  2.01it/s]
Epoch: 1, Loss: 0.7586:   4%|â–ˆâ–Ž                               | 46/1209 [00:22<09:24,  2.06it/s]
Epoch: 1, Loss: 0.6072:   4%|â–ˆâ–Ž                               | 50/1209 [00:24<09:14,  2.09it/s]
Epoch: 1, Loss: 1.9801:   5%|â–ˆâ–Œ                               | 55/1209 [00:26<09:10,  2.10it/s]
Epoch: 1, Loss: 0.8082:   5%|â–ˆâ–Œ                               | 59/1209 [00:28<09:06,  2.10it/s]
Epoch: 1, Loss: 0.7185:   5%|â–ˆâ–‹                               | 63/1209 [00:30<09:39,  1.98it/s]
Epoch: 1, Loss: 0.6210:   6%|â–ˆâ–Š                               | 67/1209 [00:32<09:35,  1.99it/s]
Epoch: 1, Loss: 0.7195:   6%|â–ˆâ–‰                               | 70/1209 [00:34<09:15,  2.05it/s]
Epoch: 1, Loss: 0.8343:   6%|â–ˆâ–ˆ                               | 75/1209 [00:36<09:02,  2.09it/s]
Epoch: 1, Loss: 0.5654:   7%|â–ˆâ–ˆâ–                              | 79/1209 [00:38<09:32,  1.97it/s]
Epoch: 1, Loss: 0.6210:   7%|â–ˆâ–ˆâ–Ž                              | 83/1209 [00:40<09:45,  1.92it/s]
Epoch: 1, Loss: 0.5798:   7%|â–ˆâ–ˆâ–Ž                              | 87/1209 [00:42<09:14,  2.02it/s]
Epoch: 1, Loss: 0.5835:   8%|â–ˆâ–ˆâ–                              | 91/1209 [00:44<09:19,  2.00it/s]
Epoch: 1, Loss: 0.8262:   8%|â–ˆâ–ˆâ–Œ                              | 95/1209 [00:46<08:57,  2.07it/s]
Epoch: 1, Loss: 0.7810:   8%|â–ˆâ–ˆâ–‹                              | 99/1209 [00:48<08:52,  2.08it/s]
Epoch: 1, Loss: 0.6186:   9%|â–ˆâ–ˆâ–Š                             | 104/1209 [00:50<08:46,  2.10it/s]
Epoch: 1, Loss: 0.4366:   9%|â–ˆâ–ˆâ–Š                             | 108/1209 [00:52<08:45,  2.09it/s]
Epoch: 1, Loss: 1.0025:   9%|â–ˆâ–ˆâ–‰                             | 112/1209 [00:54<08:47,  2.08it/s]
Epoch: 1, Loss: 0.4401:  10%|â–ˆâ–ˆâ–ˆ                             | 116/1209 [00:56<08:41,  2.09it/s]
Epoch: 1, Loss: 0.6666:  10%|â–ˆâ–ˆâ–ˆâ–                            | 120/1209 [00:58<08:38,  2.10it/s]
Epoch: 1, Loss: 0.5263:  10%|â–ˆâ–ˆâ–ˆâ–Ž                            | 124/1209 [01:00<08:38,  2.09it/s]
Epoch: 1, Loss: 0.6775:  11%|â–ˆâ–ˆâ–ˆâ–                            | 129/1209 [01:02<08:38,  2.08it/s]
Epoch: 1, Loss: 0.5314:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 133/1209 [01:04<08:32,  2.10it/s]
Epoch: 1, Loss: 0.5562:  11%|â–ˆâ–ˆâ–ˆâ–‹                            | 137/1209 [01:06<08:29,  2.10it/s]
Epoch: 1, Loss: 0.5807:  12%|â–ˆâ–ˆâ–ˆâ–                          | 140/1209 [02:28<3:39:03, 12.29s/it]
Epoch: 1, Loss: 0.5807:  12%|â–ˆâ–ˆâ–ˆâ–                          | 140/1209 [02:28<3:39:03, 12.29s/it]
lambda_max: 21.920392990112305 lrs: tensor([0.3540, 0.3216, 0.3164, 0.3004, 0.2824, 0.2776, 0.2759, 0.2552, 0.2349,
        0.2319, 0.2167, 0.1950, 0.0456]) eigenvals: tensor([ 2.8251,  3.1093,  3.1606,  3.3294,  3.5407,  3.6024,  3.6239,  3.9184,
Epoch: 1, Loss: 0.6930:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 144/1209 [02:30<58:38,  3.30s/it]
Epoch: 1, Loss: 0.5990:  12%|â–ˆâ–ˆâ–ˆâ–‰                            | 148/1209 [02:32<20:21,  1.15s/it]
Epoch: 1, Loss: 0.6740:  13%|â–ˆâ–ˆâ–ˆâ–ˆ                            | 152/1209 [02:34<11:09,  1.58it/s]
Epoch: 1, Loss: 0.6319:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 157/1209 [02:36<08:45,  2.00it/s]
Epoch: 1, Loss: 0.4206:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 161/1209 [02:38<08:30,  2.05it/s]
Epoch: 1, Loss: 0.5569:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 165/1209 [02:40<08:26,  2.06it/s]
Epoch: 1, Loss: 0.5900:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 169/1209 [02:42<08:14,  2.10it/s]
Epoch: 1, Loss: 0.7564:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 173/1209 [02:44<08:39,  1.99it/s]
Epoch: 1, Loss: 0.5484:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 178/1209 [02:46<08:03,  2.13it/s]
Epoch: 1, Loss: 0.6679:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 182/1209 [02:48<07:58,  2.15it/s]
Epoch: 1, Loss: 0.6195:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                           | 186/1209 [02:50<07:55,  2.15it/s]
Epoch: 1, Loss: 0.4774:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 191/1209 [02:52<07:55,  2.14it/s]
Epoch: 1, Loss: 0.5483:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 195/1209 [02:54<07:52,  2.15it/s]
Epoch: 1, Loss: 0.8712:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 199/1209 [02:56<07:50,  2.15it/s]
Epoch: 1, Loss: 0.4671:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 204/1209 [02:58<07:54,  2.12it/s]
Epoch: 1, Loss: 0.5108:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                          | 208/1209 [03:00<07:58,  2.09it/s]
Epoch: 1, Loss: 0.4942:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                          | 212/1209 [03:02<08:02,  2.07it/s]
Epoch: 1, Loss: 0.2352:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 216/1209 [03:04<08:07,  2.04it/s]
Epoch: 1, Loss: 0.7078:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 220/1209 [03:06<07:42,  2.14it/s]
Epoch: 1, Loss: 0.3545:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 225/1209 [03:08<07:38,  2.15it/s]
Epoch: 1, Loss: 0.5357:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 229/1209 [03:10<07:38,  2.14it/s]
Epoch: 1, Loss: 0.3510:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 233/1209 [03:12<07:36,  2.14it/s]
Epoch: 1, Loss: 0.6329:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 237/1209 [03:14<07:51,  2.06it/s]
Epoch: 1, Loss: 0.6131:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 241/1209 [03:16<07:49,  2.06it/s]
Epoch: 1, Loss: 0.5150:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 246/1209 [03:18<07:36,  2.11it/s]
Epoch: 1, Loss: 0.7708:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [03:20<07:31,  2.13it/s]
Epoch: 1, Loss: 0.5728:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 251/1209 [03:24<19:48,  1.24s/it]
Epoch: 1, Loss: 0.5708:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 255/1209 [03:26<10:24,  1.53it/s]
Epoch: 1, Loss: 0.3701:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 259/1209 [03:28<08:10,  1.94it/s]
Epoch: 1, Loss: 0.6024:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 264/1209 [03:30<07:32,  2.09it/s]
Epoch: 1, Loss: 0.5256:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 268/1209 [03:32<07:23,  2.12it/s]
Epoch: 1, Loss: 1.2178:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 272/1209 [03:34<07:18,  2.14it/s]
Epoch: 1, Loss: 1.2178:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 272/1209 [03:34<07:18,  2.14it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.5184:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 277/1209 [05:02<4:46:43, 18.46s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.5184:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 277/1209 [05:02<4:46:43, 18.46s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
lambda_max: 25.95505714416504 lrs: tensor([0.3732, 0.3494, 0.3486, 0.3360, 0.2973, 0.2941, 0.2921, 0.2830, 0.2664,
        0.2551, 0.1975, 0.1364, 0.0385]) eigenvals: tensor([ 2.6795,  2.8624,  2.8683,  2.9760,  3.3634,  3.4008,  3.4233,  3.5342,
Epoch: 1, Loss: 0.5753:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 282/1209 [05:04<53:49,  3.48s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.8057:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 286/1209 [05:06<18:12,  1.18s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.8466:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 290/1209 [05:08<09:37,  1.59it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.3790:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 295/1209 [05:10<07:23,  2.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.7702:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 299/1209 [05:12<07:02,  2.15it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.4856:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 303/1209 [05:14<07:21,  2.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.7229:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 307/1209 [05:16<07:21,  2.04it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.5943:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 312/1209 [05:18<07:13,  2.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.4786:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 316/1209 [05:20<07:03,  2.11it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.6428:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 320/1209 [05:22<06:54,  2.15it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.5963:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 325/1209 [05:25<06:47,  2.17it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.3906:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 329/1209 [05:26<06:46,  2.16it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.9028:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 333/1209 [05:28<06:44,  2.16it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.8240:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 338/1209 [05:31<06:39,  2.18it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.4627:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 342/1209 [05:32<06:38,  2.18it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.8474:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 346/1209 [05:34<06:42,  2.14it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.2592:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 351/1209 [05:37<06:36,  2.16it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.6993:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 355/1209 [05:38<06:33,  2.17it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 1.2044:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 359/1209 [05:40<06:38,  2.13it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.3747:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 363/1209 [05:42<06:36,  2.13it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.4361:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 368/1209 [05:44<06:35,  2.13it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.7475:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 372/1209 [05:46<06:26,  2.17it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.9567:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 376/1209 [05:48<06:23,  2.17it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.8365:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 381/1209 [05:51<06:23,  2.16it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.8457:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 385/1209 [05:52<06:18,  2.18it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.7328:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 389/1209 [05:54<06:21,  2.15it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.2949:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 394/1209 [05:57<06:14,  2.18it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.4999:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 398/1209 [05:58<06:15,  2.16it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.3482:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 403/1209 [06:01<06:10,  2.17it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.1701:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 407/1209 [06:03<06:14,  2.14it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.1854:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 411/1209 [06:04<06:11,  2.15it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.7780:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 413/1209 [06:05<06:10,  2.15it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.7780:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 413/1209 [06:05<06:10,  2.15it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
lambda_max: 14.750033378601074 lrs: tensor([0.2481, 0.2371, 0.2241, 0.2149, 0.2069, 0.1977, 0.1963, 0.1911, 0.1847,
        0.1822, 0.1735, 0.1604, 0.0678]) eigenvals: tensor([ 4.0302,  4.2180,  4.4624,  4.6528,  4.8344,  5.0573,  5.0934,  5.2341,
Epoch: 1, Loss: 0.4676:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 415/1209 [07:33<4:06:49, 18.65s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 1.4093:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 419/1209 [07:35<1:03:41,  4.84s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.6681:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 423/1209 [07:37<19:55,  1.52s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.2250:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 427/1209 [07:39<09:34,  1.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.3280:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 431/1209 [07:41<07:18,  1.78it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.1041:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 435/1209 [07:43<06:25,  2.01it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.7567:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 439/1209 [07:44<06:14,  2.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.5497:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 444/1209 [07:47<06:02,  2.11it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.2325:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 448/1209 [07:49<06:02,  2.10it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.1730:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 452/1209 [07:51<06:03,  2.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.3760:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 456/1209 [07:53<06:00,  2.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.3816:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 461/1209 [07:55<05:54,  2.11it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.5356:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 465/1209 [07:57<05:54,  2.10it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.2040:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 469/1209 [07:59<06:15,  1.97it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.6486:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 473/1209 [08:01<05:52,  2.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.5016:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 477/1209 [08:03<05:52,  2.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.9384:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 481/1209 [08:05<05:55,  2.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.5156:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 486/1209 [08:07<05:50,  2.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.1763:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 490/1209 [08:09<05:56,  2.02it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.7473:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 494/1209 [08:11<05:41,  2.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.1785:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 498/1209 [08:13<05:38,  2.10it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.7577:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [08:13<05:34,  2.12it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.7577:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [08:13<05:34,  2.12it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.7577:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [08:13<05:34,  2.12it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Validation at Global Step: 500, Validation Loss: 0.0941: 100%|â–ˆ| 121/121 [00:03<00:00, 33.26it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Validation at Global Step: 500, Validation Loss: 0.0941: 100%|â–ˆ| 121/121 [00:03<00:00, 33.26it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
An exception occurred:
Returning None...
[33m[W 2024-05-11 16:21:42,391][39m Trial 42 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 33.26it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
[33m[W 2024-05-11 16:21:42,391][39m Trial 42 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 33.26it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.2137:   1%|â–                                | 14/1209 [00:04<06:32,  3.04it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.2987:   2%|â–Œ                                | 20/1209 [00:06<06:32,  3.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.4864:   2%|â–‹                                | 26/1209 [00:08<06:30,  3.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 1.3274:   3%|â–Š                                | 32/1209 [00:10<06:29,  3.02it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.5041:   3%|â–ˆ                                | 38/1209 [00:12<06:23,  3.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.7664:   4%|â–ˆâ–                               | 45/1209 [00:14<06:22,  3.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.4817:   4%|â–ˆâ–                               | 51/1209 [00:16<06:21,  3.04it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.1712:   5%|â–ˆâ–Œ                               | 57/1209 [00:18<06:22,  3.01it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.8403:   5%|â–ˆâ–‹                               | 63/1209 [00:20<06:20,  3.02it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.2181:   6%|â–ˆâ–‰                               | 69/1209 [00:22<06:18,  3.01it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.9469:   6%|â–ˆâ–ˆ                               | 74/1209 [00:24<06:13,  3.04it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.2519:   7%|â–ˆâ–ˆâ–                              | 79/1209 [00:26<06:12,  3.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.9484:   7%|â–ˆâ–ˆ                             | 80/1209 [00:46<2:00:26,  6.40s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.9484:   7%|â–ˆâ–ˆ                             | 80/1209 [00:46<2:00:26,  6.40s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.1472:   7%|â–ˆâ–ˆâ–Ž                              | 86/1209 [00:48<19:46,  1.06s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.1795:   8%|â–ˆâ–ˆâ–                              | 91/1209 [00:50<08:47,  2.12it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.7055:   8%|â–ˆâ–ˆâ–‹                              | 97/1209 [00:52<06:32,  2.83it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.4092:   9%|â–ˆâ–ˆâ–‹                             | 103/1209 [00:54<06:18,  2.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.6259:   9%|â–ˆâ–ˆâ–‰                             | 109/1209 [00:56<06:18,  2.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.5495:  10%|â–ˆâ–ˆâ–ˆ                             | 115/1209 [00:58<06:11,  2.95it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.3626:  10%|â–ˆâ–ˆâ–ˆâ–                            | 121/1209 [01:01<06:08,  2.95it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.7125:  11%|â–ˆâ–ˆâ–ˆâ–Ž                            | 127/1209 [01:03<06:10,  2.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.6833:  11%|â–ˆâ–ˆâ–ˆâ–                            | 132/1209 [01:04<06:27,  2.78it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.3447:  11%|â–ˆâ–ˆâ–ˆâ–‹                            | 138/1209 [01:06<06:09,  2.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.6154:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 144/1209 [01:08<05:58,  2.97it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.2532:  12%|â–ˆâ–ˆâ–ˆâ–‰                            | 150/1209 [01:10<05:55,  2.98it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.3275:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 156/1209 [01:13<06:00,  2.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.4414:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 159/1209 [01:14<06:29,  2.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.4414:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 159/1209 [01:14<06:29,  2.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.2410:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 163/1209 [01:34<40:56,  2.35s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.3822:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 169/1209 [01:37<10:00,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 1.4158:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 175/1209 [01:39<06:23,  2.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.5478:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 181/1209 [01:41<05:57,  2.87it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.8688:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                           | 187/1209 [01:43<05:50,  2.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.6354:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 193/1209 [01:45<05:46,  2.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.2344:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 198/1209 [01:46<05:43,  2.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.1370:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 204/1209 [01:49<06:05,  2.75it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.4282:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                          | 210/1209 [01:51<05:46,  2.88it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.4462:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 216/1209 [01:53<05:37,  2.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.1146:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 222/1209 [01:55<05:38,  2.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.1696:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 228/1209 [01:57<05:39,  2.89it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 1.6497:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 233/1209 [01:59<05:41,  2.86it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.1909:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 239/1209 [02:01<05:47,  2.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.1909:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 239/1209 [02:01<05:47,  2.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.5394:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 243/1209 [02:23<39:36,  2.46s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.4382:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [02:25<09:18,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5569559335708618, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.75, 'RECALL/Train': 1.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715444201.9548895}).
Epoch: 1, Loss: 0.4382:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [02:25<09:18,  1.72it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.1715444201.9548895}).
Epoch: 1, Loss: 0.1486:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 256/1209 [02:31<07:59,  1.99it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.1715444201.9548895}).
Epoch: 1, Loss: 0.3973:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 262/1209 [02:33<05:34,  2.84it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.1715444201.9548895}).
Epoch: 1, Loss: 0.1831:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 267/1209 [02:35<05:45,  2.73it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.1715444201.9548895}).
Epoch: 1, Loss: 0.3138:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 273/1209 [02:37<05:29,  2.84it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.1715444201.9548895}).
Epoch: 1, Loss: 0.6404:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 279/1209 [02:39<05:16,  2.94it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.1715444201.9548895}).
Epoch: 1, Loss: 0.9563:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 280/1209 [02:39<05:07,  3.02it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.7914:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 291/1209 [02:43<05:09,  2.96it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.1763:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 297/1209 [02:45<05:06,  2.98it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.4704:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 303/1209 [02:47<05:03,  2.98it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.3269:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 309/1209 [02:49<05:38,  2.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.4716:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 314/1209 [02:51<05:29,  2.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.5494:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 319/1209 [02:52<05:03,  2.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.2346:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 321/1209 [03:13<1:06:08,  4.47s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.2346:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 321/1209 [03:13<1:06:08,  4.47s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.2300:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 327/1209 [03:15<12:09,  1.21it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.1211:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 333/1209 [03:17<05:47,  2.52it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.5450:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 339/1209 [03:19<05:00,  2.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 1.0659:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 345/1209 [03:21<04:53,  2.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.4850:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 351/1209 [03:23<04:52,  2.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.2635:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 357/1209 [03:25<04:44,  2.99it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.5118:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 363/1209 [03:27<04:40,  3.01it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.2443:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 369/1209 [03:29<04:41,  2.99it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 1.0161:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 375/1209 [03:31<04:37,  3.01it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.2201:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 381/1209 [03:33<04:38,  2.97it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.5299:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 387/1209 [03:35<04:37,  2.96it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.4274:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 393/1209 [03:37<04:35,  2.97it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.2245:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 399/1209 [03:39<04:31,  2.98it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.2245:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 399/1209 [03:39<04:31,  2.98it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.3308:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 404/1209 [03:59<22:12,  1.66s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.2064:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 410/1209 [04:01<06:25,  2.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.3096:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 416/1209 [04:03<04:35,  2.88it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.4009:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 422/1209 [04:05<04:36,  2.85it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.7628:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 427/1209 [04:07<04:44,  2.75it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.3587:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 434/1209 [04:09<04:17,  3.01it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.1764:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                    | 440/1209 [04:11<04:11,  3.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.1127:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 446/1209 [04:13<04:10,  3.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.1164:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 452/1209 [04:15<04:07,  3.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 1.3386:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 458/1209 [04:17<04:10,  3.00it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.0251:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 464/1209 [04:19<04:04,  3.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.8713:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 470/1209 [04:21<04:03,  3.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.3776:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 476/1209 [04:23<04:00,  3.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.4211:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 479/1209 [04:24<04:03,  2.99it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.2379:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 482/1209 [04:45<39:30,  3.26s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.2379:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 482/1209 [04:45<39:30,  3.26s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.2066:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 488/1209 [04:47<08:09,  1.47it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.8845:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 494/1209 [04:49<04:32,  2.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.8091:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [04:51<04:03,  2.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.8091:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [04:51<04:03,  2.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.8091:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [04:51<04:03,  2.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Validation at Global Step: 500, Validation Loss: 1.6437: 100%|â–ˆ| 121/121 [00:03<00:00, 33.52it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Validation at Global Step: 500, Validation Loss: 1.6437: 100%|â–ˆ| 121/121 [00:03<00:00, 33.52it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
An exception occurred:
Returning None...
[33m[W 2024-05-11 16:26:44,912][39m Trial 43 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 33.52it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
[33m[W 2024-05-11 16:26:44,912][39m Trial 43 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 33.52it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.5824:   1%|â–                                | 18/1209 [00:05<05:36,  3.54it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.5246:   2%|â–‹                                | 25/1209 [00:07<05:29,  3.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.0973:   3%|â–Š                                | 32/1209 [00:09<05:33,  3.53it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.2130:   3%|â–ˆ                                | 39/1209 [00:11<05:43,  3.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.2204:   4%|â–ˆâ–Ž                               | 46/1209 [00:13<05:41,  3.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.2176:   4%|â–ˆâ–                               | 53/1209 [00:15<05:36,  3.43it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.2803:   5%|â–ˆâ–‹                               | 60/1209 [00:17<05:42,  3.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.1838:   5%|â–ˆâ–Š                               | 66/1209 [00:19<05:25,  3.51it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.4472:   6%|â–ˆâ–ˆ                               | 74/1209 [00:21<05:13,  3.62it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.1781:   7%|â–ˆâ–ˆâ–                              | 80/1209 [00:22<05:23,  3.49it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.1781:   7%|â–ˆâ–ˆâ–                              | 80/1209 [00:22<05:23,  3.49it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.1781:   7%|â–ˆâ–ˆâ–Ž                              | 86/1209 [00:31<11:30,  1.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.0752:   8%|â–ˆâ–ˆâ–Œ                              | 93/1209 [00:33<05:44,  3.24it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.0725:   8%|â–ˆâ–ˆâ–‹                             | 100/1209 [00:35<05:20,  3.46it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.5786:   9%|â–ˆâ–ˆâ–Š                             | 107/1209 [00:37<05:13,  3.52it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.9953:  10%|â–ˆâ–ˆâ–ˆ                             | 115/1209 [00:39<05:08,  3.55it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.2537:  10%|â–ˆâ–ˆâ–ˆâ–                            | 122/1209 [00:41<05:07,  3.54it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.8262:  11%|â–ˆâ–ˆâ–ˆâ–                            | 129/1209 [00:43<05:05,  3.53it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.0617:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 136/1209 [00:45<04:59,  3.58it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.1600:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 143/1209 [00:47<05:04,  3.50it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.4048:  12%|â–ˆâ–ˆâ–ˆâ–‰                            | 150/1209 [00:49<04:56,  3.58it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.6502:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 157/1209 [00:51<04:57,  3.54it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.0843:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 161/1209 [00:52<04:54,  3.56it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.0843:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 161/1209 [00:52<04:54,  3.56it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.5637:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 168/1209 [01:01<09:03,  1.91it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.5634:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 175/1209 [01:03<05:11,  3.32it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.5292:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 183/1209 [01:05<04:46,  3.58it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.1366:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 190/1209 [01:07<04:45,  3.57it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.8007:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 197/1209 [01:09<04:43,  3.56it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.1515:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 204/1209 [01:11<04:41,  3.57it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.2222:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                          | 211/1209 [01:13<04:35,  3.62it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.1670:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 219/1209 [01:15<04:34,  3.61it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.2082:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 226/1209 [01:17<04:36,  3.55it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.6968:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 233/1209 [01:19<04:31,  3.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.0648:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 240/1209 [01:21<04:33,  3.54it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.1919:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 242/1209 [01:22<04:29,  3.59it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.5531:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 245/1209 [01:29<20:09,  1.25s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.5531:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 245/1209 [01:29<20:09,  1.25s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.5623:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [01:30<08:15,  1.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.1463:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 255/1209 [01:35<07:39,  2.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.18874572217464447, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715444651.7739491}).444201.9548895}).
Epoch: 1, Loss: 0.4495:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 260/1209 [01:37<05:04,  3.11it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.7152:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 269/1209 [01:39<04:25,  3.54it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.2233:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 276/1209 [01:41<04:28,  3.47it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.3774:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 283/1209 [01:43<04:24,  3.51it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.7542:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 290/1209 [01:45<04:18,  3.55it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.6831:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 297/1209 [01:47<04:26,  3.42it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.6771:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 304/1209 [01:49<04:18,  3.51it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1301:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 311/1209 [01:51<04:15,  3.51it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1903:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 318/1209 [01:53<04:14,  3.50it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.4347:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 323/1209 [01:55<04:08,  3.56it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1244:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 329/1209 [02:03<09:15,  1.58it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1244:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 329/1209 [02:03<09:15,  1.58it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.2480:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 336/1209 [02:05<04:40,  3.11it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.2431:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 343/1209 [02:07<04:09,  3.47it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.3722:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 350/1209 [02:09<04:06,  3.49it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.0653:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 357/1209 [02:11<04:03,  3.50it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.0355:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 364/1209 [02:13<04:04,  3.46it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1817:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 371/1209 [02:15<04:01,  3.47it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.0963:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 378/1209 [02:18<04:09,  3.33it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.4469:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 385/1209 [02:20<03:57,  3.47it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.0558:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 392/1209 [02:22<03:53,  3.50it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.7981:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 399/1209 [02:24<03:54,  3.46it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1058:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 404/1209 [02:25<03:49,  3.50it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1071:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 409/1209 [02:33<10:33,  1.26it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1071:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 409/1209 [02:33<10:33,  1.26it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.6368:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 416/1209 [02:35<04:23,  3.01it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1010:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 423/1209 [02:37<03:47,  3.46it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.4530:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 430/1209 [02:39<03:42,  3.50it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1280:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 437/1209 [02:41<03:44,  3.44it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.9147:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 445/1209 [02:44<03:36,  3.52it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.2183:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 451/1209 [02:45<03:43,  3.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1798:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 458/1209 [02:48<03:37,  3.45it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.0712:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 465/1209 [02:50<03:36,  3.44it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.6351:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 472/1209 [02:52<03:35,  3.43it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.3658:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 479/1209 [02:54<03:31,  3.46it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1048:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 485/1209 [02:55<03:26,  3.50it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.4321:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 490/1209 [03:04<09:17,  1.29it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.4321:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 490/1209 [03:04<09:17,  1.29it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.0404:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 497/1209 [03:06<03:58,  2.99it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1037:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [03:06<03:40,  3.22it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1037:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [03:06<03:40,  3.22it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1037:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [03:06<03:40,  3.22it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Validation at Global Step: 500, Validation Loss: 1.0225: 100%|â–ˆ| 121/121 [00:03<00:00, 33.54it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Validation at Global Step: 500, Validation Loss: 1.0225: 100%|â–ˆ| 121/121 [00:03<00:00, 33.54it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
An exception occurred:
Returning None...
[33m[W 2024-05-11 16:30:03,594][39m Trial 44 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 33.54it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
[33m[W 2024-05-11 16:30:03,594][39m Trial 44 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 33.54it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.0978:   1%|â–                                | 16/1209 [00:05<06:42,  2.96it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.4831:   2%|â–Œ                                | 22/1209 [00:07<06:38,  2.98it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.2471:   2%|â–Š                                | 28/1209 [00:09<06:33,  3.00it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 1.2801:   3%|â–‰                                | 35/1209 [00:11<06:26,  3.04it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1210:   3%|â–ˆ                                | 41/1209 [00:13<06:32,  2.97it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1358:   4%|â–ˆâ–Ž                               | 46/1209 [00:15<06:33,  2.95it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.5225:   4%|â–ˆâ–                               | 52/1209 [00:17<06:30,  2.96it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.7159:   5%|â–ˆâ–Œ                               | 58/1209 [00:19<06:27,  2.97it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.4426:   5%|â–ˆâ–‹                               | 64/1209 [00:21<06:32,  2.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1988:   6%|â–ˆâ–Š                               | 67/1209 [00:22<06:41,  2.84it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1988:   6%|â–ˆâ–Š                               | 67/1209 [00:22<06:41,  2.84it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.8060:   6%|â–ˆâ–Š                             | 70/1209 [00:45<1:07:34,  3.56s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.0537:   6%|â–ˆâ–ˆ                               | 76/1209 [00:47<13:33,  1.39it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1319:   7%|â–ˆâ–ˆâ–Ž                              | 83/1209 [00:49<06:48,  2.76it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1903:   7%|â–ˆâ–ˆâ–                              | 89/1209 [00:51<06:13,  3.00it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.2198:   8%|â–ˆâ–ˆâ–Œ                              | 95/1209 [00:53<06:19,  2.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.3816:   8%|â–ˆâ–ˆâ–‹                             | 100/1209 [00:55<06:20,  2.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.3770:   9%|â–ˆâ–ˆâ–Š                             | 106/1209 [00:57<06:07,  3.00it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.5730:   9%|â–ˆâ–ˆâ–‰                             | 113/1209 [00:59<06:00,  3.04it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.0178:  10%|â–ˆâ–ˆâ–ˆâ–                            | 119/1209 [01:01<05:59,  3.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1054:  10%|â–ˆâ–ˆâ–ˆâ–Ž                            | 124/1209 [01:03<05:58,  3.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.0363:  11%|â–ˆâ–ˆâ–ˆâ–                            | 131/1209 [01:05<06:11,  2.91it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.0855:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 135/1209 [01:07<05:54,  3.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.0855:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 135/1209 [01:07<05:54,  3.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.3429:  12%|â–ˆâ–ˆâ–ˆâ–‹                            | 140/1209 [01:29<32:39,  1.83s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.3088:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 146/1209 [01:31<08:55,  1.99it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.2031:  13%|â–ˆâ–ˆâ–ˆâ–ˆ                            | 152/1209 [01:33<06:10,  2.85it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.0314:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 159/1209 [01:35<05:48,  3.01it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.0268:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 165/1209 [01:37<05:42,  3.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.0329:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 171/1209 [01:39<05:40,  3.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1998:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 177/1209 [01:41<05:43,  3.00it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.2503:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 183/1209 [01:43<05:56,  2.88it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1964:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 189/1209 [01:45<05:37,  3.02it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.2422:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 195/1209 [01:47<05:32,  3.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.0991:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 201/1209 [01:49<05:28,  3.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1980:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 203/1209 [01:50<05:30,  3.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1980:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 203/1209 [01:50<05:30,  3.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.9436:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 206/1209 [02:11<55:44,  3.33s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.3635:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                          | 212/1209 [02:13<11:20,  1.47it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.0559:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 218/1209 [02:15<06:12,  2.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.9433:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 224/1209 [02:17<05:19,  3.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.0480:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 230/1209 [02:19<05:10,  3.16it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1416:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 237/1209 [02:22<05:07,  3.16it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.0957:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 243/1209 [02:23<05:08,  3.13it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 1.1565:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [02:25<05:03,  3.16it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.4592:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 252/1209 [02:30<12:48,  1.25it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1802:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 258/1209 [02:31<05:56,  2.67it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10667896270751953, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715444899.4835107}).444201.9548895}).
Epoch: 1, Loss: 0.1343:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 263/1209 [02:33<05:12,  3.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1071:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 271/1209 [02:36<04:58,  3.14it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1071:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 271/1209 [02:36<04:58,  3.14it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0394:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 276/1209 [02:58<28:14,  1.82s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.5336:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 282/1209 [03:00<07:41,  2.01it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1295:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 288/1209 [03:01<05:13,  2.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.2729:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 294/1209 [03:03<04:54,  3.11it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1517:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 301/1209 [03:06<04:52,  3.10it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0613:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 307/1209 [03:08<04:53,  3.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0286:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 313/1209 [03:10<04:47,  3.12it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0112:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 319/1209 [03:11<04:48,  3.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1173:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 325/1209 [03:14<04:53,  3.01it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0986:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 332/1209 [03:16<04:43,  3.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.4340:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 338/1209 [03:18<04:43,  3.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1628:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 339/1209 [03:18<04:44,  3.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1628:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 339/1209 [03:18<04:44,  3.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0455:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 342/1209 [03:40<48:13,  3.34s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0885:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 348/1209 [03:42<09:43,  1.48it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.2288:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 354/1209 [03:44<05:21,  2.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.2940:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 361/1209 [03:46<04:36,  3.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0111:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 367/1209 [03:48<04:30,  3.11it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0282:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 373/1209 [03:50<04:31,  3.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1807:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 379/1209 [03:52<04:26,  3.11it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.4850:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 386/1209 [03:54<04:21,  3.15it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0471:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 392/1209 [03:56<04:24,  3.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.2833:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 398/1209 [03:58<04:36,  2.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.2605:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 404/1209 [04:00<04:17,  3.12it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.5551:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 407/1209 [04:01<04:19,  3.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.6393:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 409/1209 [04:22<1:01:48,  4.64s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.6393:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 409/1209 [04:22<1:01:48,  4.64s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 1.1889:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 415/1209 [04:24<10:54,  1.21it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1661:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 421/1209 [04:26<05:00,  2.62it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0626:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 427/1209 [04:28<04:42,  2.77it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.6694:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 434/1209 [04:30<04:05,  3.15it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.4041:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                    | 440/1209 [04:32<04:03,  3.16it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1829:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 446/1209 [04:34<03:59,  3.19it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.5534:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 453/1209 [04:36<04:05,  3.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.2835:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 459/1209 [04:38<03:58,  3.14it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.2615:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 465/1209 [04:40<03:55,  3.16it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.6031:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 472/1209 [04:42<03:55,  3.13it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.2351:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 475/1209 [04:43<04:05,  2.99it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.2351:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 475/1209 [04:43<04:05,  2.99it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.2136:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 478/1209 [05:04<39:40,  3.26s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.8797:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 484/1209 [05:06<08:02,  1.50it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.2256:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 490/1209 [05:08<04:17,  2.79it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 1.0218:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 496/1209 [05:10<03:52,  3.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0826:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [05:11<03:51,  3.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0826:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [05:11<03:51,  3.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0826:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [05:11<03:51,  3.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Validation at Global Step: 500, Validation Loss: 0.5974: 100%|â–ˆ| 121/121 [00:03<00:00, 32.95it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
[33m[W 2024-05-11 16:35:26,019][39m Trial 45 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 32.95it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
[33m[W 2024-05-11 16:35:26,019][39m Trial 45 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 32.95it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
An exception occurred:
Returning None...
Returned ESE function. Lanczos order (m) is 76 .
Epoch: 1, Loss: 0.6438:   1%|â–                                 | 7/1209 [00:03<11:04,  1.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 1.1090:   1%|â–Ž                                | 11/1209 [00:06<11:49,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.2619:   1%|â–                                | 14/1209 [00:07<11:15,  1.77it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0813:   1%|â–                                | 18/1209 [00:10<11:05,  1.79it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.2516:   2%|â–Œ                                | 21/1209 [00:11<10:55,  1.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 1.1454:   2%|â–‹                                | 25/1209 [00:13<10:54,  1.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.4685:   2%|â–Š                                | 29/1209 [00:16<10:49,  1.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.2964:   3%|â–Š                                | 32/1209 [00:17<10:46,  1.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.4771:   3%|â–‰                                | 36/1209 [00:20<10:44,  1.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.4115:   3%|â–ˆ                                | 39/1209 [00:21<11:30,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.2453:   4%|â–ˆâ–                               | 43/1209 [00:24<10:51,  1.79it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.3826:   4%|â–ˆâ–Ž                               | 46/1209 [00:25<10:44,  1.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.2702:   4%|â–ˆâ–Ž                               | 50/1209 [00:27<10:45,  1.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1454:   4%|â–ˆâ–                               | 54/1209 [00:30<10:36,  1.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.4958:   5%|â–ˆâ–Œ                               | 58/1209 [00:32<10:33,  1.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.6262:   5%|â–ˆâ–‹                               | 61/1209 [00:33<10:27,  1.83it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.2977:   5%|â–ˆâ–Š                               | 65/1209 [00:36<10:46,  1.77it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.8201:   6%|â–ˆâ–Š                               | 68/1209 [00:37<10:36,  1.79it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.5140:   6%|â–ˆâ–‰                               | 72/1209 [00:40<10:32,  1.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0943:   6%|â–ˆâ–ˆ                               | 76/1209 [00:42<10:25,  1.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.5086:   7%|â–ˆâ–ˆâ–                              | 79/1209 [00:43<10:20,  1.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.2629:   7%|â–ˆâ–ˆâ–Ž                              | 83/1209 [00:46<10:20,  1.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.3998:   7%|â–ˆâ–ˆâ–Ž                              | 87/1209 [00:48<10:16,  1.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.4483:   7%|â–ˆâ–ˆâ–                              | 90/1209 [00:50<10:17,  1.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0809:   8%|â–ˆâ–ˆâ–Œ                              | 94/1209 [00:52<10:15,  1.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0893:   8%|â–ˆâ–ˆâ–‹                              | 98/1209 [00:54<10:09,  1.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0951:   8%|â–ˆâ–ˆâ–‹                             | 101/1209 [00:56<10:07,  1.83it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0555:   9%|â–ˆâ–ˆâ–Š                             | 105/1209 [00:58<10:34,  1.74it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.8829:   9%|â–ˆâ–ˆâ–Š                             | 108/1209 [01:00<10:25,  1.76it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 1.4107:   9%|â–ˆâ–ˆâ–‰                             | 112/1209 [01:02<10:08,  1.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1600:  10%|â–ˆâ–ˆâ–ˆ                             | 116/1209 [01:04<10:02,  1.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.5316:  10%|â–ˆâ–ˆâ–ˆâ–                            | 119/1209 [01:06<09:57,  1.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0856:  10%|â–ˆâ–ˆâ–ˆâ–Ž                            | 123/1209 [01:08<09:56,  1.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1332:  11%|â–ˆâ–ˆâ–ˆâ–Ž                            | 127/1209 [01:10<09:56,  1.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.6268:  11%|â–ˆâ–ˆâ–ˆâ–                            | 130/1209 [01:12<09:55,  1.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1273:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 133/1209 [01:13<09:54,  1.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1273:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 133/1209 [01:13<09:54,  1.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
lambda_max: 8.396130561828613 lrs: tensor([0.9010, 0.8536, 0.8466, 0.8077, 0.7893, 0.7820, 0.7453, 0.7356, 0.7322,
        0.7197, 0.7066, 0.6813, 0.6587, 0.6473, 0.6378, 0.5834, 0.5748, 0.5166,
        0.1191]) eigenvals: tensor([1.1099, 1.1715, 1.1812, 1.2381, 1.2670, 1.2787, 1.3417, 1.3595, 1.3658,
        1.3894, 1.4153, 1.4677, 1.5181, 1.5449, 1.5678, 1.7140, 1.7397, 1.9358,
Epoch: 1, Loss: 0.0692:  11%|â–ˆâ–ˆâ–ˆâ–Ž                          | 136/1209 [04:04<7:34:24, 25.41s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.6552:  11%|â–ˆâ–ˆâ–ˆâ–                          | 139/1209 [04:06<2:42:26,  9.11s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.3183:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 143/1209 [04:08<46:47,  2.63s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1247:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 146/1209 [04:10<22:47,  1.29s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1000:  12%|â–ˆâ–ˆâ–ˆâ–‰                            | 149/1209 [04:12<14:52,  1.19it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1024:  13%|â–ˆâ–ˆâ–ˆâ–ˆ                            | 153/1209 [04:14<11:28,  1.53it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0930:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 156/1209 [04:16<10:47,  1.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1080:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 159/1209 [04:18<10:50,  1.61it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1152:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 162/1209 [04:20<10:50,  1.61it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1026:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 166/1209 [04:22<10:34,  1.64it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1907:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 169/1209 [04:24<10:28,  1.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0439:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 172/1209 [04:26<10:26,  1.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0581:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 176/1209 [04:28<10:21,  1.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0690:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 179/1209 [04:30<10:21,  1.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.9060:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 182/1209 [04:32<10:18,  1.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 1.0234:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                           | 186/1209 [04:34<10:07,  1.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.3403:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 189/1209 [04:36<10:31,  1.61it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.2641:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 192/1209 [04:38<10:04,  1.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.6753:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 196/1209 [04:40<10:00,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1119:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 199/1209 [04:42<09:56,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0813:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 203/1209 [04:44<09:58,  1.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.4182:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 206/1209 [04:46<09:55,  1.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1474:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                          | 209/1209 [04:48<09:54,  1.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.6285:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 213/1209 [04:50<10:10,  1.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.2533:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 216/1209 [04:52<09:58,  1.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.3222:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 219/1209 [04:54<09:48,  1.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.5219:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 224/1209 [04:57<09:47,  1.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0450:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 227/1209 [04:59<09:50,  1.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0330:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 230/1209 [05:01<09:50,  1.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0269:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 233/1209 [05:02<10:01,  1.62it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.3290:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 237/1209 [05:05<09:56,  1.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.2616:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 240/1209 [05:07<10:15,  1.57it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.9488:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 243/1209 [05:09<10:05,  1.59it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.8069:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 246/1209 [05:11<09:40,  1.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.4080:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [05:12<09:44,  1.64it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1084:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 250/1209 [05:17<26:48,  1.68s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 1.2640:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 254/1209 [05:19<13:32,  1.18it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.1176:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 257/1209 [05:21<11:05,  1.43it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.2704:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 260/1209 [05:23<09:56,  1.59it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.0884:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 264/1209 [05:25<09:24,  1.67it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.061810754239559174, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445153.1693118}).44201.9548895}).
Epoch: 1, Loss: 0.3264:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 265/1209 [05:25<09:22,  1.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.3264:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 265/1209 [05:25<09:22,  1.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
lambda_max: 81.55529022216797 lrs: tensor([0.3249, 0.3247, 0.3185, 0.3118, 0.2634, 0.2346, 0.2222, 0.1763, 0.1679,
        0.1418, 0.1373, 0.1040, 0.0932, 0.0749, 0.0700, 0.0676, 0.0486, 0.0342,
        0.0123]) eigenvals: tensor([ 3.0775,  3.0797,  3.1394,  3.2072,  3.7960,  4.2619,  4.5006,  5.6725,
         5.9570,  7.0517,  7.2808,  9.6148, 10.7321, 13.3428, 14.2778, 14.7822,
Epoch: 1, Loss: 0.5819:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 268/1209 [08:05<12:32:24, 47.98s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.5340:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 271/1209 [08:07<4:23:13, 16.84s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0536:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 274/1209 [08:09<1:35:54,  6.16s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 1.4341:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 278/1209 [08:11<29:45,  1.92s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.6282:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 281/1209 [08:13<16:04,  1.04s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1293:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 285/1209 [08:15<10:37,  1.45it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0538:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 288/1209 [08:17<09:34,  1.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1619:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 292/1209 [08:19<09:12,  1.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1190:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 295/1209 [08:21<09:01,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.5788:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 298/1209 [08:23<09:09,  1.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 1.1194:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 301/1209 [08:25<09:37,  1.57it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.3627:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 305/1209 [08:27<09:01,  1.67it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.8353:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 308/1209 [08:29<08:47,  1.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.5522:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 312/1209 [08:31<08:49,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.5129:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 315/1209 [08:33<08:43,  1.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1385:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 319/1209 [08:35<08:38,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.2457:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 322/1209 [08:37<08:34,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.9361:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 325/1209 [08:39<08:34,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.5584:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 329/1209 [08:41<08:29,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0955:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 332/1209 [08:43<08:24,  1.74it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.2221:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 336/1209 [08:45<08:22,  1.74it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.9982:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 339/1209 [08:47<08:21,  1.74it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.3600:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 343/1209 [08:49<08:19,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.7938:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 346/1209 [08:51<08:49,  1.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.6131:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 349/1209 [08:53<08:40,  1.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.2874:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 353/1209 [08:55<08:22,  1.70it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0638:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 356/1209 [08:57<08:15,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.2507:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 360/1209 [08:59<08:23,  1.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.3857:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 363/1209 [09:01<08:18,  1.70it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.2309:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 367/1209 [09:03<08:10,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1915:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 370/1209 [09:05<08:06,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1337:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 374/1209 [09:07<08:02,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1557:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 377/1209 [09:09<08:05,  1.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1616:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 381/1209 [09:11<07:58,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.2528:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 384/1209 [09:13<07:54,  1.74it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.2610:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 388/1209 [09:16<07:50,  1.75it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.3311:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 391/1209 [09:17<07:53,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.2077:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 394/1209 [09:19<07:50,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1609:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 398/1209 [09:21<08:09,  1.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.2146:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 401/1209 [09:23<07:57,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.2146:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 401/1209 [09:23<07:57,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
lambda_max: 10.763374328613281 lrs: tensor([0.6137, 0.6114, 0.6047, 0.5255, 0.4956, 0.4604, 0.4553, 0.4035, 0.3757,
        0.3731, 0.3201, 0.3081, 0.2934, 0.2903, 0.2450, 0.1728, 0.1577, 0.1088,
        0.0929]) eigenvals: tensor([ 1.6296,  1.6357,  1.6538,  1.9030,  2.0178,  2.1720,  2.1966,  2.4783,
         2.6614,  2.6802,  3.1243,  3.2457,  3.4082,  3.4446,  4.0809,  5.7884,
Epoch: 1, Loss: 0.3431:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 405/1209 [12:22<4:10:50, 18.72s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.5742:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 408/1209 [12:23<1:30:46,  6.80s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0428:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 412/1209 [12:26<27:36,  2.08s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0434:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 415/1209 [12:28<14:38,  1.11s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0228:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 419/1209 [12:30<09:20,  1.41it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 1.3096:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 422/1209 [12:32<08:08,  1.61it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0299:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 425/1209 [12:33<07:51,  1.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1698:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 429/1209 [12:36<07:59,  1.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0652:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 432/1209 [12:38<07:36,  1.70it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0995:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 436/1209 [12:40<07:30,  1.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.8058:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 439/1209 [12:42<07:28,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0890:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                    | 442/1209 [12:44<07:34,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0903:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 446/1209 [12:46<07:26,  1.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 1.1030:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 449/1209 [12:48<07:24,  1.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1533:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 452/1209 [12:50<07:59,  1.58it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.3142:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 457/1209 [12:53<07:28,  1.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0497:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 460/1209 [12:54<07:16,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.3319:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 464/1209 [12:57<07:11,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0541:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 467/1209 [12:58<07:17,  1.70it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0326:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 470/1209 [13:00<07:33,  1.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 1.0749:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 474/1209 [13:03<07:15,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.8094:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 477/1209 [13:04<07:12,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0599:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 480/1209 [13:06<07:03,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.8296:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 484/1209 [13:09<07:17,  1.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.5136:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 487/1209 [13:10<07:09,  1.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0840:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 491/1209 [13:13<07:03,  1.70it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1133:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 494/1209 [13:14<06:53,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0643:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 498/1209 [13:17<06:53,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1842:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [13:17<06:54,  1.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1842:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [13:17<06:54,  1.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1842:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [13:17<06:54,  1.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Validation at Global Step: 500, Validation Loss: 0.5151: 100%|â–ˆ| 121/121 [00:03<00:00, 33.39it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Validation at Global Step: 500, Validation Loss: 0.5151: 100%|â–ˆ| 121/121 [00:03<00:00, 33.39it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
An exception occurred:
Returning None...
[33m[W 2024-05-11 16:48:55,303][39m Trial 46 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 33.39it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
[33m[W 2024-05-11 16:48:55,303][39m Trial 46 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 33.39it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1629:   1%|â–                                | 14/1209 [00:05<07:45,  2.57it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0324:   1%|â–                                | 18/1209 [00:07<08:17,  2.39it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.3456:   2%|â–‹                                | 24/1209 [00:09<07:27,  2.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1005:   2%|â–Š                                | 29/1209 [00:11<07:13,  2.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0406:   3%|â–‰                                | 35/1209 [00:13<07:15,  2.70it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0245:   3%|â–ˆ                                | 40/1209 [00:15<07:14,  2.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 1.0033:   4%|â–ˆâ–Ž                               | 46/1209 [00:17<07:11,  2.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0317:   4%|â–ˆâ–                               | 51/1209 [00:19<07:10,  2.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0536:   5%|â–ˆâ–Œ                               | 56/1209 [00:21<07:06,  2.70it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.8193:   5%|â–ˆâ–‹                               | 62/1209 [00:23<07:02,  2.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0821:   6%|â–ˆâ–Š                               | 67/1209 [00:25<07:03,  2.70it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.6683:   6%|â–ˆâ–‰                               | 73/1209 [00:27<07:02,  2.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 1.4892:   6%|â–ˆâ–ˆâ–                              | 78/1209 [00:29<06:59,  2.70it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1308:   7%|â–ˆâ–ˆâ–Ž                              | 84/1209 [00:31<06:55,  2.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0981:   7%|â–ˆâ–ˆâ–                              | 89/1209 [00:33<06:53,  2.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.8243:   8%|â–ˆâ–ˆâ–Œ                              | 95/1209 [00:35<06:48,  2.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0810:   8%|â–ˆâ–ˆâ–‹                             | 100/1209 [00:37<06:58,  2.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.8396:   9%|â–ˆâ–ˆâ–Š                             | 105/1209 [00:39<06:49,  2.70it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1254:   9%|â–ˆâ–ˆâ–‰                             | 110/1209 [00:41<06:45,  2.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.2047:  10%|â–ˆâ–ˆâ–ˆ                             | 116/1209 [00:43<07:02,  2.59it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.6002:  10%|â–ˆâ–ˆâ–ˆ                             | 117/1209 [00:44<07:15,  2.51it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.6002:  10%|â–ˆâ–ˆâ–ˆ                             | 117/1209 [00:44<07:15,  2.51it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
lambda_max: 272.5270690917969 lrs: tensor([0.0183, 0.0171, 0.0140, 0.0131, 0.0111, 0.0067, 0.0049, 0.0037]) eigenvals: tensor([ 54.5590,  58.6007,  71.3047,  76.2364,  90.3350, 148.8584, 204.8587,
Epoch: 1, Loss: 0.1233:  10%|â–ˆâ–ˆâ–ˆâ–                            | 122/1209 [01:21<53:29,  2.95s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1198:  11%|â–ˆâ–ˆâ–ˆâ–Ž                            | 127/1209 [01:23<14:17,  1.26it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.5709:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 133/1209 [01:25<07:34,  2.37it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1774:  11%|â–ˆâ–ˆâ–ˆâ–‹                            | 138/1209 [01:27<06:44,  2.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.9099:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 144/1209 [01:29<06:20,  2.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.3021:  12%|â–ˆâ–ˆâ–ˆâ–‰                            | 149/1209 [01:31<06:59,  2.53it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0498:  13%|â–ˆâ–ˆâ–ˆâ–ˆ                            | 154/1209 [01:33<06:54,  2.54it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0441:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 159/1209 [01:35<06:18,  2.77it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1710:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 165/1209 [01:37<06:21,  2.74it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0405:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 170/1209 [01:39<06:21,  2.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0534:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 176/1209 [01:41<06:05,  2.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0271:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 182/1209 [01:43<06:09,  2.78it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.2496:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                           | 187/1209 [01:45<06:04,  2.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0434:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 193/1209 [01:47<06:24,  2.64it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.8854:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 198/1209 [01:49<06:08,  2.75it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.2434:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 204/1209 [01:51<06:08,  2.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.7475:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                          | 209/1209 [01:53<05:56,  2.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1254:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 215/1209 [01:55<05:49,  2.85it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.8945:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 221/1209 [01:57<05:49,  2.83it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 1.0844:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 226/1209 [01:59<05:44,  2.86it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1040:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 231/1209 [02:01<06:18,  2.58it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.8479:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 235/1209 [02:03<05:57,  2.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1755:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 238/1209 [02:43<1:40:09,  6.19s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1755:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 238/1209 [02:43<1:40:09,  6.19s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
lambda_max: 210.5087890625 lrs: tensor([0.0330, 0.0236, 0.0225, 0.0186, 0.0105, 0.0096, 0.0055, 0.0048]) eigenvals: tensor([ 30.2973,  42.4155,  44.4972,  53.8079,  94.9540, 104.0150, 181.3764,
Epoch: 1, Loss: 0.1434:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 243/1209 [02:45<21:51,  1.36s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1264:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [02:48<07:55,  2.02it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.1382:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 255/1209 [02:54<09:12,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.9132:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 260/1209 [02:55<06:36,  2.39it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.10841971635818481, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715445643.214875}).).44201.9548895}).
Epoch: 1, Loss: 0.0407:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 262/1209 [02:56<06:18,  2.50it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.1085:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 271/1209 [03:00<05:57,  2.62it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0437:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 276/1209 [03:02<05:56,  2.61it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0650:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 281/1209 [03:03<05:49,  2.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0504:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 286/1209 [03:05<05:52,  2.62it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0199:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 292/1209 [03:08<05:55,  2.58it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0389:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 297/1209 [03:10<05:43,  2.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0892:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 302/1209 [03:11<05:47,  2.61it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0360:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 307/1209 [03:13<05:47,  2.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.4157:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 313/1209 [03:16<05:39,  2.64it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0015:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 318/1209 [03:18<05:46,  2.57it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0858:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 323/1209 [03:20<05:36,  2.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.3174:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 328/1209 [03:22<05:55,  2.48it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0309:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 333/1209 [03:23<05:35,  2.61it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.4152:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 339/1209 [03:26<05:32,  2.62it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0485:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 344/1209 [03:28<05:25,  2.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0162:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 349/1209 [03:29<05:17,  2.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.3644:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 353/1209 [03:31<05:16,  2.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.3644:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 353/1209 [03:31<05:16,  2.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
lambda_max: 1490.0537109375 lrs: tensor([9.7615e-01, 1.9724e-01, 1.8443e-01, 1.0998e-01, 6.4952e-03, 2.6324e-03,
        9.4465e-04, 6.7112e-04]) eigenvals: tensor([1.0244e+00, 5.0699e+00, 5.4221e+00, 9.0930e+00, 1.5396e+02, 3.7988e+02,
Epoch: 1, Loss: 1.9015:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 358/1209 [04:08<41:09,  2.90s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.8802:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 363/1209 [04:10<11:12,  1.26it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 1.2360:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 368/1209 [04:12<06:38,  2.11it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0638:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 373/1209 [04:14<05:27,  2.55it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0552:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 379/1209 [04:16<05:15,  2.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.1733:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 384/1209 [04:18<05:21,  2.57it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 1.9297:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 389/1209 [04:20<05:07,  2.67it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.6184:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 394/1209 [04:22<05:39,  2.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.5019:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 399/1209 [04:24<05:24,  2.50it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 1.1118:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 404/1209 [04:26<05:10,  2.59it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.5613:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 409/1209 [04:28<05:15,  2.54it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0725:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 415/1209 [04:30<04:58,  2.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.1773:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 420/1209 [04:32<04:57,  2.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.1812:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 425/1209 [04:34<04:51,  2.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.9241:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 430/1209 [04:36<05:16,  2.46it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0811:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 436/1209 [04:38<04:56,  2.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0940:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                    | 441/1209 [04:40<04:52,  2.62it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.1096:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 446/1209 [04:42<04:49,  2.64it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.5396:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 451/1209 [04:44<04:54,  2.57it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0846:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 457/1209 [04:46<04:43,  2.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0563:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 462/1209 [04:48<04:43,  2.64it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 1.6818:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 467/1209 [04:50<04:37,  2.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.1342:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 471/1209 [04:51<04:51,  2.54it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.1342:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 471/1209 [04:51<04:51,  2.54it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
lambda_max: 984.8755493164062 lrs: tensor([0.0052, 0.0050, 0.0030, 0.0020, 0.0020, 0.0013, 0.0011, 0.0010]) eigenvals: tensor([190.8653, 199.9356, 328.8915, 496.4767, 500.2322, 775.0806, 893.7956,
Epoch: 1, Loss: 0.7812:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 472/1209 [05:32<2:33:13, 12.47s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.7548:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 477/1209 [05:34<29:17,  2.40s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0697:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 483/1209 [05:36<07:32,  1.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0929:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 488/1209 [05:38<04:59,  2.41it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0756:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 495/1209 [05:41<04:21,  2.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0856:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [05:42<04:19,  2.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0856:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [05:42<04:19,  2.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0856:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [05:42<04:19,  2.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Validation at Global Step: 500, Validation Loss: 0.7695: 100%|â–ˆ| 121/121 [00:03<00:00, 31.09it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Validation at Global Step: 500, Validation Loss: 0.7695: 100%|â–ˆ| 121/121 [00:03<00:00, 31.09it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
An exception occurred:
Returning None...
[33m[W 2024-05-11 16:54:49,350][39m Trial 47 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 31.09it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
[33m[W 2024-05-11 16:54:49,350][39m Trial 47 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 31.09it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0804:   1%|â–                                | 14/1209 [00:04<06:21,  3.13it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.6380:   2%|â–Œ                                | 20/1209 [00:06<06:44,  2.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.9124:   2%|â–‹                                | 27/1209 [00:08<06:31,  3.02it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.8328:   3%|â–‰                                | 33/1209 [00:10<06:24,  3.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.6023:   3%|â–ˆ                                | 38/1209 [00:12<07:00,  2.78it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0852:   4%|â–ˆâ–                               | 44/1209 [00:14<06:49,  2.84it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.1206:   4%|â–ˆâ–Ž                               | 50/1209 [00:16<06:45,  2.86it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0815:   5%|â–ˆâ–Œ                               | 56/1209 [00:18<06:13,  3.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0657:   5%|â–ˆâ–‹                               | 62/1209 [00:20<06:07,  3.12it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.6246:   6%|â–ˆâ–Š                               | 68/1209 [00:22<06:12,  3.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.4066:   6%|â–ˆâ–ˆ                               | 75/1209 [00:24<06:09,  3.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.4592:   7%|â–ˆâ–ˆâ–                              | 81/1209 [00:26<06:19,  2.97it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.6637:   7%|â–ˆâ–ˆâ–Ž                              | 86/1209 [00:28<06:47,  2.76it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.2208:   8%|â–ˆâ–ˆâ–Œ                              | 92/1209 [00:30<06:37,  2.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0990:   8%|â–ˆâ–ˆâ–‹                              | 97/1209 [00:32<06:29,  2.86it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.4767:   9%|â–ˆâ–ˆâ–Š                             | 104/1209 [00:34<05:49,  3.16it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.9316:   9%|â–ˆâ–ˆâ–‰                             | 110/1209 [00:36<05:50,  3.14it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.4189:  10%|â–ˆâ–ˆâ–ˆ                             | 116/1209 [00:38<05:54,  3.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.1137:  10%|â–ˆâ–ˆâ–ˆâ–Ž                            | 123/1209 [00:40<05:47,  3.13it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.5164:  11%|â–ˆâ–ˆâ–ˆâ–                            | 129/1209 [00:42<05:46,  3.12it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.2752:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 135/1209 [00:44<05:39,  3.16it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.5065:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 142/1209 [00:47<05:39,  3.14it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0989:  12%|â–ˆâ–ˆâ–ˆâ–‰                            | 147/1209 [00:48<05:55,  2.99it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0688:  13%|â–ˆâ–ˆâ–ˆâ–ˆ                            | 154/1209 [00:51<05:37,  3.13it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.1040:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 160/1209 [00:52<05:33,  3.14it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0137:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 166/1209 [00:54<05:42,  3.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.1466:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 172/1209 [00:57<06:00,  2.88it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0658:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 178/1209 [00:59<05:48,  2.95it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.1352:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 184/1209 [01:01<05:33,  3.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.3938:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                           | 186/1209 [01:01<05:26,  3.14it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.3938:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                           | 186/1209 [01:01<05:26,  3.14it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0202:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 190/1209 [01:28<51:12,  3.02s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.1248:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 196/1209 [01:31<11:16,  1.50it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.1199:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 201/1209 [01:32<06:49,  2.46it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 1.0767:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                          | 208/1209 [01:35<06:07,  2.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.5256:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 213/1209 [01:37<05:42,  2.91it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.6030:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 218/1209 [01:39<06:14,  2.64it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.4643:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 225/1209 [01:41<05:50,  2.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.3682:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 230/1209 [01:43<05:56,  2.74it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.1370:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 236/1209 [01:45<05:39,  2.87it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.4685:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 242/1209 [01:47<05:53,  2.74it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.2322:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 247/1209 [01:49<05:53,  2.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.2238:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [01:50<05:40,  2.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.11509691178798676, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.2238:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [01:50<05:40,  2.82it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.1138:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 255/1209 [01:55<08:16,  1.92it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0507:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 261/1209 [01:57<05:47,  2.73it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.6934:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 266/1209 [01:59<05:29,  2.86it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.4676:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 272/1209 [02:01<05:27,  2.86it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.446307.6849911})..44201.9548895}).
Epoch: 1, Loss: 0.0535:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 275/1209 [02:02<05:27,  2.85it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.0319:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 283/1209 [02:05<05:40,  2.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.2530:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 289/1209 [02:07<05:27,  2.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.1356:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 294/1209 [02:09<05:41,  2.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.1024:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 300/1209 [02:11<05:19,  2.84it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.0393:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 305/1209 [02:13<05:27,  2.76it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.0414:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 311/1209 [02:15<05:15,  2.85it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.3388:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 316/1209 [02:17<05:17,  2.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.0290:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 321/1209 [02:19<05:13,  2.83it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.0837:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 327/1209 [02:21<05:07,  2.86it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.0756:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 332/1209 [02:23<05:05,  2.87it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.0819:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 338/1209 [02:25<05:03,  2.87it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.0851:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 344/1209 [02:27<05:16,  2.74it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.3447:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 349/1209 [02:29<05:07,  2.79it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.0794:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 355/1209 [02:31<05:02,  2.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.0704:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 361/1209 [02:33<05:03,  2.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.0944:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 367/1209 [02:35<04:59,  2.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.7209:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 372/1209 [02:37<04:52,  2.86it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.0613:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 373/1209 [02:37<04:54,  2.83it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.0613:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 373/1209 [02:37<04:54,  2.83it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.0774:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 377/1209 [03:03<39:43,  2.86s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.0489:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 383/1209 [03:05<08:56,  1.54it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.0668:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 388/1209 [03:07<05:49,  2.35it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.0672:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 394/1209 [03:09<04:53,  2.78it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 1.2584:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 399/1209 [03:11<04:52,  2.77it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.0640:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 405/1209 [03:13<04:53,  2.74it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.1993:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 410/1209 [03:15<04:42,  2.83it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.1551:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 416/1209 [03:17<04:37,  2.86it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.1186:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 422/1209 [03:19<04:35,  2.86it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.5338:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 428/1209 [03:21<04:34,  2.85it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.4724:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 433/1209 [03:23<04:34,  2.83it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.2428:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 439/1209 [03:25<04:29,  2.85it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.4642:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 445/1209 [03:27<04:35,  2.77it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.1034:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 450/1209 [03:29<04:27,  2.84it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.4094:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 456/1209 [03:31<04:36,  2.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 1.1957:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 462/1209 [03:33<04:21,  2.86it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.1276:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 467/1209 [03:35<04:17,  2.88it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.1361:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 473/1209 [03:37<04:15,  2.88it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.0918:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 479/1209 [03:39<04:14,  2.87it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.3412:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 485/1209 [03:41<04:15,  2.83it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.4786:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 490/1209 [03:43<04:15,  2.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.3723:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 496/1209 [03:45<04:07,  2.88it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.1964:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [03:46<04:08,  2.86it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.6353738307952881, 'F1_Macro/Train': 0.0, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 0.0, 'RECALL/Train': 0.0, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715446603.5616546}).44201.9548895}).
Epoch: 1, Loss: 0.1964:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [03:46<04:08,  2.86it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.1964:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [03:46<04:08,  2.86it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Validation at Global Step: 500, Validation Loss: 1.9830: 100%|â–ˆ| 121/121 [00:03<00:00, 33.47it/s/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
[33m[W 2024-05-11 16:58:47,245][39m Trial 48 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 33.47it/s/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
[33m[W 2024-05-11 16:58:47,245][39m Trial 48 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 33.47it/s/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
An exception occurred:
Returning None...
Returned ESE function. Lanczos order (m) is 28 .
Epoch: 1, Loss: 0.0001:   1%|â–Ž                                 | 9/1209 [00:03<08:13,  2.43it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0004:   1%|â–                                | 14/1209 [00:05<08:13,  2.42it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0355:   2%|â–Œ                                | 19/1209 [00:07<08:00,  2.47it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.4965:   2%|â–‹                                | 24/1209 [00:10<08:43,  2.26it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 1.9161:   2%|â–Š                                | 28/1209 [00:11<08:22,  2.35it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0705:   3%|â–‰                                | 33/1209 [00:13<07:55,  2.48it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 1.4817:   3%|â–ˆ                                | 38/1209 [00:15<08:04,  2.42it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.1039:   4%|â–ˆâ–                               | 43/1209 [00:17<07:56,  2.45it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.1357:   4%|â–ˆâ–Ž                               | 48/1209 [00:19<07:48,  2.48it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 1.4960:   4%|â–ˆâ–                               | 53/1209 [00:21<07:50,  2.46it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.2526:   5%|â–ˆâ–Œ                               | 58/1209 [00:23<07:48,  2.46it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0740:   5%|â–ˆâ–‹                               | 63/1209 [00:25<07:39,  2.49it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.5570:   6%|â–ˆâ–Š                               | 68/1209 [00:28<07:44,  2.45it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.6320:   6%|â–ˆâ–‰                               | 73/1209 [00:30<07:43,  2.45it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0631:   6%|â–ˆâ–ˆâ–                              | 78/1209 [00:32<07:32,  2.50it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0873:   7%|â–ˆâ–ˆâ–Ž                              | 83/1209 [00:34<07:41,  2.44it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.1509:   7%|â–ˆâ–ˆâ–                              | 88/1209 [00:36<07:39,  2.44it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0695:   8%|â–ˆâ–ˆâ–Œ                              | 93/1209 [00:38<07:32,  2.47it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.1009:   8%|â–ˆâ–ˆâ–‹                              | 97/1209 [00:39<07:32,  2.46it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0328:   8%|â–ˆâ–ˆâ–‹                             | 102/1209 [00:41<07:23,  2.50it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0773:   9%|â–ˆâ–ˆâ–Š                             | 107/1209 [00:43<07:33,  2.43it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0249:   9%|â–ˆâ–ˆâ–‰                             | 112/1209 [00:45<07:27,  2.45it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0219:  10%|â–ˆâ–ˆâ–ˆ                             | 117/1209 [00:47<07:19,  2.49it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 1.0534:  10%|â–ˆâ–ˆâ–ˆâ–                            | 122/1209 [00:50<07:27,  2.43it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.1123:  11%|â–ˆâ–ˆâ–ˆâ–Ž                            | 127/1209 [00:52<07:27,  2.42it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0877:  11%|â–ˆâ–ˆâ–ˆâ–                            | 132/1209 [00:54<07:11,  2.50it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.4120:  11%|â–ˆâ–ˆâ–ˆâ–‹                            | 137/1209 [00:56<07:16,  2.46it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0793:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 142/1209 [00:58<07:16,  2.44it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.1303:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 146/1209 [00:59<07:48,  2.27it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.1699:  12%|â–ˆâ–ˆâ–ˆâ–‰                            | 151/1209 [01:01<07:15,  2.43it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.4476:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 156/1209 [01:04<07:07,  2.46it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.1160:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 161/1209 [01:06<07:07,  2.45it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.2562:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 165/1209 [01:07<07:01,  2.48it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0772:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                         | 167/1209 [01:38<1:55:40,  6.66s/it]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0772:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                         | 167/1209 [01:38<1:55:40,  6.66s/it]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
lambda_max: 3976.4970703125 lrs: tensor([0.0597, 0.0453, 0.0268, 0.0138, 0.0057, 0.0024, 0.0003]) eigenvals: tensor([  16.7421,   22.0890,   37.2441,   72.6530,  174.7324,  417.3120,
Epoch: 1, Loss: 0.7652:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 172/1209 [01:40<24:58,  1.45s/it]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.1681:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 177/1209 [01:42<09:43,  1.77it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.2889:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 182/1209 [01:44<07:26,  2.30it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.6501:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                           | 187/1209 [01:46<06:46,  2.52it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.8165:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 192/1209 [01:48<06:42,  2.53it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0770:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 197/1209 [01:50<06:44,  2.50it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0520:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 202/1209 [01:52<06:37,  2.53it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0620:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 207/1209 [01:54<06:33,  2.55it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0653:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 213/1209 [01:56<06:31,  2.54it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.1698:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 217/1209 [01:58<06:34,  2.51it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0417:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 223/1209 [02:00<06:30,  2.53it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0962:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 228/1209 [02:02<06:24,  2.55it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.8487:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 233/1209 [02:04<06:24,  2.54it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0466:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 238/1209 [02:06<06:19,  2.56it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.0243:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 243/1209 [02:08<06:17,  2.56it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.9380:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 248/1209 [02:10<06:30,  2.46it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.2923:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [02:10<06:37,  2.41it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.2435:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 254/1209 [02:16<10:38,  1.50it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.1418:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 259/1209 [02:18<06:58,  2.27it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.46}).44201.9548895}).
Epoch: 1, Loss: 0.7467:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 262/1209 [02:19<06:24,  2.46it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0518:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 269/1209 [02:22<06:14,  2.51it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0657:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 274/1209 [02:24<06:06,  2.55it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0655:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 279/1209 [02:26<06:02,  2.57it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.6853:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 284/1209 [02:28<06:06,  2.52it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0597:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 289/1209 [02:30<06:26,  2.38it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 1.3594:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 294/1209 [02:32<05:59,  2.54it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0608:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 299/1209 [02:34<06:03,  2.51it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.1167:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 304/1209 [02:36<05:56,  2.54it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.7077:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 309/1209 [02:38<05:57,  2.51it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0956:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 315/1209 [02:40<05:51,  2.54it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.1105:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 320/1209 [02:42<05:53,  2.51it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.5726:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 325/1209 [02:44<05:47,  2.55it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0246:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 330/1209 [02:46<05:42,  2.56it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0240:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 331/1209 [02:46<05:44,  2.55it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0240:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 331/1209 [02:46<05:44,  2.55it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0333:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 334/1209 [03:20<1:15:29,  5.18s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.1636:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 339/1209 [03:22<17:33,  1.21s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0369:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 344/1209 [03:24<07:53,  1.83it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.7507:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 349/1209 [03:26<06:09,  2.33it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0366:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 353/1209 [03:28<05:56,  2.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0252:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 358/1209 [03:30<05:49,  2.44it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.8642:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 363/1209 [03:32<05:44,  2.45it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0513:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 368/1209 [03:34<05:48,  2.42it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0786:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 373/1209 [03:36<06:01,  2.31it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.2414:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 377/1209 [03:38<06:01,  2.30it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0622:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 382/1209 [03:40<05:45,  2.39it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0980:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 387/1209 [03:42<05:41,  2.41it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0619:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 392/1209 [03:44<05:49,  2.34it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0765:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 397/1209 [03:46<05:37,  2.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.6856:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 402/1209 [03:48<05:33,  2.42it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.6825:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 406/1209 [03:50<05:32,  2.41it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0594:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 411/1209 [03:52<05:29,  2.42it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0692:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 416/1209 [03:54<05:27,  2.42it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.2351:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 421/1209 [03:56<05:23,  2.44it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 1.8380:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 426/1209 [03:58<05:23,  2.42it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.1752:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 431/1209 [04:00<05:19,  2.43it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.1344:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 436/1209 [04:02<05:21,  2.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.6324:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                    | 440/1209 [04:04<05:19,  2.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.1395:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 445/1209 [04:06<05:15,  2.42it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0825:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 450/1209 [04:08<05:17,  2.39it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.1524:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 455/1209 [04:10<05:14,  2.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0596:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 460/1209 [04:12<05:13,  2.39it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0373:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 465/1209 [04:15<05:13,  2.37it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0332:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 469/1209 [04:16<05:10,  2.38it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0385:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 474/1209 [04:18<05:09,  2.38it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.1329:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 479/1209 [04:20<05:00,  2.43it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0604:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 484/1209 [04:22<04:58,  2.43it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.4228:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 489/1209 [04:25<04:58,  2.41it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.6302:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 494/1209 [04:27<04:56,  2.41it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.8679:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 497/1209 [04:28<05:00,  2.37it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.8679:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 497/1209 [04:28<05:00,  2.37it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.7455:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 499/1209 [05:00<1:23:41,  7.07s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.7455:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 499/1209 [05:00<1:23:41,  7.07s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.7455:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 499/1209 [05:00<1:23:41,  7.07s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Validation at Global Step: 500, Validation Loss: 1.3791: 100%|â–ˆ| 121/121 [00:03<00:00, 33.10it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Validation at Global Step: 500, Validation Loss: 1.3791: 100%|â–ˆ| 121/121 [00:03<00:00, 33.10it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
An exception occurred:
Returning None...
[33m[W 2024-05-11 17:03:59,928][39m Trial 49 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 33.10it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
[33m[W 2024-05-11 17:03:59,928][39m Trial 49 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 33.10it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 1.0998:   1%|â–Ž                                | 10/1209 [00:04<08:47,  2.27it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.6005:   1%|â–                                | 15/1209 [00:06<08:50,  2.25it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0901:   2%|â–Œ                                | 19/1209 [00:08<08:37,  2.30it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0664:   2%|â–‹                                | 24/1209 [00:10<08:28,  2.33it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0686:   2%|â–Š                                | 29/1209 [00:12<08:22,  2.35it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.4425:   3%|â–‰                                | 33/1209 [00:14<08:18,  2.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.1311:   3%|â–ˆ                                | 38/1209 [00:16<09:02,  2.16it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.3700:   3%|â–ˆâ–                               | 42/1209 [00:18<08:29,  2.29it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0448:   4%|â–ˆâ–Ž                               | 47/1209 [00:20<08:30,  2.28it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.1615:   4%|â–ˆâ–                               | 52/1209 [00:22<08:13,  2.35it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.3215:   5%|â–ˆâ–Œ                               | 56/1209 [00:24<08:12,  2.34it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.1474:   5%|â–ˆâ–‹                               | 61/1209 [00:26<08:05,  2.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.9109:   5%|â–ˆâ–Š                               | 66/1209 [00:28<08:10,  2.33it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.2139:   6%|â–ˆâ–‰                               | 71/1209 [00:30<08:00,  2.37it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0467:   6%|â–ˆâ–ˆ                               | 75/1209 [00:32<07:56,  2.38it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.7922:   7%|â–ˆâ–ˆâ–                              | 80/1209 [00:34<08:02,  2.34it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0489:   7%|â–ˆâ–ˆâ–Ž                              | 85/1209 [00:36<07:55,  2.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.1754:   7%|â–ˆâ–ˆâ–                              | 90/1209 [00:38<07:59,  2.33it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0001:   8%|â–ˆâ–ˆâ–Œ                              | 94/1209 [00:40<07:53,  2.35it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0535:   8%|â–ˆâ–ˆâ–‹                              | 99/1209 [00:42<07:57,  2.33it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.5432:   9%|â–ˆâ–ˆâ–Š                             | 104/1209 [00:44<07:51,  2.34it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0373:   9%|â–ˆâ–ˆâ–Š                             | 108/1209 [00:46<08:48,  2.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.2324:   9%|â–ˆâ–ˆâ–‰                             | 113/1209 [00:48<08:05,  2.26it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0782:  10%|â–ˆâ–ˆâ–ˆ                             | 117/1209 [00:50<07:46,  2.34it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.1527:  10%|â–ˆâ–ˆâ–ˆâ–                            | 122/1209 [00:52<07:38,  2.37it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0072:  11%|â–ˆâ–ˆâ–ˆâ–Ž                            | 127/1209 [00:54<07:31,  2.39it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0806:  11%|â–ˆâ–ˆâ–ˆâ–                            | 132/1209 [00:56<07:32,  2.38it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.4547:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 136/1209 [00:58<07:30,  2.38it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0875:  12%|â–ˆâ–ˆâ–ˆâ–‹                            | 141/1209 [01:00<07:34,  2.35it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 2.2070:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 146/1209 [01:02<07:29,  2.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0794:  12%|â–ˆâ–ˆâ–ˆâ–‰                            | 151/1209 [01:05<07:30,  2.35it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.1087:  13%|â–ˆâ–ˆâ–ˆâ–ˆ                            | 155/1209 [01:06<07:24,  2.37it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.5857:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 160/1209 [01:08<07:19,  2.39it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0982:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 165/1209 [01:10<07:15,  2.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.2190:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 170/1209 [01:13<07:28,  2.32it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.1327:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 174/1209 [01:14<07:21,  2.34it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0923:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 179/1209 [01:16<07:48,  2.20it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0517:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 184/1209 [01:19<07:18,  2.34it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0312:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                           | 188/1209 [01:20<07:12,  2.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0530:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 193/1209 [01:22<07:09,  2.37it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0528:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 194/1209 [01:23<07:09,  2.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0244:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 195/1209 [02:17<4:37:46, 16.44s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0244:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 195/1209 [02:17<4:37:46, 16.44s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
lambda_max: 30.668718338012695 lrs: tensor([0.4127, 0.2795, 0.2578, 0.1813, 0.1798, 0.0545, 0.0436, 0.0378, 0.0367,
        0.0326]) eigenvals: tensor([ 2.4228,  3.5775,  3.8792,  5.5169,  5.5611, 18.3382, 22.9286, 26.4459,
Epoch: 1, Loss: 0.0430:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 200/1209 [02:19<52:16,  3.11s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.3421:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 204/1209 [02:20<17:46,  1.06s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0201:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                          | 209/1209 [02:22<08:47,  1.89it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.4798:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 214/1209 [02:24<07:07,  2.32it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.5152:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 219/1209 [02:27<06:55,  2.38it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0107:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 224/1209 [02:29<06:50,  2.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.3781:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 229/1209 [02:31<06:41,  2.44it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.4784:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 233/1209 [02:32<07:14,  2.25it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0550:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 238/1209 [02:35<06:56,  2.33it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 1.3727:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 243/1209 [02:37<06:51,  2.35it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0393:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 247/1209 [02:38<06:38,  2.41it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.4660:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [02:39<06:35,  2.43it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 1.4054:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 251/1209 [02:45<21:01,  1.32s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0158:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 256/1209 [02:47<09:09,  1.74it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.3304:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 261/1209 [02:49<06:57,  2.27it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 1.0103:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 266/1209 [02:51<06:40,  2.35it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.043640293180942535, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715446862.3788257}).44201.9548895}).
Epoch: 1, Loss: 0.0487:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 268/1209 [02:52<06:29,  2.42it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0733:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 276/1209 [02:55<06:25,  2.42it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.3960:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 280/1209 [02:57<06:28,  2.39it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 1.0824:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 285/1209 [02:59<06:23,  2.41it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.3629:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 291/1209 [03:01<06:28,  2.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.2456:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 296/1209 [03:03<06:27,  2.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.3424:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 301/1209 [03:05<06:17,  2.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.2003:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 306/1209 [03:07<06:09,  2.44it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0884:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 310/1209 [03:09<06:11,  2.42it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0645:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 315/1209 [03:11<06:07,  2.43it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0405:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 320/1209 [03:13<06:15,  2.37it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.2540:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 325/1209 [03:15<06:08,  2.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0174:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 329/1209 [03:17<06:32,  2.24it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0222:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 334/1209 [03:19<06:09,  2.37it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0518:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 339/1209 [03:21<06:19,  2.29it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 1.4266:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 343/1209 [03:23<06:09,  2.35it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 2.0129:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 348/1209 [03:25<06:14,  2.30it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0903:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 353/1209 [03:28<06:02,  2.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0877:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 357/1209 [03:29<05:54,  2.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.1229:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 362/1209 [03:31<06:17,  2.25it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0754:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 367/1209 [03:33<05:50,  2.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0603:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 372/1209 [03:35<05:48,  2.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0711:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 377/1209 [03:38<05:45,  2.41it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0432:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 381/1209 [03:39<05:40,  2.43it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0720:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 386/1209 [03:41<05:50,  2.35it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0581:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 389/1209 [03:43<06:03,  2.26it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.7773:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 393/1209 [04:36<1:17:26,  5.69s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.7773:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 393/1209 [04:36<1:17:26,  5.69s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
lambda_max: 121.7716064453125 lrs: tensor([0.0730, 0.0571, 0.0453, 0.0419, 0.0379, 0.0255, 0.0228, 0.0182, 0.0100,
        0.0082]) eigenvals: tensor([ 13.6953,  17.5062,  22.0765,  23.8905,  26.3591,  39.1808,  43.8586,
Epoch: 1, Loss: 0.0753:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 398/1209 [04:38<17:26,  1.29s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0723:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 403/1209 [04:40<07:24,  1.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.5816:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 408/1209 [04:42<05:45,  2.32it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.1326:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 413/1209 [04:44<05:19,  2.49it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.4554:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 418/1209 [04:46<05:19,  2.48it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0852:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 422/1209 [04:47<05:29,  2.39it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.5976:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 427/1209 [04:49<05:23,  2.42it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.1981:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 432/1209 [04:51<05:16,  2.46it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.2129:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 437/1209 [04:54<05:23,  2.38it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.1611:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                    | 441/1209 [04:55<05:35,  2.29it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0295:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 446/1209 [04:57<05:18,  2.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0626:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 451/1209 [04:59<05:07,  2.46it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.1030:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 456/1209 [05:02<05:24,  2.32it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0767:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 461/1209 [05:04<05:17,  2.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.4191:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 465/1209 [05:05<05:20,  2.32it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0937:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 470/1209 [05:08<05:22,  2.29it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0953:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 475/1209 [05:10<05:06,  2.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.1022:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 480/1209 [05:12<04:59,  2.43it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0594:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 485/1209 [05:14<04:57,  2.44it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0277:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 489/1209 [05:15<04:53,  2.45it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0542:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 494/1209 [05:18<04:56,  2.41it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0195:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [05:20<04:42,  2.51it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.03860821947455406, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715447204.5183759})..44201.9548895}).
Epoch: 1, Loss: 0.0195:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [05:20<04:42,  2.51it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0195:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [05:20<04:42,  2.51it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Validation at Global Step: 500, Validation Loss: 0.8520: 100%|â–ˆ| 121/121 [00:03<00:00, 33.50it/s/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
[33m[W 2024-05-11 17:09:31,364][39m Trial 50 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 33.50it/s/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
[33m[W 2024-05-11 17:09:31,364][39m Trial 50 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 33.50it/s/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
An exception occurred:
Returning None...
Returned ESE function. Lanczos order (m) is 48 .
Epoch: 1, Loss: 0.0155:   1%|â–Ž                                | 11/1209 [00:04<09:00,  2.21it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.7158:   1%|â–                                | 15/1209 [00:06<08:58,  2.22it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0310:   2%|â–Œ                                | 20/1209 [00:09<08:52,  2.23it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0336:   2%|â–‹                                | 24/1209 [00:10<08:53,  2.22it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0454:   2%|â–Š                                | 29/1209 [00:13<08:43,  2.25it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.1068:   3%|â–‰                                | 33/1209 [00:14<08:43,  2.25it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0522:   3%|â–ˆ                                | 38/1209 [00:17<08:50,  2.21it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0461:   3%|â–ˆâ–                               | 42/1209 [00:18<08:39,  2.25it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0609:   4%|â–ˆâ–Ž                               | 46/1209 [00:20<08:37,  2.25it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.1090:   4%|â–ˆâ–                               | 51/1209 [00:22<08:36,  2.24it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0760:   5%|â–ˆâ–Œ                               | 56/1209 [00:25<08:34,  2.24it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0226:   5%|â–ˆâ–‹                               | 60/1209 [00:26<08:30,  2.25it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0463:   5%|â–ˆâ–Š                               | 65/1209 [00:29<08:27,  2.25it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.6608:   6%|â–ˆâ–Š                               | 67/1209 [00:29<08:41,  2.19it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.6608:   6%|â–ˆâ–Š                               | 67/1209 [00:29<08:41,  2.19it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
lambda_max: 7815.10693359375 lrs: tensor([0.1235, 0.1219, 0.1203, 0.0854, 0.0302, 0.0132, 0.0102, 0.0054, 0.0025,
        0.0018, 0.0008, 0.0001]) eigenvals: tensor([   8.0992,    8.2026,    8.3096,   11.7153,   33.0609,   75.5039,
Epoch: 1, Loss: 0.0234:   6%|â–ˆâ–Š                             | 71/1209 [01:44<2:30:06,  7.91s/it]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0686:   6%|â–ˆâ–ˆ                               | 76/1209 [01:46<32:18,  1.71s/it]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0303:   7%|â–ˆâ–ˆâ–                              | 80/1209 [01:48<13:57,  1.35it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0787:   7%|â–ˆâ–ˆâ–Ž                              | 85/1209 [01:50<09:12,  2.03it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.6203:   7%|â–ˆâ–ˆâ–                              | 89/1209 [01:52<08:22,  2.23it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0089:   8%|â–ˆâ–ˆâ–Œ                              | 94/1209 [01:54<08:14,  2.26it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0868:   8%|â–ˆâ–ˆâ–‹                              | 99/1209 [01:56<08:00,  2.31it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.1951:   9%|â–ˆâ–ˆâ–‹                             | 103/1209 [01:58<08:02,  2.29it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0907:   9%|â–ˆâ–ˆâ–Š                             | 108/1209 [02:00<08:09,  2.25it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0049:   9%|â–ˆâ–ˆâ–‰                             | 112/1209 [02:02<08:12,  2.23it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.4608:  10%|â–ˆâ–ˆâ–ˆ                             | 117/1209 [02:04<08:01,  2.27it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.1049:  10%|â–ˆâ–ˆâ–ˆâ–                            | 122/1209 [02:06<08:01,  2.26it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 1.0456:  10%|â–ˆâ–ˆâ–ˆâ–Ž                            | 126/1209 [02:08<07:59,  2.26it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.2985:  11%|â–ˆâ–ˆâ–ˆâ–                            | 131/1209 [02:10<07:58,  2.25it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.2418:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 135/1209 [02:12<07:52,  2.27it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.2418:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 135/1209 [02:12<07:52,  2.27it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
lambda_max: 10236.8349609375 lrs: tensor([3.7615e-03, 3.6472e-03, 1.6668e-03, 1.1189e-03, 9.1367e-04, 9.0617e-04,
        7.2040e-04, 5.2150e-04, 4.1970e-04, 2.7131e-04, 2.3688e-04, 9.7686e-05]) eigenvals: tensor([  265.8514,   274.1861,   599.9354,   893.7708,  1094.4901,  1103.5514,
Epoch: 1, Loss: 0.3373:  11%|â–ˆâ–ˆâ–ˆâ–                          | 137/1209 [03:28<4:49:54, 16.23s/it]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.1104:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 142/1209 [03:30<54:51,  3.09s/it]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.5532:  12%|â–ˆâ–ˆâ–ˆâ–‰                            | 147/1209 [03:32<15:24,  1.15it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.2020:  12%|â–ˆâ–ˆâ–ˆâ–‰                            | 151/1209 [03:34<09:25,  1.87it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.5066:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 156/1209 [03:36<07:46,  2.26it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0212:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 161/1209 [03:38<07:38,  2.29it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.6461:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 165/1209 [03:40<07:27,  2.33it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0418:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 170/1209 [03:42<07:53,  2.19it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.7612:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 174/1209 [03:44<07:27,  2.31it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0447:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 179/1209 [03:46<07:37,  2.25it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.2260:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 183/1209 [03:48<08:04,  2.12it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0450:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                           | 187/1209 [03:50<08:04,  2.11it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0877:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 192/1209 [03:52<07:26,  2.28it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0446:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 197/1209 [03:55<07:20,  2.30it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.8626:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 201/1209 [03:56<07:10,  2.34it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.3102:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 203/1209 [03:57<07:13,  2.32it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.3102:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 203/1209 [03:57<07:13,  2.32it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
lambda_max: 29587.025390625 lrs: tensor([2.3864e-03, 2.0272e-03, 1.8968e-03, 1.5843e-03, 1.5323e-03, 7.9356e-04,
        6.1560e-04, 5.8180e-04, 3.3280e-04, 2.5854e-04, 6.2997e-05, 3.3799e-05]) eigenvals: tensor([  419.0485,   493.2900,   527.2145,   631.2055,   652.5964,  1260.1497,
Epoch: 1, Loss: 0.0813:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 204/1209 [05:08<6:03:08, 21.68s/it]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.8688:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 209/1209 [05:10<1:06:09,  3.97s/it]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0990:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 214/1209 [05:12<16:33,  1.00it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0511:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 220/1209 [05:15<07:40,  2.15it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0718:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 225/1209 [05:17<06:40,  2.46it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 1.1110:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 230/1209 [05:19<06:37,  2.46it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0475:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 235/1209 [05:21<06:24,  2.53it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.1232:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 240/1209 [05:23<06:29,  2.49it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.0654:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 245/1209 [05:25<06:26,  2.49it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.9643:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [05:26<06:22,  2.51it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.9643:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [05:26<06:22,  2.51it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.3906:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 256/1209 [05:32<08:12,  1.94it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 1.3064:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 261/1209 [05:34<06:38,  2.38it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.9})..44201.9548895}).
Epoch: 1, Loss: 0.1640:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 263/1209 [05:35<06:27,  2.44it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.5548:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 271/1209 [05:39<06:37,  2.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.5548:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 271/1209 [05:39<06:37,  2.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
lambda_max: 5632.3603515625 lrs: tensor([0.0049, 0.0029, 0.0025, 0.0025, 0.0022, 0.0013, 0.0012, 0.0011, 0.0009,
        0.0005, 0.0003, 0.0002]) eigenvals: tensor([ 205.7712,  343.0907,  402.4565,  404.9614,  446.1978,  766.9338,
Epoch: 1, Loss: 0.4815:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 273/1209 [06:53<4:06:59, 15.83s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.8465:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 277/1209 [06:55<1:04:08,  4.13s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.5930:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 282/1209 [06:57<16:24,  1.06s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 1.1400:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 286/1209 [06:59<08:56,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.4398:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 291/1209 [07:01<07:08,  2.14it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0748:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 296/1209 [07:03<06:40,  2.28it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0407:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 301/1209 [07:05<06:34,  2.30it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0552:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 306/1209 [07:07<06:38,  2.27it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.1472:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 311/1209 [07:10<06:35,  2.27it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.2004:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 315/1209 [07:11<06:32,  2.28it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.7820:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 320/1209 [07:14<06:31,  2.27it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.4623:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 324/1209 [07:15<06:45,  2.18it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0988:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 329/1209 [07:18<06:24,  2.29it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0511:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 333/1209 [07:19<06:21,  2.30it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.8223:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 338/1209 [07:21<06:19,  2.29it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.6500:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 339/1209 [07:22<06:20,  2.28it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0281:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 340/1209 [08:35<5:23:49, 22.36s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0281:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 340/1209 [08:35<5:23:49, 22.36s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
lambda_max: 106491.3046875 lrs: tensor([8.6448e-04, 8.1347e-04, 7.3976e-04, 7.0732e-04, 6.3295e-04, 6.1754e-04,
        5.6173e-04, 5.5189e-04, 5.0422e-04, 3.8932e-04, 1.6829e-04, 9.3904e-06]) eigenvals: tensor([  1156.7645,   1229.3047,   1351.7949,   1413.7858,   1579.9119,
          1619.3398,   1780.2047,   1811.9436,   1983.2686,   2568.6130,
Epoch: 1, Loss: 0.8025:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 345/1209 [08:37<58:58,  4.10s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.4007:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 350/1209 [08:39<14:36,  1.02s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.4180:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 355/1209 [08:41<07:08,  1.99it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.3473:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 360/1209 [08:43<05:55,  2.39it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 1.2873:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 365/1209 [08:46<05:43,  2.46it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.2704:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 370/1209 [08:48<06:03,  2.31it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0839:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 375/1209 [08:50<05:44,  2.42it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0525:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 380/1209 [08:52<05:27,  2.53it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0446:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 385/1209 [08:54<05:21,  2.56it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0201:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 390/1209 [08:56<05:22,  2.54it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0867:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 395/1209 [08:58<05:55,  2.29it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0330:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 399/1209 [08:59<05:26,  2.48it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0376:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 404/1209 [09:02<05:36,  2.39it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0628:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 407/1209 [09:03<05:20,  2.50it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0628:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 407/1209 [09:03<05:20,  2.50it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
lambda_max: 17737.5390625 lrs: tensor([1.4595e-02, 7.0385e-03, 6.4434e-03, 3.1720e-03, 2.4611e-03, 1.7114e-03,
        1.5933e-03, 8.9679e-04, 4.5326e-04, 4.4043e-04, 3.5809e-04, 5.6378e-05]) eigenvals: tensor([   68.5175,   142.0764,   155.1986,   315.2548,   406.3177,   584.3148,
Epoch: 1, Loss: 0.4428:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 409/1209 [10:18<3:32:44, 15.96s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0545:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 414/1209 [10:20<39:58,  3.02s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 1.1081:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 419/1209 [10:22<11:09,  1.18it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0428:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 424/1209 [10:24<06:29,  2.02it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.2779:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 429/1209 [10:26<05:27,  2.38it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0390:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 434/1209 [10:28<05:17,  2.44it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0448:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 439/1209 [10:30<05:30,  2.33it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0358:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 444/1209 [10:32<05:09,  2.47it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0643:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 449/1209 [10:34<05:05,  2.49it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.5424:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 454/1209 [10:36<05:03,  2.49it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0425:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 458/1209 [10:38<05:20,  2.35it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0288:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 463/1209 [10:40<05:08,  2.41it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.5906:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 468/1209 [10:42<04:59,  2.47it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.1114:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 473/1209 [10:44<04:56,  2.48it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.1746:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 475/1209 [10:45<05:25,  2.25it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.1746:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 475/1209 [10:45<05:25,  2.25it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
lambda_max: 3876.117919921875 lrs: tensor([0.0019, 0.0017, 0.0016, 0.0016, 0.0015, 0.0014, 0.0011, 0.0009, 0.0007,
        0.0005, 0.0003, 0.0003]) eigenvals: tensor([ 523.7363,  605.2357,  610.4116,  617.1995,  672.1019,  705.0830,
Epoch: 1, Loss: 0.0582:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                  | 479/1209 [11:58<1:34:39,  7.78s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0415:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 484/1209 [12:00<19:57,  1.65s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.3230:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 489/1209 [12:02<07:33,  1.59it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.2212:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 494/1209 [12:04<05:26,  2.19it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.6833:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 498/1209 [12:06<05:06,  2.32it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.9915:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [12:06<05:04,  2.33it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.9915:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [12:06<05:04,  2.33it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.9915:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [12:06<05:04,  2.33it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Validation at Global Step: 500, Validation Loss: 0.0513: 100%|â–ˆ| 121/121 [00:03<00:00, 32.81it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
[33m[W 2024-05-11 17:21:49,474][39m Trial 51 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 32.81it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
[33m[W 2024-05-11 17:21:49,474][39m Trial 51 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 32.81it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
An exception occurred:
Returning None...
Returned ESE function. Lanczos order (m) is 80 .
Epoch: 1, Loss: 0.0711:   1%|â–                                 | 8/1209 [00:04<10:20,  1.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0550:   1%|â–Ž                                | 12/1209 [00:06<10:17,  1.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0640:   1%|â–                                | 16/1209 [00:08<10:23,  1.91it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0353:   2%|â–Œ                                | 19/1209 [00:10<11:07,  1.78it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.8979:   2%|â–‹                                | 23/1209 [00:12<10:27,  1.89it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0213:   2%|â–‹                                | 27/1209 [00:14<11:07,  1.77it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0402:   3%|â–Š                                | 31/1209 [00:16<10:37,  1.85it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0447:   3%|â–‰                                | 35/1209 [00:18<10:08,  1.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0422:   3%|â–ˆ                                | 38/1209 [00:20<10:01,  1.95it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0908:   3%|â–ˆâ–                               | 42/1209 [00:22<09:57,  1.95it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0503:   4%|â–ˆâ–Ž                               | 46/1209 [00:24<10:24,  1.86it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0381:   4%|â–ˆâ–Ž                               | 50/1209 [00:26<10:07,  1.91it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0307:   4%|â–ˆâ–                               | 54/1209 [00:28<09:56,  1.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0352:   5%|â–ˆâ–Œ                               | 58/1209 [00:30<09:56,  1.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0573:   5%|â–ˆâ–‹                               | 61/1209 [00:32<10:51,  1.76it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.9523:   5%|â–ˆâ–Š                               | 65/1209 [00:34<10:38,  1.79it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0454:   6%|â–ˆâ–‰                               | 69/1209 [00:36<10:00,  1.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0526:   6%|â–ˆâ–‰                               | 72/1209 [00:38<09:48,  1.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0454:   6%|â–ˆâ–ˆ                               | 76/1209 [00:40<09:48,  1.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0559:   7%|â–ˆâ–ˆâ–                              | 80/1209 [00:42<10:29,  1.79it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0904:   7%|â–ˆâ–ˆâ–Ž                              | 84/1209 [00:44<09:51,  1.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0431:   7%|â–ˆâ–ˆâ–Ž                              | 87/1209 [00:46<09:57,  1.88it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0569:   8%|â–ˆâ–ˆâ–                              | 91/1209 [00:48<10:11,  1.83it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0563:   8%|â–ˆâ–ˆâ–Œ                              | 95/1209 [00:50<09:45,  1.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0402:   8%|â–ˆâ–ˆâ–‹                              | 99/1209 [00:52<09:34,  1.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.6455:   9%|â–ˆâ–ˆâ–‹                             | 103/1209 [00:54<09:46,  1.88it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.1240:   9%|â–ˆâ–ˆâ–Š                             | 106/1209 [00:56<09:34,  1.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0533:   9%|â–ˆâ–ˆâ–‰                             | 110/1209 [00:58<09:32,  1.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.7312:   9%|â–ˆâ–ˆâ–ˆ                             | 114/1209 [01:00<09:26,  1.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0549:  10%|â–ˆâ–ˆâ–ˆ                             | 118/1209 [01:02<09:23,  1.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0601:  10%|â–ˆâ–ˆâ–ˆâ–                            | 122/1209 [01:04<09:16,  1.95it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0582:  10%|â–ˆâ–ˆâ–ˆâ–Ž                            | 126/1209 [01:06<09:18,  1.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0605:  11%|â–ˆâ–ˆâ–ˆâ–                            | 129/1209 [01:08<10:18,  1.75it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0553:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 133/1209 [01:10<10:32,  1.70it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0628:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 136/1209 [01:12<10:29,  1.70it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.7353:  12%|â–ˆâ–ˆâ–ˆâ–‹                            | 140/1209 [01:14<09:41,  1.84it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0792:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 144/1209 [01:16<09:16,  1.91it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.1408:  12%|â–ˆâ–ˆâ–ˆâ–‰                            | 148/1209 [01:18<09:09,  1.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.8291:  12%|â–ˆâ–ˆâ–ˆâ–‰                            | 151/1209 [01:20<09:06,  1.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.1568:  13%|â–ˆâ–ˆâ–ˆâ–ˆ                            | 155/1209 [01:22<09:02,  1.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.1820:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 159/1209 [01:24<09:06,  1.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.4490:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 163/1209 [01:26<09:01,  1.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.1457:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 167/1209 [01:28<09:07,  1.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0760:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 171/1209 [01:30<09:13,  1.88it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0912:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 174/1209 [01:32<09:11,  1.88it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0613:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 178/1209 [01:34<08:58,  1.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0326:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 182/1209 [01:36<08:46,  1.95it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0326:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 182/1209 [01:36<08:46,  1.95it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
lambda_max: 200.3456268310547 lrs: tensor([0.9169, 0.8976, 0.8145, 0.7230, 0.6443, 0.6042, 0.5752, 0.5053, 0.4303,
        0.4262, 0.4150, 0.3618, 0.2997, 0.2902, 0.2676, 0.2009, 0.1525, 0.0759,
        0.0346, 0.0050]) eigenvals: tensor([  1.0907,   1.1140,   1.2277,   1.3831,   1.5521,   1.6550,   1.7386,
          1.9791,   2.3242,   2.3463,   2.4094,   2.7640,   3.3366,   3.4454,
Epoch: 1, Loss: 0.5238:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–                        | 183/1209 [04:45<16:12:30, 56.87s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0646:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 187/1209 [04:47<4:00:23, 14.11s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0562:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 190/1209 [04:49<1:28:48,  5.23s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0389:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 194/1209 [04:51<28:57,  1.71s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0805:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 197/1209 [04:53<16:29,  1.02it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0637:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 200/1209 [04:55<12:25,  1.35it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0637:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 204/1209 [04:57<10:54,  1.54it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.6020:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 207/1209 [04:59<10:08,  1.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0689:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                          | 210/1209 [05:01<10:00,  1.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.5805:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 214/1209 [05:03<09:54,  1.67it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.1342:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 217/1209 [05:05<09:46,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.1501:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 221/1209 [05:07<09:44,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0862:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 224/1209 [05:09<09:43,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0747:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 227/1209 [05:11<09:39,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0181:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 231/1209 [05:13<09:45,  1.67it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.6315:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 234/1209 [05:15<09:35,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.1764:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 238/1209 [05:17<09:34,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 1.3376:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 241/1209 [05:19<09:41,  1.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0417:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 244/1209 [05:21<09:33,  1.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0862:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 248/1209 [05:23<09:32,  1.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0703:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [05:24<09:29,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.6617:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 252/1209 [05:29<17:56,  1.13s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0593:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 255/1209 [05:31<12:25,  1.28it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.013474804349243641, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 0.0, '_timestamp': 1715447702.110629})..44201.9548895}).
Epoch: 1, Loss: 0.0674:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 257/1209 [05:32<10:52,  1.46it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0475:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 262/1209 [05:35<09:35,  1.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.6262:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 265/1209 [05:37<09:19,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0662:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 269/1209 [05:39<09:17,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1268:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 272/1209 [05:41<09:15,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1072:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 275/1209 [05:43<09:30,  1.64it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1871:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 279/1209 [05:45<09:21,  1.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1173:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 282/1209 [05:47<09:09,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0666:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 285/1209 [05:49<09:05,  1.70it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0930:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 289/1209 [05:51<09:02,  1.70it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.6579:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 292/1209 [05:53<09:01,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1646:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 296/1209 [05:55<08:59,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1610:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 299/1209 [05:57<09:06,  1.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1479:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 302/1209 [05:59<08:59,  1.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1049:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 306/1209 [06:01<08:50,  1.70it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0293:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 309/1209 [06:03<08:47,  1.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0387:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 313/1209 [06:06<08:49,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0221:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 316/1209 [06:07<08:48,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.7489:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 319/1209 [06:09<08:45,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.9408:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 323/1209 [06:12<09:13,  1.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0266:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 326/1209 [06:13<09:12,  1.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0359:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 329/1209 [06:15<09:23,  1.56it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0305:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 332/1209 [06:17<09:13,  1.58it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0799:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 335/1209 [06:19<09:07,  1.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.5922:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 339/1209 [06:22<08:47,  1.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0583:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 342/1209 [06:23<08:37,  1.67it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.5883:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 345/1209 [06:25<08:39,  1.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1007:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 349/1209 [06:28<08:50,  1.62it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0917:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 352/1209 [06:29<08:35,  1.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0370:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 355/1209 [06:31<08:30,  1.67it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.4334:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 359/1209 [06:34<08:29,  1.67it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0557:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 362/1209 [06:35<08:27,  1.67it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0272:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 365/1209 [06:37<08:24,  1.67it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0272:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 365/1209 [06:37<08:24,  1.67it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
lambda_max: 1909.481689453125 lrs: tensor([0.0085, 0.0081, 0.0075, 0.0071, 0.0068, 0.0060, 0.0051, 0.0042, 0.0040,
        0.0039, 0.0034, 0.0034, 0.0032, 0.0030, 0.0020, 0.0018, 0.0010, 0.0007,
        0.0007, 0.0005]) eigenvals: tensor([ 117.0018,  123.5741,  134.0483,  140.2980,  147.3111,  166.3844,
         197.6726,  237.8911,  251.4220,  258.3689,  296.1243,  296.6591,
         309.3657,  328.5775,  505.0089,  559.8271, 1016.5252, 1512.7000,
Epoch: 1, Loss: 1.2033:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 368/1209 [09:42<6:24:47, 27.45s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1129:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 371/1209 [09:43<2:16:48,  9.80s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.3717:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 375/1209 [09:46<38:48,  2.79s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0469:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 378/1209 [09:48<18:34,  1.34s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0840:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 382/1209 [09:50<10:34,  1.30it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.3740:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 385/1209 [09:52<08:55,  1.54it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 1.7525:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 389/1209 [09:54<08:05,  1.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1266:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 392/1209 [09:56<08:01,  1.70it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0479:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 395/1209 [09:57<07:53,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0887:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 399/1209 [10:00<07:50,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1221:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 402/1209 [10:01<07:46,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.3548:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 406/1209 [10:04<07:45,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.2121:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 409/1209 [10:06<07:47,  1.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.9254:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 413/1209 [10:08<07:42,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0985:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 416/1209 [10:10<07:38,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0414:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 420/1209 [10:12<07:36,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0313:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 423/1209 [10:14<07:34,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0166:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 427/1209 [10:16<07:31,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.3098:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 430/1209 [10:18<07:32,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0129:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 434/1209 [10:20<07:30,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.3461:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 437/1209 [10:22<07:27,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0238:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                    | 440/1209 [10:24<07:24,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 1.1301:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 444/1209 [10:26<07:21,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.3203:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 447/1209 [10:28<07:46,  1.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0282:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 451/1209 [10:30<07:24,  1.70it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.2069:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 454/1209 [10:32<07:19,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.3333:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 457/1209 [10:34<07:13,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0822:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 461/1209 [10:36<07:14,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.2560:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 464/1209 [10:38<07:12,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 1.2412:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 468/1209 [10:40<07:09,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0318:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 471/1209 [10:42<07:11,  1.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1047:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 475/1209 [10:44<07:08,  1.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1200:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 478/1209 [10:46<07:06,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.8231:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 482/1209 [10:48<07:02,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0301:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 485/1209 [10:50<07:00,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1032:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 489/1209 [10:52<06:57,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1165:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 492/1209 [10:54<06:54,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0276:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 495/1209 [10:56<06:53,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1098:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [10:58<06:55,  1.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1098:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [10:58<06:55,  1.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1098:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [10:58<06:55,  1.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Validation at Global Step: 500, Validation Loss: 1.4956: 100%|â–ˆ| 121/121 [00:03<00:00, 33.23it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Validation at Global Step: 500, Validation Loss: 1.4956: 100%|â–ˆ| 121/121 [00:03<00:00, 33.23it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
An exception occurred:
Returning None...
[33m[W 2024-05-11 17:32:59,448][39m Trial 52 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 33.23it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
[33m[W 2024-05-11 17:32:59,448][39m Trial 52 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 33.23it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0119:   1%|â–Ž                                 | 9/1209 [00:04<10:17,  1.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 1.0460:   1%|â–Ž                                | 13/1209 [00:06<10:18,  1.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0533:   1%|â–                                | 17/1209 [00:08<10:16,  1.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0564:   2%|â–Œ                                | 21/1209 [00:10<09:41,  2.04it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0075:   2%|â–‹                                | 25/1209 [00:12<09:52,  2.00it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1123:   2%|â–Š                                | 29/1209 [00:14<09:32,  2.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0785:   3%|â–‰                                | 33/1209 [00:16<10:13,  1.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0238:   3%|â–‰                                | 36/1209 [00:18<10:19,  1.89it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0197:   3%|â–ˆ                                | 40/1209 [00:20<10:41,  1.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 1.0160:   4%|â–ˆâ–                               | 44/1209 [00:22<10:31,  1.84it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0222:   4%|â–ˆâ–Ž                               | 48/1209 [00:24<10:14,  1.89it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0039:   4%|â–ˆâ–                               | 52/1209 [00:26<09:30,  2.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0231:   5%|â–ˆâ–Œ                               | 56/1209 [00:28<09:59,  1.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0304:   5%|â–ˆâ–‹                               | 60/1209 [00:30<09:19,  2.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0192:   5%|â–ˆâ–‹                               | 64/1209 [00:32<09:15,  2.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0232:   6%|â–ˆâ–Š                               | 68/1209 [00:34<09:08,  2.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0292:   6%|â–ˆâ–‰                               | 72/1209 [00:36<09:46,  1.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0245:   6%|â–ˆâ–ˆ                               | 76/1209 [00:38<09:26,  2.00it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0638:   7%|â–ˆâ–ˆâ–                              | 80/1209 [00:40<09:02,  2.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1063:   7%|â–ˆâ–ˆâ–Ž                              | 84/1209 [00:42<09:16,  2.02it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0222:   7%|â–ˆâ–ˆâ–                              | 88/1209 [00:44<10:10,  1.84it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.9427:   8%|â–ˆâ–ˆâ–Œ                              | 92/1209 [00:46<09:07,  2.04it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.2274:   8%|â–ˆâ–ˆâ–Œ                              | 96/1209 [00:48<09:00,  2.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0605:   8%|â–ˆâ–ˆâ–‹                             | 100/1209 [00:50<08:53,  2.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.3218:   9%|â–ˆâ–ˆâ–Š                             | 104/1209 [00:52<08:50,  2.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0455:   9%|â–ˆâ–ˆâ–‰                             | 109/1209 [00:54<08:49,  2.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0936:   9%|â–ˆâ–ˆâ–‰                             | 113/1209 [00:56<08:44,  2.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0482:  10%|â–ˆâ–ˆâ–ˆ                             | 117/1209 [00:58<08:51,  2.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 1.8642:  10%|â–ˆâ–ˆâ–ˆâ–                            | 121/1209 [01:00<08:40,  2.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.3856:  10%|â–ˆâ–ˆâ–ˆâ–Ž                            | 125/1209 [01:02<08:40,  2.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0473:  11%|â–ˆâ–ˆâ–ˆâ–                            | 130/1209 [01:04<08:37,  2.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.8647:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 134/1209 [01:06<08:33,  2.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.3258:  11%|â–ˆâ–ˆâ–ˆâ–‹                            | 138/1209 [01:08<08:28,  2.11it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.7028:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 142/1209 [01:10<09:05,  1.96it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0452:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 146/1209 [01:12<08:44,  2.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0519:  12%|â–ˆâ–ˆâ–ˆâ–‰                            | 150/1209 [01:14<08:32,  2.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0569:  12%|â–ˆâ–ˆâ–ˆâ–‰                            | 151/1209 [01:15<08:33,  2.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0569:  12%|â–ˆâ–ˆâ–ˆâ–‰                            | 151/1209 [01:15<08:33,  2.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
lambda_max: 24747.41015625 lrs: tensor([3.2845e-02, 2.9864e-02, 2.5030e-02, 1.7770e-02, 1.1218e-02, 1.0625e-02,
        3.7819e-03, 2.7344e-03, 1.5656e-03, 1.5500e-03, 8.2646e-04, 5.2082e-04,
        4.4755e-04, 4.0408e-05]) eigenvals: tensor([   30.4460,    33.4848,    39.9528,    56.2743,    89.1429,    94.1154,
          264.4198,   365.7136,   638.7332,   645.1530,  1209.9846,  1920.0660,
Epoch: 1, Loss: 0.0406:  13%|â–ˆâ–ˆâ–ˆâ–Š                          | 153/1209 [02:50<5:58:29, 20.37s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.8104:  13%|â–ˆâ–ˆâ–ˆâ–Š                          | 156/1209 [02:52<2:08:11,  7.30s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1521:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 162/1209 [02:55<22:25,  1.29s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 2.8199:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 166/1209 [02:57<11:43,  1.48it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.5278:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 170/1209 [02:59<09:12,  1.88it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0286:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 174/1209 [03:00<08:29,  2.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0561:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 178/1209 [03:02<08:25,  2.04it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.4609:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 182/1209 [03:04<08:17,  2.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0334:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                           | 187/1209 [03:07<08:12,  2.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0482:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 191/1209 [03:09<08:08,  2.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.4134:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 195/1209 [03:11<08:07,  2.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0852:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 199/1209 [03:13<08:05,  2.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0708:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 203/1209 [03:14<08:03,  2.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0438:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 207/1209 [03:16<08:04,  2.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.8506:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                          | 211/1209 [03:18<08:16,  2.01it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0265:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 216/1209 [03:21<08:03,  2.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.8272:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 220/1209 [03:23<08:08,  2.02it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0320:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 224/1209 [03:25<07:57,  2.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0422:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 228/1209 [03:27<07:54,  2.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.3293:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 232/1209 [03:29<07:54,  2.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0323:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 236/1209 [03:31<07:48,  2.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0344:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 240/1209 [03:33<07:53,  2.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.1438:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 245/1209 [03:35<07:51,  2.04it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0312:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [03:37<07:48,  2.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.5650:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 250/1209 [03:41<23:22,  1.46s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0085:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 254/1209 [03:43<11:27,  1.39it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.9806:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 259/1209 [03:45<08:20,  1.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0253:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 263/1209 [03:47<08:04,  1.95it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.9404:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 268/1209 [03:49<07:37,  2.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0215:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 272/1209 [03:51<07:36,  2.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.04946369677782059, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715448438.280545})...44201.9548895}).
Epoch: 1, Loss: 0.0227:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 273/1209 [03:52<07:34,  2.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0370:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 280/1209 [03:55<07:41,  2.01it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.3496:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 284/1209 [03:57<07:36,  2.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0183:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 288/1209 [03:59<07:29,  2.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.1058:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 292/1209 [04:01<07:26,  2.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0834:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 296/1209 [04:03<07:26,  2.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.1104:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 300/1209 [04:05<07:18,  2.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0231:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 303/1209 [04:07<07:20,  2.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0231:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 303/1209 [04:07<07:20,  2.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
lambda_max: 10743.904296875 lrs: tensor([3.7077e-02, 2.4053e-02, 1.7473e-02, 1.4492e-02, 1.1679e-02, 1.0735e-02,
        7.3385e-03, 5.4523e-03, 3.7354e-03, 2.0421e-03, 9.3763e-04, 8.1098e-04,
        1.4156e-04, 9.3076e-05]) eigenvals: tensor([   26.9711,    41.5752,    57.2311,    69.0015,    85.6271,    93.1536,
          136.2683,   183.4103,   267.7108,   489.6961,  1066.5187,  1233.0718,
Epoch: 1, Loss: 0.7489:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 304/1209 [05:39<7:04:12, 28.12s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.5950:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 309/1209 [05:42<1:16:49,  5.12s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.1475:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 313/1209 [05:43<23:38,  1.58s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0337:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 317/1209 [05:45<11:12,  1.33it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0293:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 321/1209 [05:47<08:03,  1.84it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0285:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 325/1209 [05:49<07:09,  2.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.1051:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 329/1209 [05:51<07:18,  2.01it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0235:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 334/1209 [05:54<07:00,  2.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0233:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 338/1209 [05:56<06:50,  2.12it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.3556:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 342/1209 [05:58<07:26,  1.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0804:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 346/1209 [06:00<06:59,  2.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0355:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 350/1209 [06:01<06:45,  2.12it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.7129:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 354/1209 [06:03<06:39,  2.14it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.8285:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 359/1209 [06:06<06:36,  2.14it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0358:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 363/1209 [06:08<06:34,  2.14it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0598:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 367/1209 [06:10<07:03,  1.99it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0795:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 371/1209 [06:11<06:39,  2.10it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0335:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 376/1209 [06:14<06:30,  2.13it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0294:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 380/1209 [06:16<06:29,  2.13it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.1939:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 384/1209 [06:18<06:55,  1.98it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0959:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 388/1209 [06:20<06:44,  2.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0306:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 392/1209 [06:22<06:30,  2.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.2125:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 397/1209 [06:24<06:18,  2.15it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 1.3288:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 401/1209 [06:26<06:20,  2.12it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.2651:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 405/1209 [06:28<06:16,  2.14it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0416:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 409/1209 [06:30<06:20,  2.10it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0864:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 413/1209 [06:31<06:35,  2.01it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0891:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 418/1209 [06:34<06:23,  2.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.3508:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 422/1209 [06:36<06:08,  2.13it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.9311:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 426/1209 [06:38<06:07,  2.13it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0349:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 430/1209 [06:40<06:06,  2.13it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0343:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 435/1209 [06:42<06:12,  2.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0276:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 439/1209 [06:44<06:05,  2.11it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 1.2547:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                    | 443/1209 [06:46<06:01,  2.12it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0944:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 447/1209 [06:48<06:01,  2.11it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.9914:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 451/1209 [06:50<06:29,  1.95it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0490:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 455/1209 [06:52<06:03,  2.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0490:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 455/1209 [06:52<06:03,  2.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
lambda_max: 361.0462646484375 lrs: tensor([0.0685, 0.0627, 0.0489, 0.0478, 0.0455, 0.0242, 0.0239, 0.0219, 0.0050,
        0.0046, 0.0034, 0.0034, 0.0031, 0.0028]) eigenvals: tensor([ 14.5915,  15.9379,  20.4674,  20.9235,  21.9614,  41.3770,  41.7545,
Epoch: 1, Loss: 0.0428:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                  | 458/1209 [08:26<2:56:30, 14.10s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0260:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 463/1209 [08:28<34:31,  2.78s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.3953:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 467/1209 [08:30<12:58,  1.05s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0351:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 470/1209 [08:32<09:00,  1.37it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.8865:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 474/1209 [08:34<06:49,  1.79it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0390:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 478/1209 [08:36<06:15,  1.95it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0371:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 482/1209 [08:38<06:01,  2.01it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.2091:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 486/1209 [08:40<05:56,  2.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0402:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 490/1209 [08:42<05:58,  2.00it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.1220:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 495/1209 [08:44<05:51,  2.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.4024:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [08:46<05:50,  2.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.4024:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [08:46<05:50,  2.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.4024:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [08:46<05:50,  2.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Validation at Global Step: 500, Validation Loss: 0.6556: 100%|â–ˆ| 121/121 [00:04<00:00, 29.87it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
[33m[W 2024-05-11 17:41:58,043][39m Trial 53 failed with value None.%|â–ˆ| 121/121 [00:04<00:00, 29.87it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
[33m[W 2024-05-11 17:41:58,043][39m Trial 53 failed with value None.%|â–ˆ| 121/121 [00:04<00:00, 29.87it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
An exception occurred:
Returning None...
Returned ESE function. Lanczos order (m) is 4 .
Epoch: 1, Loss: 0.0786:   1%|â–                                | 14/1209 [00:04<05:44,  3.47it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0962:   2%|â–Œ                                | 22/1209 [00:06<05:32,  3.57it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.9620:   2%|â–Š                                | 29/1209 [00:08<05:28,  3.59it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0350:   3%|â–‰                                | 36/1209 [00:10<05:37,  3.47it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0265:   4%|â–ˆâ–                               | 43/1209 [00:12<05:38,  3.45it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0337:   4%|â–ˆâ–Ž                               | 50/1209 [00:14<05:20,  3.62it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0259:   5%|â–ˆâ–Œ                               | 57/1209 [00:16<05:19,  3.61it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0556:   5%|â–ˆâ–‹                               | 64/1209 [00:18<05:27,  3.49it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0234:   6%|â–ˆâ–‰                               | 71/1209 [00:20<05:54,  3.21it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0192:   6%|â–ˆâ–ˆâ–                              | 78/1209 [00:22<05:16,  3.57it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0150:   7%|â–ˆâ–ˆâ–Ž                              | 85/1209 [00:24<05:09,  3.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 1.0923:   8%|â–ˆâ–ˆâ–Œ                              | 92/1209 [00:26<05:16,  3.53it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0764:   8%|â–ˆâ–ˆâ–‹                             | 100/1209 [00:28<05:06,  3.62it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.5041:   9%|â–ˆâ–ˆâ–Š                             | 106/1209 [00:30<05:15,  3.50it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.5041:   9%|â–ˆâ–ˆâ–Š                             | 106/1209 [00:30<05:15,  3.50it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0206:   9%|â–ˆâ–ˆâ–‰                             | 113/1209 [00:36<08:04,  2.26it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0400:  10%|â–ˆâ–ˆâ–ˆâ–                            | 120/1209 [00:38<05:22,  3.37it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0396:  11%|â–ˆâ–ˆâ–ˆâ–Ž                            | 127/1209 [00:40<05:00,  3.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0711:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 134/1209 [00:42<04:58,  3.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0299:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 142/1209 [00:44<04:57,  3.59it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0290:  12%|â–ˆâ–ˆâ–ˆâ–‰                            | 149/1209 [00:46<05:04,  3.48it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.4466:  13%|â–ˆâ–ˆâ–ˆâ–ˆ                            | 155/1209 [00:48<05:19,  3.30it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.1991:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 162/1209 [00:50<05:03,  3.45it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0512:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 169/1209 [00:52<04:52,  3.56it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0160:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 177/1209 [00:54<04:47,  3.59it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0106:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 184/1209 [00:56<04:45,  3.58it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 1.1671:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 191/1209 [00:58<04:49,  3.52it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0330:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 198/1209 [01:00<04:47,  3.51it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0454:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 205/1209 [01:02<04:41,  3.57it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0368:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 213/1209 [01:04<04:34,  3.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0368:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 213/1209 [01:04<04:34,  3.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0788:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 219/1209 [01:10<08:02,  2.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0734:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 227/1209 [01:12<04:48,  3.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.1122:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 234/1209 [01:14<04:34,  3.55it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.1844:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 241/1209 [01:16<04:31,  3.56it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0304:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 247/1209 [01:18<04:39,  3.44it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 1.3272:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [01:19<05:00,  3.20it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.5650010108947754, 'F1_Macro/Train': 0.5, 'ACCURACY/Train': 0.5, 'PRECISION/Train': 0.5, 'RECALL/Train': 0.5, 'MAE/Train': 0.5, 'MCC/Train': 0.0, '_timestamp': 1715449000.9283018})...44201.9548895}).
Epoch: 1, Loss: 0.0978:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 255/1209 [01:24<07:20,  2.17it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0354:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 263/1209 [01:26<04:47,  3.29it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0467:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 270/1209 [01:28<04:25,  3.54it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.8636:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 278/1209 [01:30<04:19,  3.59it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.9173:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 285/1209 [01:32<04:20,  3.55it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0405:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 292/1209 [01:34<04:15,  3.59it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0485:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 299/1209 [01:36<04:15,  3.56it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.9961:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 306/1209 [01:38<04:14,  3.54it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0483:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 313/1209 [01:40<04:10,  3.58it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0463:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 320/1209 [01:42<04:03,  3.64it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0463:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 320/1209 [01:42<04:03,  3.64it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.6793:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 327/1209 [01:48<06:40,  2.20it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 1.1340:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 334/1209 [01:50<04:17,  3.39it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0263:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 341/1209 [01:52<04:04,  3.54it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0894:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 349/1209 [01:54<04:00,  3.58it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0359:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 356/1209 [01:56<03:56,  3.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0256:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 363/1209 [01:58<03:56,  3.58it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0328:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 370/1209 [02:00<03:50,  3.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0222:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 378/1209 [02:02<03:52,  3.58it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0621:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 384/1209 [02:04<04:07,  3.34it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.9401:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 392/1209 [02:06<03:46,  3.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0363:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 399/1209 [02:08<03:50,  3.52it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 1.5261:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 406/1209 [02:10<03:42,  3.62it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0691:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 413/1209 [02:12<03:45,  3.53it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0379:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 420/1209 [02:14<03:39,  3.59it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0801:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 427/1209 [02:16<03:37,  3.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0801:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 427/1209 [02:16<03:37,  3.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0517:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 434/1209 [02:22<05:29,  2.35it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0330:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                    | 441/1209 [02:24<03:45,  3.41it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0312:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 448/1209 [02:26<03:32,  3.59it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0760:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 455/1209 [02:28<03:35,  3.49it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.3691:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 463/1209 [02:31<03:29,  3.56it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.9794:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 470/1209 [02:32<03:24,  3.61it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0229:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 477/1209 [02:35<03:29,  3.49it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0919:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 483/1209 [02:36<03:40,  3.29it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0478:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 490/1209 [02:38<03:30,  3.42it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0257:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 497/1209 [02:40<03:30,  3.38it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0468:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [02:41<03:24,  3.48it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0468:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [02:41<03:24,  3.48it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0468:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [02:41<03:24,  3.48it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Validation at Global Step: 500, Validation Loss: 0.6218: 100%|â–ˆ| 121/121 [00:03<00:00, 31.39it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
[33m[W 2024-05-11 17:44:51,040][39m Trial 54 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 31.39it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
[33m[W 2024-05-11 17:44:51,040][39m Trial 54 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 31.39it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
An exception occurred:
Returning None...
Returned ESE function. Lanczos order (m) is 36 .
Epoch: 1, Loss: 0.0093:   1%|â–Ž                                | 11/1209 [00:04<07:30,  2.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0162:   1%|â–                                | 16/1209 [00:06<07:35,  2.62it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0099:   2%|â–Œ                                | 21/1209 [00:07<07:31,  2.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0104:   2%|â–‹                                | 26/1209 [00:09<07:27,  2.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0242:   3%|â–Š                                | 31/1209 [00:11<07:32,  2.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0658:   3%|â–ˆ                                | 37/1209 [00:14<07:23,  2.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0130:   3%|â–ˆâ–                               | 42/1209 [00:16<07:27,  2.61it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.6040:   4%|â–ˆâ–Ž                               | 47/1209 [00:18<08:12,  2.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.8773:   4%|â–ˆâ–                               | 52/1209 [00:20<08:05,  2.38it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.6353:   5%|â–ˆâ–Œ                               | 57/1209 [00:22<07:20,  2.61it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0042:   5%|â–ˆâ–‹                               | 62/1209 [00:24<07:21,  2.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0309:   6%|â–ˆâ–Š                               | 67/1209 [00:26<08:11,  2.32it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0323:   6%|â–ˆâ–‰                               | 71/1209 [00:28<08:27,  2.24it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0230:   6%|â–ˆâ–ˆ                               | 76/1209 [00:30<08:24,  2.25it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.1151:   7%|â–ˆâ–ˆâ–                              | 80/1209 [00:32<08:24,  2.24it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0399:   7%|â–ˆâ–ˆâ–Ž                              | 85/1209 [00:34<07:25,  2.52it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0078:   7%|â–ˆâ–ˆâ–                              | 90/1209 [00:35<07:07,  2.62it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0081:   8%|â–ˆâ–ˆâ–Œ                              | 96/1209 [00:38<07:03,  2.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.1711:   8%|â–ˆâ–ˆâ–‹                             | 101/1209 [00:40<06:59,  2.64it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0096:   9%|â–ˆâ–ˆâ–Š                             | 106/1209 [00:42<06:58,  2.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0203:   9%|â–ˆâ–ˆâ–‰                             | 112/1209 [00:44<06:56,  2.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0293:  10%|â–ˆâ–ˆâ–ˆ                             | 116/1209 [00:45<06:55,  2.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.4236:  10%|â–ˆâ–ˆâ–‰                           | 120/1209 [01:36<1:38:24,  5.42s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.4236:  10%|â–ˆâ–ˆâ–‰                           | 120/1209 [01:36<1:38:24,  5.42s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
lambda_max: 12.249363899230957 lrs: tensor([1.5573, 1.4042, 0.9895, 0.6632, 0.5271, 0.1719, 0.1168, 0.0962, 0.0816]) eigenvals: tensor([ 0.6421,  0.7122,  1.0106,  1.5078,  1.8971,  5.8170,  8.5580, 10.3936,
Epoch: 1, Loss: 0.0290:  10%|â–ˆâ–ˆâ–ˆâ–Ž                            | 125/1209 [01:38<22:07,  1.22s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0204:  11%|â–ˆâ–ˆâ–ˆâ–                            | 130/1209 [01:40<09:24,  1.91it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.6740:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 135/1209 [01:42<07:22,  2.43it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0287:  12%|â–ˆâ–ˆâ–ˆâ–‹                            | 141/1209 [01:44<06:48,  2.61it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0107:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 146/1209 [01:46<06:49,  2.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0154:  12%|â–ˆâ–ˆâ–ˆâ–‰                            | 151/1209 [01:48<06:41,  2.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0636:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 157/1209 [01:50<06:38,  2.64it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0270:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 162/1209 [01:52<06:36,  2.64it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.8530:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 167/1209 [01:54<06:45,  2.57it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.7053:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 171/1209 [01:56<07:31,  2.30it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.1634:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 177/1209 [01:58<06:35,  2.61it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.1842:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 182/1209 [02:00<06:30,  2.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0896:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                           | 187/1209 [02:02<06:49,  2.50it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.8025:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 192/1209 [02:04<06:38,  2.55it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0375:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 197/1209 [02:06<06:25,  2.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.2353:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 203/1209 [02:08<06:26,  2.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 1.4243:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                          | 208/1209 [02:10<06:23,  2.61it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0635:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 213/1209 [02:12<06:26,  2.57it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0229:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 218/1209 [02:14<06:14,  2.64it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0063:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 223/1209 [02:16<06:13,  2.64it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.1591:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 229/1209 [02:18<06:14,  2.62it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 1.5598:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 233/1209 [02:20<06:11,  2.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 1.5598:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 233/1209 [02:20<06:11,  2.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
lambda_max: 13592.4013671875 lrs: tensor([1.1613e+00, 5.7395e-01, 4.2579e-01, 2.5493e-01, 1.5901e-01, 1.4006e-01,
        1.0329e-02, 8.9826e-05, 7.3571e-05]) eigenvals: tensor([8.6108e-01, 1.7423e+00, 2.3486e+00, 3.9226e+00, 6.2890e+00, 7.1398e+00,
Epoch: 1, Loss: 0.2718:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 237/1209 [03:08<1:24:36,  5.22s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0048:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 242/1209 [03:10<20:02,  1.24s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0151:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 246/1209 [03:12<09:50,  1.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.2784:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [03:13<07:40,  2.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0058:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 253/1209 [03:18<12:14,  1.30it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0122:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 258/1209 [03:20<07:33,  2.10it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0065:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 262/1209 [03:22<07:15,  2.17it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 1.0651:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 267/1209 [03:24<06:39,  2.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.9212:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 272/1209 [03:26<06:50,  2.28it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.2173:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 277/1209 [03:28<06:28,  2.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0111:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 281/1209 [03:30<06:28,  2.39it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0291578471660614, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715449400.9953218})...44201.9548895}).
Epoch: 1, Loss: 0.0237:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 283/1209 [03:31<06:24,  2.41it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.4034:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 291/1209 [03:34<06:28,  2.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.1780:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 296/1209 [03:36<06:19,  2.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0153:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 300/1209 [03:38<06:39,  2.27it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0329:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 305/1209 [03:40<06:50,  2.20it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 1.2094:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 309/1209 [03:42<06:33,  2.29it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 1.0743:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 314/1209 [03:44<06:10,  2.42it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0301:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 319/1209 [03:46<06:11,  2.39it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.1127:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 324/1209 [03:48<06:10,  2.39it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.1792:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 329/1209 [03:50<06:12,  2.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.4244:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 334/1209 [03:52<06:01,  2.42it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.1250:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 338/1209 [03:54<06:04,  2.39it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0751:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 342/1209 [03:56<06:57,  2.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0974:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 347/1209 [03:58<06:10,  2.32it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0717:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 350/1209 [03:59<06:01,  2.38it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0717:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 350/1209 [03:59<06:01,  2.38it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
lambda_max: 20782.138671875 lrs: tensor([5.9613e-01, 3.6593e-01, 3.5680e-01, 2.9520e-01, 1.9148e-01, 4.7323e-03,
        2.0688e-03, 5.1506e-05, 4.8118e-05]) eigenvals: tensor([1.6775e+00, 2.7328e+00, 2.8027e+00, 3.3876e+00, 5.2224e+00, 2.1132e+02,
Epoch: 1, Loss: 0.0291:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 355/1209 [04:50<55:24,  3.89s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.1381:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 361/1209 [04:52<11:02,  1.28it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0204:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 366/1209 [04:54<06:08,  2.29it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0089:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 372/1209 [04:56<05:12,  2.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 1.1597:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 377/1209 [04:58<05:05,  2.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0336:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 382/1209 [05:00<05:23,  2.55it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0482:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 388/1209 [05:02<05:06,  2.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0750:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 393/1209 [05:04<05:00,  2.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0490:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 399/1209 [05:06<04:57,  2.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.8296:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 404/1209 [05:08<04:54,  2.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0326:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 410/1209 [05:10<05:02,  2.64it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0255:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 415/1209 [05:12<04:53,  2.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0439:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 421/1209 [05:14<04:51,  2.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0205:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 426/1209 [05:16<04:49,  2.70it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0137:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 432/1209 [05:19<04:45,  2.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0924:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 437/1209 [05:20<04:41,  2.74it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.1380:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                    | 443/1209 [05:23<04:40,  2.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0064:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 448/1209 [05:24<04:43,  2.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0082:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 453/1209 [05:26<05:01,  2.50it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0628:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 458/1209 [05:28<04:41,  2.67it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.2207:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 464/1209 [05:31<04:37,  2.69it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0761:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 467/1209 [05:32<04:31,  2.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0761:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 467/1209 [05:32<04:31,  2.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
lambda_max: 9560.1328125 lrs: tensor([0.0276, 0.0227, 0.0224, 0.0208, 0.0113, 0.0075, 0.0033, 0.0010, 0.0001]) eigenvals: tensor([  36.2795,   43.9908,   44.5675,   48.0197,   88.1466,  134.0289,
Epoch: 1, Loss: 0.0593:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 470/1209 [06:19<1:27:30,  7.10s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0542:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 475/1209 [06:20<18:29,  1.51s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0593:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 480/1209 [06:22<06:56,  1.75it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.4180:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 486/1209 [06:25<04:54,  2.45it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0700:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 491/1209 [06:27<04:35,  2.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0138:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 496/1209 [06:28<04:31,  2.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.1195:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [06:30<04:27,  2.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.1195:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [06:30<04:27,  2.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.1195:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [06:30<04:27,  2.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Validation at Global Step: 500, Validation Loss: 3.3279: 100%|â–ˆ| 121/121 [00:03<00:00, 33.22it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Validation at Global Step: 500, Validation Loss: 3.3279: 100%|â–ˆ| 121/121 [00:03<00:00, 33.22it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
An exception occurred:
Returning None...
[33m[W 2024-05-11 17:51:32,518][39m Trial 55 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 33.22it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
[33m[W 2024-05-11 17:51:32,518][39m Trial 55 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 33.22it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0067:   1%|â–                                | 15/1209 [00:05<07:31,  2.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0020:   2%|â–Œ                                | 20/1209 [00:07<07:35,  2.61it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 2.0354:   2%|â–‹                                | 25/1209 [00:09<07:41,  2.57it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 1.4350:   3%|â–Š                                | 31/1209 [00:11<07:27,  2.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.1129:   3%|â–‰                                | 36/1209 [00:13<07:30,  2.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0125:   3%|â–ˆ                                | 41/1209 [00:15<07:26,  2.62it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0562:   4%|â–ˆâ–Ž                               | 46/1209 [00:17<07:23,  2.62it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0278:   4%|â–ˆâ–                               | 51/1209 [00:19<07:23,  2.61it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0146:   5%|â–ˆâ–Œ                               | 56/1209 [00:21<07:36,  2.52it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0183:   5%|â–ˆâ–‹                               | 62/1209 [00:23<07:22,  2.59it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 1.0376:   6%|â–ˆâ–Š                               | 67/1209 [00:25<07:13,  2.64it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0233:   6%|â–ˆâ–‰                               | 72/1209 [00:27<07:13,  2.62it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0221:   6%|â–ˆâ–ˆ                               | 77/1209 [00:29<07:27,  2.53it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0206:   7%|â–ˆâ–ˆâ–Ž                              | 83/1209 [00:31<07:11,  2.61it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0220:   7%|â–ˆâ–ˆâ–                              | 88/1209 [00:33<07:07,  2.62it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0210:   8%|â–ˆâ–ˆâ–Œ                              | 93/1209 [00:35<07:00,  2.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0210:   8%|â–ˆâ–ˆâ–Œ                              | 93/1209 [00:35<07:00,  2.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
lambda_max: 10824.427734375 lrs: tensor([2.8754e-02, 2.5510e-02, 1.1319e-02, 8.3840e-03, 1.9161e-03, 7.5922e-04,
        7.0760e-04, 3.3412e-04, 2.9301e-04, 9.2384e-05]) eigenvals: tensor([   34.7778,    39.2004,    88.3479,   119.2746,   521.9033,  1317.1471,
Epoch: 1, Loss: 0.0136:   8%|â–ˆâ–ˆâ–                            | 96/1209 [01:25<2:21:08,  7.61s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0154:   8%|â–ˆâ–ˆâ–‹                             | 100/1209 [01:27<39:39,  2.15s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 1.1049:   9%|â–ˆâ–ˆâ–Š                             | 105/1209 [01:29<13:05,  1.41it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0277:   9%|â–ˆâ–ˆâ–‰                             | 110/1209 [01:31<08:34,  2.13it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0167:  10%|â–ˆâ–ˆâ–ˆ                             | 115/1209 [01:33<07:50,  2.33it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0211:  10%|â–ˆâ–ˆâ–ˆâ–                            | 119/1209 [01:35<07:41,  2.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0265:  10%|â–ˆâ–ˆâ–ˆâ–Ž                            | 124/1209 [01:37<07:39,  2.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0520:  11%|â–ˆâ–ˆâ–ˆâ–                            | 129/1209 [01:39<07:38,  2.35it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.1027:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 134/1209 [01:41<07:30,  2.39it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0523:  11%|â–ˆâ–ˆâ–ˆâ–‹                            | 138/1209 [01:43<07:47,  2.29it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0179:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 143/1209 [01:46<07:52,  2.26it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0290:  12%|â–ˆâ–ˆâ–ˆâ–‰                            | 147/1209 [01:47<07:45,  2.28it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0466:  13%|â–ˆâ–ˆâ–ˆâ–ˆ                            | 152/1209 [01:49<07:21,  2.39it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0196:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 157/1209 [01:51<07:19,  2.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.1391:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 161/1209 [01:53<07:46,  2.25it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0646:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 166/1209 [01:55<07:19,  2.37it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0179:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 171/1209 [01:57<07:15,  2.38it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0367:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 175/1209 [01:59<07:54,  2.18it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0609:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 180/1209 [02:01<07:21,  2.33it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0087:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                           | 185/1209 [02:04<07:16,  2.35it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0264:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                           | 187/1209 [02:04<07:10,  2.38it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0264:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                           | 187/1209 [02:04<07:10,  2.38it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
lambda_max: 28117.103515625 lrs: tensor([9.2632e-04, 7.5210e-04, 7.4747e-04, 7.2632e-04, 7.2380e-04, 5.1624e-04,
        5.0240e-04, 2.6012e-04, 4.8754e-05, 3.5566e-05]) eigenvals: tensor([ 1079.5438,  1329.6135,  1337.8533,  1376.7979,  1381.5880,  1937.0813,
Epoch: 1, Loss: 1.9015:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 191/1209 [02:58<1:36:41,  5.70s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0256:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 196/1209 [02:59<21:40,  1.28s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0231:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 202/1209 [03:02<08:08,  2.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0169:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 207/1209 [03:04<06:34,  2.54it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0492:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                          | 212/1209 [03:05<06:16,  2.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.1773:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 218/1209 [03:08<06:09,  2.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.3468:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 223/1209 [03:10<06:09,  2.67it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.2847:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 228/1209 [03:11<06:12,  2.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 1.6727:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 234/1209 [03:14<06:10,  2.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.3989:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 239/1209 [03:16<06:08,  2.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0121:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 244/1209 [03:18<06:07,  2.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.1398:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [03:19<06:03,  2.64it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.3045:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 251/1209 [03:24<17:22,  1.09s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.3927:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 257/1209 [03:26<07:15,  2.18it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.1599:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 262/1209 [03:28<06:08,  2.57it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0766:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 267/1209 [03:30<05:57,  2.64it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0186:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 273/1209 [03:32<05:50,  2.67it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0208:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 278/1209 [03:34<05:51,  2.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 1.432511568069458, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715449688.3809104})..
Epoch: 1, Loss: 0.0341:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 279/1209 [03:34<05:50,  2.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0341:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 279/1209 [03:34<05:50,  2.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
lambda_max: 7152.22802734375 lrs: tensor([0.0044, 0.0041, 0.0028, 0.0016, 0.0013, 0.0008, 0.0007, 0.0007, 0.0002,
        0.0001]) eigenvals: tensor([ 227.7725,  241.6042,  360.0514,  630.0107,  764.2546, 1178.5488,
Epoch: 1, Loss: 0.0238:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 284/1209 [04:26<1:58:41,  7.70s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0412:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 289/1209 [04:28<25:09,  1.64s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0636:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 294/1209 [04:30<09:33,  1.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.7056:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 298/1209 [04:32<07:16,  2.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0073:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 303/1209 [04:34<07:07,  2.12it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0350:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 308/1209 [04:36<06:22,  2.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.6231:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 312/1209 [04:38<06:15,  2.39it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0911:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 317/1209 [04:40<06:19,  2.35it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0807:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 322/1209 [04:42<06:16,  2.35it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0054:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 327/1209 [04:44<06:10,  2.38it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0439:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 332/1209 [04:46<06:10,  2.37it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.5289:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 338/1209 [04:49<06:03,  2.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0684:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 342/1209 [04:50<06:01,  2.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0518:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 346/1209 [04:52<06:03,  2.38it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0188:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 351/1209 [04:54<05:58,  2.39it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.1450:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 356/1209 [04:56<06:02,  2.35it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0482:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 360/1209 [04:58<05:57,  2.38it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 1.3640:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 365/1209 [05:00<05:55,  2.37it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0284:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 370/1209 [05:02<05:53,  2.38it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0139:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 375/1209 [05:04<06:07,  2.27it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0139:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 375/1209 [05:04<06:07,  2.27it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
lambda_max: 11.485599517822266 lrs: tensor([1.6611, 1.6176, 1.3632, 1.2531, 1.2193, 0.6761, 0.6477, 0.6006, 0.2415,
        0.0871]) eigenvals: tensor([ 0.6020,  0.6182,  0.7336,  0.7980,  0.8201,  1.4791,  1.5440,  1.6651,
Epoch: 1, Loss: 0.0341:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 379/1209 [05:58<1:20:07,  5.79s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0254:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 384/1209 [06:00<17:38,  1.28s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.2503:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 390/1209 [06:02<06:31,  2.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0107:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 395/1209 [06:04<05:41,  2.38it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0143:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 400/1209 [06:06<05:15,  2.56it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.3936:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 405/1209 [06:08<04:56,  2.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0234:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 410/1209 [06:10<05:10,  2.58it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0961:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 416/1209 [06:12<04:58,  2.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0384:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 421/1209 [06:14<04:55,  2.67it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0707:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 426/1209 [06:16<04:49,  2.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0092:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 432/1209 [06:18<04:48,  2.70it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0143:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 437/1209 [06:20<04:50,  2.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0548:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                    | 443/1209 [06:23<04:45,  2.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0950:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 448/1209 [06:24<04:56,  2.57it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.4252:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 453/1209 [06:26<04:48,  2.62it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0482:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 458/1209 [06:28<04:42,  2.66it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0343:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 463/1209 [06:30<05:00,  2.48it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0442:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 468/1209 [06:32<04:53,  2.53it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0512:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 469/1209 [06:33<04:48,  2.56it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0325:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 470/1209 [07:23<3:09:00, 15.35s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0325:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 470/1209 [07:23<3:09:00, 15.35s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
lambda_max: 4680.35498046875 lrs: tensor([0.0067, 0.0062, 0.0052, 0.0051, 0.0023, 0.0020, 0.0009, 0.0005, 0.0002,
        0.0002]) eigenvals: tensor([ 150.0381,  160.5613,  193.8618,  197.1578,  432.0984,  497.2869,
Epoch: 1, Loss: 0.8344:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 474/1209 [07:25<49:29,  4.04s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0522:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 479/1209 [07:27<12:50,  1.06s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0352:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 483/1209 [07:29<07:05,  1.71it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0494:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 488/1209 [07:31<05:49,  2.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0325:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 492/1209 [07:33<05:36,  2.13it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0200:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 497/1209 [07:35<05:08,  2.31it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0643:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [07:36<05:07,  2.31it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.08198137581348419, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715450096.3668747}).49688.3809104})..
Epoch: 1, Loss: 0.0643:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [07:36<05:07,  2.31it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0643:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [07:36<05:07,  2.31it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Validation at Global Step: 500, Validation Loss: 0.6626: 100%|â–ˆ| 121/121 [00:03<00:00, 32.11it/s/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Validation at Global Step: 500, Validation Loss: 0.6626: 100%|â–ˆ| 121/121 [00:03<00:00, 32.11it/s/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
An exception occurred:
Returning None...
[33m[W 2024-05-11 17:59:20,557][39m Trial 56 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 32.11it/s/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
[33m[W 2024-05-11 17:59:20,557][39m Trial 56 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 32.11it/s/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 1.2371:   1%|â–                                | 15/1209 [00:05<07:16,  2.74it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0065:   2%|â–Œ                                | 21/1209 [00:07<06:37,  2.99it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0748:   2%|â–‹                                | 26/1209 [00:08<06:42,  2.94it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0046:   3%|â–Š                                | 32/1209 [00:11<06:45,  2.90it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0222:   3%|â–ˆ                                | 38/1209 [00:13<06:30,  3.00it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0119:   4%|â–ˆâ–                               | 44/1209 [00:15<06:27,  3.00it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0136:   4%|â–ˆâ–                               | 51/1209 [00:17<06:17,  3.07it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.2176:   5%|â–ˆâ–Œ                               | 57/1209 [00:19<06:22,  3.01it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 2.2544:   5%|â–ˆâ–‹                               | 63/1209 [00:21<06:25,  2.98it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.2829:   6%|â–ˆâ–Š                               | 68/1209 [00:23<06:54,  2.75it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0946:   6%|â–ˆâ–ˆ                               | 74/1209 [00:25<06:53,  2.75it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0971:   7%|â–ˆâ–ˆâ–                              | 79/1209 [00:27<06:42,  2.81it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0361:   7%|â–ˆâ–ˆâ–Ž                              | 86/1209 [00:29<06:10,  3.03it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0562:   8%|â–ˆâ–ˆâ–Œ                              | 92/1209 [00:31<06:05,  3.06it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0486:   8%|â–ˆâ–ˆâ–‹                              | 98/1209 [00:33<06:23,  2.89it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0349:   9%|â–ˆâ–ˆâ–Š                             | 104/1209 [00:35<06:12,  2.96it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0357:   9%|â–ˆâ–ˆâ–‰                             | 110/1209 [00:37<06:02,  3.03it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.1313:  10%|â–ˆâ–ˆâ–ˆ                             | 116/1209 [00:39<06:09,  2.96it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0487:  10%|â–ˆâ–ˆâ–ˆâ–                            | 121/1209 [00:41<06:36,  2.74it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0241:  11%|â–ˆâ–ˆâ–ˆâ–Ž                            | 127/1209 [00:43<06:04,  2.97it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0244:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 133/1209 [00:45<06:00,  2.99it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0206:  11%|â–ˆâ–ˆâ–ˆâ–‹                            | 138/1209 [00:46<05:58,  2.99it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0206:  11%|â–ˆâ–ˆâ–ˆâ–‹                            | 138/1209 [00:46<05:58,  2.99it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0554:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 143/1209 [01:13<37:45,  2.13s/it]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0361:  12%|â–ˆâ–ˆâ–ˆâ–‰                            | 149/1209 [01:15<09:32,  1.85it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0468:  13%|â–ˆâ–ˆâ–ˆâ–ˆ                            | 155/1209 [01:17<06:12,  2.83it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0438:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 161/1209 [01:19<05:46,  3.02it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.6857:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 167/1209 [01:21<05:48,  2.99it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0296:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 173/1209 [01:23<06:17,  2.75it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0353:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 178/1209 [01:25<06:03,  2.83it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0337:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 184/1209 [01:27<05:40,  3.01it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0382:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 190/1209 [01:29<05:42,  2.97it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.2059:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 196/1209 [01:31<05:33,  3.04it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0459:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 202/1209 [01:33<05:53,  2.85it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0250:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                          | 208/1209 [01:35<05:40,  2.94it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.3087:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 214/1209 [01:37<05:36,  2.96it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.1505:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 220/1209 [01:39<05:40,  2.90it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 1.0908:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 226/1209 [01:41<05:25,  3.02it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0520:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 232/1209 [01:43<05:20,  3.05it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.9033:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 238/1209 [01:45<05:17,  3.05it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.2875:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 244/1209 [01:47<05:17,  3.04it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0267:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [01:49<05:13,  3.06it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0809:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 252/1209 [01:53<13:30,  1.18it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0264:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 258/1209 [01:55<06:10,  2.57it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0202:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 264/1209 [01:57<05:22,  2.93it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.0341:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 270/1209 [01:59<05:07,  3.06it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.2408:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 276/1209 [02:01<05:05,  3.05it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.7}).49688.3809104})..
Epoch: 1, Loss: 0.2408:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 276/1209 [02:01<05:05,  3.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.2408:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 276/1209 [02:01<05:05,  3.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0267:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 283/1209 [02:27<23:32,  1.53s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 1.0949:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 289/1209 [02:29<07:05,  2.16it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0206:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 295/1209 [02:31<05:08,  2.96it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0392:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 301/1209 [02:33<05:16,  2.87it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0373:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 307/1209 [02:35<04:51,  3.10it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.2906:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 313/1209 [02:37<04:58,  3.01it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.1164:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 319/1209 [02:39<04:59,  2.97it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.1909:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 325/1209 [02:41<04:53,  3.01it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.3601:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 331/1209 [02:43<04:46,  3.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0320:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 338/1209 [02:45<04:45,  3.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.1195:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 344/1209 [02:47<04:41,  3.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 1.4427:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 350/1209 [02:49<04:41,  3.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0267:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 356/1209 [02:51<04:36,  3.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.2497:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 362/1209 [02:53<04:33,  3.10it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0263:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 368/1209 [02:55<04:31,  3.10it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0324:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 375/1209 [02:57<04:28,  3.10it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0191:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 381/1209 [02:59<04:29,  3.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0257:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 387/1209 [03:01<04:25,  3.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0448:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 393/1209 [03:03<04:23,  3.10it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0389:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 399/1209 [03:05<04:21,  3.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0236:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 405/1209 [03:07<04:23,  3.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.5757:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 411/1209 [03:09<04:21,  3.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.5487:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 416/1209 [03:11<04:32,  2.91it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.5487:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 416/1209 [03:11<04:32,  2.91it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 1.3096:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 421/1209 [03:37<27:50,  2.12s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.4037:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 427/1209 [03:39<06:59,  1.86it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0426:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 433/1209 [03:41<04:46,  2.70it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0279:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 439/1209 [03:43<04:12,  3.04it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0281:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 445/1209 [03:45<04:10,  3.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0139:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 451/1209 [03:47<04:23,  2.88it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0205:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 457/1209 [03:49<04:11,  2.99it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0146:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 463/1209 [03:51<03:56,  3.15it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.1408:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 470/1209 [03:54<03:56,  3.12it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.4045:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 476/1209 [03:56<04:18,  2.84it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0205:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 482/1209 [03:58<04:08,  2.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.2533:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 488/1209 [04:00<03:55,  3.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0348:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 493/1209 [04:01<03:49,  3.12it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0341:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [04:03<03:50,  3.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0341:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [04:03<03:50,  3.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0341:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [04:03<03:50,  3.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Validation at Global Step: 500, Validation Loss: 0.0400: 100%|â–ˆ| 121/121 [00:03<00:00, 31.94it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Validation at Global Step: 500, Validation Loss: 0.0400: 100%|â–ˆ| 121/121 [00:03<00:00, 31.94it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
An exception occurred:
Returning None...
[33m[W 2024-05-11 18:03:34,980][39m Trial 57 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 31.94it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
[33m[W 2024-05-11 18:03:34,980][39m Trial 57 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 31.94it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0217:   2%|â–‹                                | 24/1209 [00:05<04:45,  4.16it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0358:   3%|â–Š                                | 32/1209 [00:07<04:44,  4.13it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0269:   3%|â–ˆ                                | 40/1209 [00:09<04:44,  4.11it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0325:   4%|â–ˆâ–Ž                               | 48/1209 [00:11<05:19,  3.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0276:   5%|â–ˆâ–Œ                               | 56/1209 [00:13<04:40,  4.10it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.2107:   5%|â–ˆâ–Š                               | 65/1209 [00:15<04:31,  4.21it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0272:   6%|â–ˆâ–‰                               | 73/1209 [00:17<04:30,  4.20it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0308:   7%|â–ˆâ–ˆâ–                              | 82/1209 [00:19<04:33,  4.11it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0251:   7%|â–ˆâ–ˆâ–                              | 90/1209 [00:21<04:35,  4.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0276:   8%|â–ˆâ–ˆâ–‹                              | 98/1209 [00:23<04:29,  4.12it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0346:   9%|â–ˆâ–ˆâ–Š                             | 106/1209 [00:25<04:28,  4.10it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0514:   9%|â–ˆâ–ˆâ–ˆ                             | 114/1209 [00:27<04:44,  3.85it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0275:  10%|â–ˆâ–ˆâ–ˆ                             | 115/1209 [00:28<04:36,  3.96it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0275:  10%|â–ˆâ–ˆâ–ˆ                             | 115/1209 [00:28<04:36,  3.96it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
An exception occurred:
index 0 is out of bounds for dimension 0 with size 0
Returning None...
Epoch: 1, Loss: 0.0275:  10%|â–ˆâ–ˆâ–ˆ                             | 115/1209 [00:30<04:48,  3.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0396:   0%|â–                                 | 5/1209 [00:02<11:31,  1.74it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.9752:   1%|â–Ž                                 | 9/1209 [00:05<11:29,  1.74it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 1.5832:   1%|â–Ž                                | 13/1209 [00:07<11:10,  1.78it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.8992:   1%|â–                                | 16/1209 [00:09<11:04,  1.79it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0313:   2%|â–Œ                                | 20/1209 [00:11<11:10,  1.77it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0410:   2%|â–‹                                | 23/1209 [00:13<11:03,  1.79it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.9107:   2%|â–‹                                | 27/1209 [00:15<10:55,  1.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0386:   3%|â–Š                                | 31/1209 [00:17<10:41,  1.84it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.2013:   3%|â–‰                                | 34/1209 [00:19<10:32,  1.86it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.8507:   3%|â–ˆ                                | 38/1209 [00:21<10:25,  1.87it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0540:   3%|â–ˆâ–                               | 42/1209 [00:23<10:21,  1.88it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.1254:   4%|â–ˆâ–Ž                               | 46/1209 [00:25<10:04,  1.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.1402:   4%|â–ˆâ–Ž                               | 50/1209 [00:27<09:52,  1.95it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0319:   4%|â–ˆâ–                               | 54/1209 [00:29<09:51,  1.95it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0364:   5%|â–ˆâ–Œ                               | 58/1209 [00:31<09:45,  1.97it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.9176:   5%|â–ˆâ–‹                               | 62/1209 [00:33<09:47,  1.95it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0374:   5%|â–ˆâ–Š                               | 66/1209 [00:35<09:45,  1.95it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.8933:   6%|â–ˆâ–‰                               | 69/1209 [00:37<09:40,  1.97it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.9096:   6%|â–ˆâ–‰                               | 73/1209 [00:39<09:38,  1.96it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0465:   6%|â–ˆâ–ˆ                               | 76/1209 [00:40<09:39,  1.96it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0465:   6%|â–ˆâ–ˆ                               | 76/1209 [00:40<09:39,  1.96it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
lambda_max: 4.192853927612305 lrs: tensor([1.3111, 1.2860, 1.2501, 1.2329, 1.1985, 1.1485, 1.1483, 1.0968, 1.0824,
        1.0423, 1.0081, 0.9649, 0.9454, 0.8506, 0.7002, 0.6586, 0.6216, 0.5553,
        0.4252, 0.2385]) eigenvals: tensor([0.7627, 0.7776, 0.7999, 0.8111, 0.8344, 0.8707, 0.8708, 0.9117, 0.9239,
        0.9594, 0.9920, 1.0364, 1.0577, 1.1756, 1.4282, 1.5185, 1.6088, 1.8008,
Epoch: 1, Loss: 0.8353:   7%|â–ˆâ–ˆ                             | 80/1209 [03:48<6:09:19, 19.63s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0395:   7%|â–ˆâ–ˆâ–                            | 83/1209 [03:49<2:13:16,  7.10s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.8419:   7%|â–ˆâ–ˆâ–Ž                              | 86/1209 [03:51<53:33,  2.86s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0415:   7%|â–ˆâ–ˆâ–                              | 90/1209 [03:54<21:44,  1.17s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.1610:   8%|â–ˆâ–ˆâ–Œ                              | 93/1209 [03:56<15:04,  1.23it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0463:   8%|â–ˆâ–ˆâ–Œ                              | 96/1209 [03:58<12:30,  1.48it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.1581:   8%|â–ˆâ–ˆâ–‹                              | 99/1209 [03:59<11:31,  1.61it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0566:   9%|â–ˆâ–ˆâ–‹                             | 103/1209 [04:02<11:03,  1.67it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0437:   9%|â–ˆâ–ˆâ–Š                             | 106/1209 [04:03<10:27,  1.76it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.1374:   9%|â–ˆâ–ˆâ–‰                             | 110/1209 [04:06<10:17,  1.78it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.8362:   9%|â–ˆâ–ˆâ–ˆ                             | 114/1209 [04:08<10:26,  1.75it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0546:  10%|â–ˆâ–ˆâ–ˆ                             | 117/1209 [04:10<10:16,  1.77it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 1.0786:  10%|â–ˆâ–ˆâ–ˆâ–                            | 121/1209 [04:12<10:13,  1.77it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.6941:  10%|â–ˆâ–ˆâ–ˆâ–Ž                            | 124/1209 [04:14<10:09,  1.78it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.6615:  11%|â–ˆâ–ˆâ–ˆâ–                            | 128/1209 [04:16<10:06,  1.78it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0821:  11%|â–ˆâ–ˆâ–ˆâ–                            | 131/1209 [04:18<10:07,  1.77it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.1992:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 135/1209 [04:20<10:04,  1.78it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0980:  11%|â–ˆâ–ˆâ–ˆâ–‹                            | 139/1209 [04:22<10:00,  1.78it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.7538:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 142/1209 [04:24<10:04,  1.76it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0727:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 146/1209 [04:26<10:01,  1.77it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0581:  12%|â–ˆâ–ˆâ–ˆâ–‰                            | 149/1209 [04:28<09:51,  1.79it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0621:  13%|â–ˆâ–ˆâ–ˆâ–ˆ                            | 153/1209 [04:30<10:04,  1.75it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0621:  13%|â–ˆâ–ˆâ–ˆâ–ˆ                            | 153/1209 [04:30<10:04,  1.75it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
lambda_max: 5.059848308563232 lrs: tensor([1.0835, 1.0606, 1.0449, 1.0233, 0.9989, 0.9857, 0.9686, 0.9668, 0.9503,
        0.8775, 0.8425, 0.8327, 0.7514, 0.7112, 0.5709, 0.5397, 0.5039, 0.4418,
        0.4142, 0.1976]) eigenvals: tensor([0.9229, 0.9428, 0.9570, 0.9772, 1.0011, 1.0145, 1.0324, 1.0344, 1.0523,
        1.1396, 1.1870, 1.2009, 1.3308, 1.4062, 1.7516, 1.8528, 1.9845, 2.2633,
Epoch: 1, Loss: 0.0704:  13%|â–ˆâ–ˆâ–ˆâ–Š                          | 156/1209 [07:36<8:05:43, 27.68s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0411:  13%|â–ˆâ–ˆâ–ˆâ–‰                          | 159/1209 [07:38<2:53:11,  9.90s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0522:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 163/1209 [07:40<48:57,  2.81s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.7641:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 166/1209 [07:42<23:04,  1.33s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.8424:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 170/1209 [07:44<12:43,  1.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.8974:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 174/1209 [07:46<10:17,  1.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0661:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 177/1209 [07:48<09:46,  1.76it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0399:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 181/1209 [07:50<09:36,  1.78it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.7928:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 184/1209 [07:52<09:33,  1.79it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0470:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                           | 188/1209 [07:54<09:43,  1.75it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0731:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 192/1209 [07:56<09:26,  1.79it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0624:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 195/1209 [07:58<09:24,  1.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0700:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 199/1209 [08:00<09:42,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.2012:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 202/1209 [08:02<09:27,  1.77it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0501:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 206/1209 [08:04<09:15,  1.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.1381:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                          | 209/1209 [08:06<09:27,  1.76it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0361:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 213/1209 [08:08<09:26,  1.76it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 1.1730:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 217/1209 [08:10<09:11,  1.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0336:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 220/1209 [08:12<09:08,  1.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0244:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 224/1209 [08:14<09:02,  1.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.3094:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 227/1209 [08:16<09:05,  1.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0498:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 230/1209 [08:18<09:00,  1.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0498:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 230/1209 [08:18<09:00,  1.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
lambda_max: 2.104759454727173 lrs: tensor([3.2515, 3.1741, 3.1030, 2.9576, 2.8870, 2.7800, 2.6579, 2.6519, 2.6138,
        2.5695, 2.5176, 2.3921, 2.2848, 1.8023, 1.6310, 1.4958, 1.3663, 1.2673,
        1.1808, 0.4751]) eigenvals: tensor([0.3076, 0.3151, 0.3223, 0.3381, 0.3464, 0.3597, 0.3762, 0.3771, 0.3826,
        0.3892, 0.3972, 0.4180, 0.4377, 0.5549, 0.6131, 0.6685, 0.7319, 0.7891,
Epoch: 1, Loss: 0.0242:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 232/1209 [11:21<10:32:12, 38.83s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 1.0310:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 236/1209 [11:23<2:37:59,  9.74s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0370:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 239/1209 [11:25<59:53,  3.70s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0515:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 243/1209 [11:27<21:06,  1.31s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0613:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 247/1209 [11:29<11:47,  1.36it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.1637:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [11:30<10:19,  1.55it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0487:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 251/1209 [11:35<21:27,  1.34s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0725:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 255/1209 [11:37<11:50,  1.34it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0433:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 258/1209 [11:39<09:44,  1.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0276:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 262/1209 [11:41<09:03,  1.74it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0525:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 266/1209 [11:43<08:47,  1.79it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0230:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 269/1209 [11:45<08:42,  1.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.7495718598365784, 'F1_Macro/Train': 0.8, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.6666666666666666, 'MAE/Train': 0.25, 'MCC/Train': 0.5773502691896258, '_timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0255:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 271/1209 [11:46<08:35,  1.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0201:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 277/1209 [11:49<08:38,  1.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0892:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 280/1209 [11:51<08:36,  1.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.2512:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 284/1209 [11:53<08:32,  1.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.9754:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 287/1209 [11:55<08:32,  1.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0648:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 291/1209 [11:57<08:31,  1.79it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.8495:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 295/1209 [11:59<08:19,  1.83it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.1722:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 298/1209 [12:01<08:15,  1.84it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.1968:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 302/1209 [12:03<08:10,  1.85it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.1020:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 306/1209 [12:05<08:05,  1.86it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0807:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 307/1209 [12:06<08:02,  1.87it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0807:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 307/1209 [12:06<08:02,  1.87it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
lambda_max: 5.859373092651367 lrs: tensor([0.8808, 0.8502, 0.8139, 0.7984, 0.7818, 0.7701, 0.7539, 0.7285, 0.7212,
        0.7090, 0.7068, 0.6788, 0.6609, 0.6206, 0.5171, 0.5016, 0.4728, 0.4541,
        0.4021, 0.1707]) eigenvals: tensor([1.1354, 1.1762, 1.2287, 1.2525, 1.2792, 1.2985, 1.3265, 1.3726, 1.3866,
        1.4104, 1.4147, 1.4733, 1.5130, 1.6114, 1.9340, 1.9935, 2.1149, 2.2020,
Epoch: 1, Loss: 0.2618:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 309/1209 [15:09<9:42:19, 38.82s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0656:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 313/1209 [15:12<2:25:55,  9.77s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.7601:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 316/1209 [15:13<55:36,  3.74s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0440:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 319/1209 [15:15<24:52,  1.68s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.7800:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 323/1209 [15:18<12:24,  1.19it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.1330:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 327/1209 [15:20<08:58,  1.64it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0464:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 330/1209 [15:21<08:12,  1.78it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0562:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 334/1209 [15:23<07:53,  1.85it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.8859:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 338/1209 [15:26<07:50,  1.85it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0431:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 341/1209 [15:27<08:10,  1.77it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 1.4044:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 345/1209 [15:29<07:44,  1.86it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0408:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 350/1209 [15:32<08:02,  1.78it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.1545:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 353/1209 [15:34<08:11,  1.74it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0284:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 357/1209 [15:36<08:16,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0590:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 360/1209 [15:38<07:57,  1.78it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0308:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 364/1209 [15:40<07:36,  1.85it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0317:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 368/1209 [15:42<07:41,  1.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.1293:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 371/1209 [15:44<07:43,  1.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0299:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 375/1209 [15:46<07:39,  1.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0359:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 378/1209 [15:48<07:54,  1.75it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0176:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 382/1209 [15:50<07:34,  1.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0194:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 384/1209 [15:51<07:27,  1.84it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0238:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 386/1209 [18:57<8:58:38, 39.27s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0238:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 386/1209 [18:57<8:58:38, 39.27s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
lambda_max: 1.5937654972076416 lrs: tensor([4.2496, 3.9112, 3.8953, 3.8507, 3.6956, 3.6088, 3.4209, 3.3223, 3.2210,
        3.1837, 3.0562, 3.0481, 2.8733, 2.8117, 2.5915, 2.4778, 2.3489, 1.8485,
        1.5968, 0.6274]) eigenvals: tensor([0.2353, 0.2557, 0.2567, 0.2597, 0.2706, 0.2771, 0.2923, 0.3010, 0.3105,
        0.3141, 0.3272, 0.3281, 0.3480, 0.3557, 0.3859, 0.4036, 0.4257, 0.5410,
Epoch: 1, Loss: 1.3185:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                    | 389/1209 [18:58<3:08:50, 13.82s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0361:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 393/1209 [19:00<50:32,  3.72s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0344:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 396/1209 [19:02<22:34,  1.67s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0449:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 400/1209 [19:05<11:34,  1.17it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0249:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 403/1209 [19:06<09:19,  1.44it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 1.0678:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 406/1209 [19:08<08:30,  1.57it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0427:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 410/1209 [19:11<08:11,  1.63it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.8600:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 413/1209 [19:12<07:57,  1.67it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0382:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 416/1209 [19:14<07:50,  1.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0488:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 420/1209 [19:16<07:18,  1.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0363:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 424/1209 [19:18<07:02,  1.86it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0264:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 428/1209 [19:21<06:59,  1.86it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0328:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 431/1209 [19:22<06:50,  1.89it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0266:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 435/1209 [19:25<07:31,  1.72it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0336:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 438/1209 [19:26<07:26,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.8498:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                    | 442/1209 [19:28<06:54,  1.85it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0439:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 446/1209 [19:31<06:47,  1.87it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0321:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 450/1209 [19:33<06:50,  1.85it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.9253:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 453/1209 [19:34<07:02,  1.79it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0250:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 457/1209 [19:37<06:53,  1.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0191:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 461/1209 [19:39<06:39,  1.87it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0191:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 461/1209 [19:39<06:39,  1.87it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
lambda_max: 1.9728809595108032 lrs: tensor([3.2183, 3.0539, 3.0329, 2.9560, 2.7795, 2.6889, 2.6730, 2.6496, 2.5010,
        2.3669, 2.3036, 2.1964, 2.0789, 2.0522, 2.0385, 1.8582, 1.7021, 1.3477,
        1.1882, 0.5069]) eigenvals: tensor([0.3107, 0.3274, 0.3297, 0.3383, 0.3598, 0.3719, 0.3741, 0.3774, 0.3998,
        0.4225, 0.4341, 0.4553, 0.4810, 0.4873, 0.4905, 0.5382, 0.5875, 0.7420,
Epoch: 1, Loss: 0.9161:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 463/1209 [22:25<7:17:04, 35.15s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.2089:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 467/1209 [22:27<1:49:38,  8.87s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0242:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 471/1209 [22:29<30:59,  2.52s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0089:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 474/1209 [22:31<14:41,  1.20s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0257:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 479/1209 [22:33<07:45,  1.57it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0253:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 483/1209 [22:35<06:34,  1.84it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.7875:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 487/1209 [22:38<06:47,  1.77it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0351:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 490/1209 [22:39<06:43,  1.78it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0229:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 494/1209 [22:42<06:50,  1.74it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0456:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 497/1209 [22:43<06:40,  1.78it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0376:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [22:44<06:26,  1.84it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0376:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [22:44<06:26,  1.84it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0376:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [22:44<06:26,  1.84it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Validation at Global Step: 500, Validation Loss: 1.0246: 100%|â–ˆ| 121/121 [00:03<00:00, 32.95it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Validation at Global Step: 500, Validation Loss: 1.0246: 100%|â–ˆ| 121/121 [00:03<00:00, 32.95it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
An exception occurred:
Returning None...
[33m[W 2024-05-11 18:27:01,140][39m Trial 59 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 32.95it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
[33m[W 2024-05-11 18:27:01,140][39m Trial 59 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 32.95it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0531:   1%|â–                                | 16/1209 [00:03<04:53,  4.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.8152:   2%|â–‹                                | 24/1209 [00:05<04:52,  4.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0284:   3%|â–Š                                | 32/1209 [00:07<04:54,  3.99it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.2576:   3%|â–ˆ                                | 40/1209 [00:09<04:48,  4.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0404:   4%|â–ˆâ–Ž                               | 48/1209 [00:11<04:58,  3.88it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0218:   5%|â–ˆâ–Œ                               | 56/1209 [00:14<04:54,  3.91it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0237:   5%|â–ˆâ–‹                               | 63/1209 [00:15<05:01,  3.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0281:   6%|â–ˆâ–Š                               | 67/1209 [00:16<05:12,  3.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0281:   6%|â–ˆâ–Š                               | 67/1209 [00:16<05:12,  3.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0432:   6%|â–ˆâ–Š                               | 68/1209 [00:21<30:01,  1.58s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0230:   6%|â–ˆâ–ˆâ–                              | 78/1209 [00:24<05:21,  3.52it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.8669:   7%|â–ˆâ–ˆâ–Ž                              | 86/1209 [00:26<04:46,  3.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0402:   8%|â–ˆâ–ˆâ–Œ                              | 94/1209 [00:28<04:36,  4.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.7499:   8%|â–ˆâ–ˆâ–‹                             | 102/1209 [00:30<04:44,  3.89it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0458:   9%|â–ˆâ–ˆâ–‰                             | 110/1209 [00:32<04:31,  4.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0449:  10%|â–ˆâ–ˆâ–ˆ                             | 118/1209 [00:34<04:28,  4.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0458:  11%|â–ˆâ–ˆâ–ˆâ–Ž                            | 127/1209 [00:36<04:22,  4.12it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.5979:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 135/1209 [00:38<04:26,  4.02it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.5979:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 135/1209 [00:38<04:26,  4.02it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.1230:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 142/1209 [00:44<07:00,  2.54it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0513:  12%|â–ˆâ–ˆâ–ˆâ–‰                            | 150/1209 [00:46<04:35,  3.84it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0575:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 158/1209 [00:48<04:22,  4.01it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0452:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 166/1209 [00:50<04:11,  4.15it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 1.5575:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 174/1209 [00:52<04:29,  3.85it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0260:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 182/1209 [00:54<04:14,  4.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0376:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 190/1209 [00:56<04:06,  4.14it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.7678:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 199/1209 [00:58<04:03,  4.15it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.7914:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 203/1209 [00:59<04:08,  4.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.7914:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 203/1209 [00:59<04:08,  4.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0377:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 206/1209 [01:04<14:15,  1.17it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0680:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 215/1209 [01:06<04:24,  3.76it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0432:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 223/1209 [01:08<03:57,  4.15it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0583:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 231/1209 [01:10<03:54,  4.16it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0474:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 239/1209 [01:12<03:58,  4.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.3544:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 248/1209 [01:14<03:54,  4.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.4057:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [01:14<03:54,  4.10it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.0673:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 251/1209 [01:18<14:46,  1.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.3468:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 259/1209 [01:20<04:28,  3.54it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.05469432845711708, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715451340.63751}).timestamp': 1715450473.7074797}).
Epoch: 1, Loss: 0.7242:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 263/1209 [01:21<04:02,  3.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0388:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 271/1209 [01:23<03:44,  4.18it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0388:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 271/1209 [01:23<03:44,  4.18it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.9031:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 275/1209 [01:28<10:16,  1.52it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0730:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 284/1209 [01:30<03:57,  3.89it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.1728:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 292/1209 [01:32<03:46,  4.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0480:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 300/1209 [01:34<03:43,  4.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0661:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 308/1209 [01:36<03:40,  4.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0354:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 316/1209 [01:38<03:35,  4.14it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0585:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 324/1209 [01:40<03:54,  3.77it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0333:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 331/1209 [01:42<03:50,  3.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0691:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 339/1209 [01:44<03:42,  3.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0691:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 339/1209 [01:44<03:42,  3.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0501:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 345/1209 [01:50<07:13,  1.99it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0437:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 352/1209 [01:52<04:18,  3.31it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0447:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 360/1209 [01:54<03:31,  4.02it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0348:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 368/1209 [01:56<03:32,  3.95it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.2164:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 376/1209 [01:58<03:27,  4.02it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0310:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 384/1209 [02:00<03:22,  4.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 1.0288:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 392/1209 [02:02<03:27,  3.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0294:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 401/1209 [02:04<03:21,  4.01it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0232:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 407/1209 [02:06<03:17,  4.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0244:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 408/1209 [02:10<19:40,  1.47s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0244:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 408/1209 [02:10<19:40,  1.47s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0248:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 416/1209 [02:12<04:35,  2.88it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0238:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 423/1209 [02:14<03:41,  3.55it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0306:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 431/1209 [02:16<03:11,  4.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0241:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 439/1209 [02:18<03:10,  4.05it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0204:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 448/1209 [02:20<03:06,  4.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0553:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 456/1209 [02:22<03:02,  4.12it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0527:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 464/1209 [02:24<03:03,  4.07it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.1692:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 472/1209 [02:26<03:04,  4.00it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0434:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 475/1209 [02:27<02:59,  4.10it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0434:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 475/1209 [02:27<02:59,  4.10it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0356:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 480/1209 [02:32<06:38,  1.83it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0311:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 488/1209 [02:34<03:08,  3.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0401:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 496/1209 [02:36<02:55,  4.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0432:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [02:37<02:50,  4.16it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0432:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [02:37<02:50,  4.16it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Validation at Global Step: 500, Validation Loss: 2.1514: 100%|â–ˆ| 121/121 [00:03<00:00, 32.94it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
[33m[W 2024-05-11 18:29:49,180][39m Trial 60 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 32.94it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
[33m[W 2024-05-11 18:29:49,180][39m Trial 60 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 32.94it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
An exception occurred:
Returning None...
Returned ESE function. Lanczos order (m) is 76 .
Epoch: 1, Loss: 0.0231:   1%|â–                                 | 8/1209 [00:04<11:15,  1.78it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.1857:   1%|â–Ž                                | 11/1209 [00:06<11:01,  1.81it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0328:   1%|â–                                | 15/1209 [00:08<10:54,  1.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0271:   2%|â–Œ                                | 19/1209 [00:10<10:00,  1.98it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0404:   2%|â–‹                                | 23/1209 [00:12<09:44,  2.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0191:   2%|â–‹                                | 27/1209 [00:14<10:14,  1.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0175:   3%|â–Š                                | 31/1209 [00:16<09:47,  2.01it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0170:   3%|â–‰                                | 35/1209 [00:18<09:39,  2.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0139:   3%|â–ˆ                                | 39/1209 [00:20<10:14,  1.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 1.1707:   4%|â–ˆâ–                               | 43/1209 [00:22<09:42,  2.00it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.1681:   4%|â–ˆâ–Ž                               | 47/1209 [00:24<09:33,  2.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 1.0648:   4%|â–ˆâ–                               | 51/1209 [00:26<09:29,  2.03it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 1.0623:   5%|â–ˆâ–Œ                               | 55/1209 [00:28<09:30,  2.02it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0400:   5%|â–ˆâ–Œ                               | 57/1209 [00:29<09:29,  2.02it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0248:   5%|â–ˆâ–                            | 58/1209 [02:52<13:53:08, 43.43s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0248:   5%|â–ˆâ–                            | 58/1209 [02:52<13:53:08, 43.43s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
lambda_max: 7698.08935546875 lrs: tensor([1.4168e+00, 1.3547e+00, 1.3534e+00, 9.1011e-01, 8.7231e-01, 8.0951e-01,
        5.9115e-01, 2.6156e-01, 2.5903e-01, 1.8806e-01, 7.6614e-02, 2.7202e-02,
        1.2783e-02, 9.3557e-03, 6.0491e-03, 2.3313e-03, 2.8733e-04, 2.2738e-04,
        1.2990e-04]) eigenvals: tensor([7.0581e-01, 7.3818e-01, 7.3890e-01, 1.0988e+00, 1.1464e+00, 1.2353e+00,
        1.6916e+00, 3.8232e+00, 3.8606e+00, 5.3174e+00, 1.3052e+01, 3.6762e+01,
        7.8228e+01, 1.0689e+02, 1.6531e+02, 4.2895e+02, 3.4803e+03, 4.3978e+03,
Epoch: 1, Loss: 0.0250:   5%|â–ˆâ–Œ                             | 61/1209 [02:54<4:52:00, 15.26s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0351:   5%|â–ˆâ–‹                             | 65/1209 [02:56<1:17:32,  4.07s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.3693:   6%|â–ˆâ–‰                               | 70/1209 [02:59<21:11,  1.12s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.2588:   6%|â–ˆâ–ˆ                               | 74/1209 [03:01<12:37,  1.50it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.1342:   6%|â–ˆâ–ˆ                               | 77/1209 [03:03<10:46,  1.75it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.1586:   7%|â–ˆâ–ˆâ–                              | 81/1209 [03:04<10:00,  1.88it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0469:   7%|â–ˆâ–ˆâ–Ž                              | 85/1209 [03:06<09:51,  1.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.2367:   7%|â–ˆâ–ˆâ–                              | 89/1209 [03:09<09:50,  1.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0523:   8%|â–ˆâ–ˆâ–Œ                              | 93/1209 [03:11<09:49,  1.89it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.1373:   8%|â–ˆâ–ˆâ–‹                              | 97/1209 [03:13<09:56,  1.86it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.1174:   8%|â–ˆâ–ˆâ–‹                             | 100/1209 [03:14<09:45,  1.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0372:   9%|â–ˆâ–ˆâ–Š                             | 104/1209 [03:17<09:37,  1.91it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0565:   9%|â–ˆâ–ˆâ–Š                             | 108/1209 [03:19<09:34,  1.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0317:   9%|â–ˆâ–ˆâ–‰                             | 112/1209 [03:21<09:40,  1.89it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0472:  10%|â–ˆâ–ˆâ–ˆ                             | 115/1209 [03:22<09:34,  1.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0408:  10%|â–ˆâ–ˆâ–‰                           | 118/1209 [05:47<6:31:54, 21.55s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0408:  10%|â–ˆâ–ˆâ–‰                           | 118/1209 [05:47<6:31:54, 21.55s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
lambda_max: 7428.3388671875 lrs: tensor([2.1434e-01, 2.0877e-01, 1.9808e-01, 1.9030e-01, 1.8579e-01, 1.8411e-01,
        1.3674e-01, 1.2277e-01, 1.0905e-01, 2.6778e-02, 2.5133e-02, 1.9210e-02,
        1.6979e-02, 3.3684e-03, 1.4015e-03, 4.6565e-04, 4.0828e-04, 4.0130e-04,
        1.3462e-04]) eigenvals: tensor([4.6656e+00, 4.7899e+00, 5.0484e+00, 5.2548e+00, 5.3823e+00, 5.4315e+00,
        7.3134e+00, 8.1450e+00, 9.1701e+00, 3.7343e+01, 3.9789e+01, 5.2057e+01,
        5.8895e+01, 2.9688e+02, 7.1354e+02, 2.1475e+03, 2.4493e+03, 2.4919e+03,
Epoch: 1, Loss: 0.0931:  10%|â–ˆâ–ˆâ–ˆ                           | 121/1209 [05:49<2:20:22,  7.74s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0164:  10%|â–ˆâ–ˆâ–ˆâ–Ž                            | 125/1209 [05:51<40:46,  2.26s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.5426:  11%|â–ˆâ–ˆâ–ˆâ–                            | 129/1209 [05:53<16:56,  1.06it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.8949:  11%|â–ˆâ–ˆâ–ˆâ–Œ                            | 133/1209 [05:55<11:13,  1.60it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0453:  11%|â–ˆâ–ˆâ–ˆâ–‹                            | 137/1209 [05:57<10:17,  1.74it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0702:  12%|â–ˆâ–ˆâ–ˆâ–‹                            | 140/1209 [05:59<09:59,  1.78it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0884:  12%|â–ˆâ–ˆâ–ˆâ–Š                            | 144/1209 [06:01<09:28,  1.87it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.7718:  12%|â–ˆâ–ˆâ–ˆâ–‰                            | 148/1209 [06:03<09:19,  1.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.1164:  13%|â–ˆâ–ˆâ–ˆâ–ˆ                            | 152/1209 [06:05<09:12,  1.91it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 1.4926:  13%|â–ˆâ–ˆâ–ˆâ–ˆ                            | 155/1209 [06:07<09:14,  1.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.5638:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 159/1209 [06:09<09:21,  1.87it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0735:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 163/1209 [06:11<09:12,  1.89it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0820:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 167/1209 [06:13<09:07,  1.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0762:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 171/1209 [06:15<09:09,  1.89it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0803:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 173/1209 [06:16<09:15,  1.87it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0803:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 173/1209 [06:16<09:15,  1.87it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
lambda_max: 368000.6875 lrs: tensor([3.4306e-02, 3.4025e-02, 3.1278e-02, 1.9473e-02, 7.3515e-03, 6.8319e-03,
        6.3757e-03, 2.6409e-03, 1.3775e-03, 1.1891e-03, 4.6847e-04, 7.0243e-05,
        5.2647e-05, 4.2909e-05, 3.7403e-05, 1.2107e-05, 3.9061e-06, 3.1580e-06,
        2.7174e-06]) eigenvals: tensor([2.9149e+01, 2.9390e+01, 3.1971e+01, 5.1354e+01, 1.3603e+02, 1.4637e+02,
        1.5684e+02, 3.7865e+02, 7.2595e+02, 8.4099e+02, 2.1346e+03, 1.4236e+04,
        1.8995e+04, 2.3305e+04, 2.6736e+04, 8.2600e+04, 2.5601e+05, 3.1666e+05,
Epoch: 1, Loss: 0.0746:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–                        | 174/1209 [08:33<11:55:46, 41.49s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0677:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–                         | 177/1209 [08:35<4:10:50, 14.58s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0700:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–                         | 181/1209 [08:37<1:06:59,  3.91s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0447:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                           | 185/1209 [08:39<22:47,  1.34s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0704:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 189/1209 [08:41<12:07,  1.40it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.1920:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 193/1209 [08:43<09:48,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0430:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 197/1209 [08:46<09:07,  1.85it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.7572:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                          | 200/1209 [08:47<09:36,  1.75it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.1419:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 204/1209 [08:49<09:10,  1.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0425:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                          | 208/1209 [08:52<08:51,  1.88it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0571:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                          | 212/1209 [08:54<08:53,  1.87it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0475:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 216/1209 [08:56<08:41,  1.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 1.0872:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 219/1209 [08:58<09:49,  1.68it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0423:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 223/1209 [09:00<09:07,  1.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0509:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                          | 226/1209 [09:02<08:59,  1.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0394:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 230/1209 [09:04<08:40,  1.88it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.3302:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 231/1209 [09:04<08:46,  1.86it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.3302:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 231/1209 [09:04<08:46,  1.86it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
lambda_max: 634034.4375 lrs: tensor([1.8441e-01, 1.8044e-01, 1.4183e-01, 1.2796e-01, 9.6092e-02, 7.1673e-02,
        7.1134e-02, 5.9343e-02, 2.8458e-02, 1.9228e-02, 9.0005e-03, 4.7684e-03,
        4.4651e-03, 2.7966e-03, 1.8007e-03, 1.5546e-03, 1.5677e-05, 7.5632e-06,
        1.5772e-06]) eigenvals: tensor([5.4227e+00, 5.5420e+00, 7.0506e+00, 7.8152e+00, 1.0407e+01, 1.3952e+01,
        1.4058e+01, 1.6851e+01, 3.5140e+01, 5.2008e+01, 1.1110e+02, 2.0971e+02,
        2.2396e+02, 3.5758e+02, 5.5534e+02, 6.4325e+02, 6.3788e+04, 1.3222e+05,
Epoch: 1, Loss: 0.0427:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 234/1209 [11:24<5:38:51, 20.85s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.7985:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 237/1209 [11:26<2:01:20,  7.49s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0621:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 241/1209 [11:28<35:30,  2.20s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0628:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 245/1209 [11:30<14:42,  1.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.1084:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                         | 249/1209 [11:32<09:44,  1.64it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0579:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 251/1209 [11:36<19:57,  1.25s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0457:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                         | 254/1209 [11:38<12:16,  1.30it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0857:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 258/1209 [11:40<09:08,  1.73it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0476:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 262/1209 [11:42<08:51,  1.78it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0322:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 266/1209 [11:44<08:28,  1.86it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.1437:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 270/1209 [11:46<08:13,  1.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.24659618735313416, 'F1_Macro/Train': 0.8571428571428571, 'ACCURACY/Train': 0.75, 'PRECISION/Train': 1.0, 'RECALL/Train': 0.75, 'MAE/Train': 0.25, 'MCC/Train': 0.0, '_timestamp': 1715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0627:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 272/1209 [11:47<08:09,  1.91it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0870:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 277/1209 [11:50<08:02,  1.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.1595:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 281/1209 [11:52<07:59,  1.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0498:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                        | 285/1209 [11:54<07:57,  1.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0401:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                        | 289/1209 [11:56<07:57,  1.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0622:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 290/1209 [14:14<10:40:28, 41.82s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0622:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 290/1209 [14:14<10:40:28, 41.82s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
lambda_max: 4528492.0 lrs: tensor([2.1539e-02, 2.0545e-02, 1.8331e-02, 1.7614e-02, 1.2155e-02, 8.9888e-03,
        5.7142e-03, 3.3918e-03, 2.4843e-03, 9.9197e-04, 9.8136e-04, 4.5900e-04,
        3.6562e-04, 3.0809e-04, 2.8284e-04, 1.1560e-05, 3.2429e-07, 2.7676e-07,
        2.2082e-07]) eigenvals: tensor([4.6428e+01, 4.8674e+01, 5.4553e+01, 5.6774e+01, 8.2269e+01, 1.1125e+02,
        1.7500e+02, 2.9482e+02, 4.0254e+02, 1.0081e+03, 1.0190e+03, 2.1786e+03,
        2.7351e+03, 3.2458e+03, 3.5356e+03, 8.6508e+04, 3.0837e+06, 3.6132e+06,
Epoch: 1, Loss: 0.0703:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 294/1209 [14:16<2:39:08, 10.44s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0429:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 298/1209 [14:18<44:35,  2.94s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 1.0976:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 302/1209 [14:21<16:39,  1.10s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0175:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 306/1209 [14:23<09:54,  1.52it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.4816:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 310/1209 [14:25<08:18,  1.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.5193:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 314/1209 [14:27<07:59,  1.87it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.5738:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 318/1209 [14:29<07:42,  1.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0217:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 322/1209 [14:31<07:35,  1.95it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0265:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 325/1209 [14:32<07:37,  1.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0740:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 329/1209 [14:35<07:39,  1.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.5577:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 333/1209 [14:37<07:34,  1.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0347:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 337/1209 [14:39<07:31,  1.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0586:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                       | 341/1209 [14:41<07:26,  1.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 1.6527:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 345/1209 [14:43<07:27,  1.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.1414:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 347/1209 [14:44<07:25,  1.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.1414:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 347/1209 [14:44<07:25,  1.94it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
lambda_max: 16032695.0 lrs: tensor([1.1799e-02, 1.0717e-02, 9.4245e-03, 8.0050e-03, 7.7387e-03, 6.6653e-03,
        5.5286e-03, 4.3368e-03, 3.4407e-03, 1.9013e-03, 1.8576e-03, 1.5791e-03,
        1.0765e-03, 1.0618e-03, 4.1013e-04, 1.7965e-04, 2.4202e-05, 2.9566e-06,
        6.2373e-08]) eigenvals: tensor([8.4751e+01, 9.3314e+01, 1.0611e+02, 1.2492e+02, 1.2922e+02, 1.5003e+02,
        1.8088e+02, 2.3059e+02, 2.9064e+02, 5.2595e+02, 5.3833e+02, 6.3325e+02,
        9.2893e+02, 9.4181e+02, 2.4382e+03, 5.5664e+03, 4.1318e+04, 3.3823e+05,
Epoch: 1, Loss: 0.0752:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 351/1209 [17:01<3:26:00, 14.41s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.1548:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 355/1209 [17:03<54:42,  3.84s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.3174:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 359/1209 [17:05<18:30,  1.31s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.1100:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 363/1209 [17:07<09:52,  1.43it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0960:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 367/1209 [17:09<07:56,  1.77it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0399:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 371/1209 [17:11<07:21,  1.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0826:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 375/1209 [17:13<07:07,  1.95it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.5713:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 379/1209 [17:15<07:02,  1.96it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0345:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 383/1209 [17:17<07:00,  1.97it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.1518:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 386/1209 [17:19<07:00,  1.96it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.4217:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 390/1209 [17:21<06:57,  1.96it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0717:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 394/1209 [17:23<06:52,  1.97it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.5253:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                     | 398/1209 [17:25<06:55,  1.95it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.1433:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 402/1209 [17:27<07:02,  1.91it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.4030:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 405/1209 [17:28<06:56,  1.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0733:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 408/1209 [19:43<4:28:34, 20.12s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0733:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 408/1209 [19:43<4:28:34, 20.12s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
lambda_max: 4364740.5 lrs: tensor([3.3530e-03, 2.5726e-03, 1.9409e-03, 1.8268e-03, 1.4451e-03, 1.2034e-03,
        1.0562e-03, 7.4431e-04, 5.3531e-04, 5.1250e-04, 2.6625e-04, 2.5715e-04,
        1.9621e-04, 1.2966e-04, 7.1575e-05, 1.8713e-05, 1.4763e-05, 5.0775e-07,
        2.2911e-07]) eigenvals: tensor([2.9824e+02, 3.8871e+02, 5.1522e+02, 5.4740e+02, 6.9201e+02, 8.3099e+02,
        9.4680e+02, 1.3435e+03, 1.8681e+03, 1.9512e+03, 3.7559e+03, 3.8888e+03,
        5.0967e+03, 7.7126e+03, 1.3971e+04, 5.3439e+04, 6.7737e+04, 1.9695e+06,
Epoch: 1, Loss: 0.1070:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 411/1209 [19:45<1:36:21,  7.25s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0798:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                     | 415/1209 [19:47<28:21,  2.14s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.2612:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 419/1209 [19:49<12:10,  1.08it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0669:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 423/1209 [19:51<08:04,  1.62it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 1.3024:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 427/1209 [19:53<07:08,  1.82it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0485:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 430/1209 [19:55<06:55,  1.87it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0260:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 434/1209 [19:57<06:49,  1.89it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0406:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 438/1209 [19:59<06:45,  1.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0522:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                    | 443/1209 [20:02<06:38,  1.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0396:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                    | 447/1209 [20:04<06:38,  1.91it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.3123:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 451/1209 [20:06<06:38,  1.90it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0176:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 455/1209 [20:08<06:34,  1.91it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.3919:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 458/1209 [20:10<06:31,  1.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0191:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 462/1209 [20:12<06:35,  1.89it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0208:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 463/1209 [20:12<06:36,  1.88it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0208:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                   | 463/1209 [20:12<06:36,  1.88it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
lambda_max: 209046.140625 lrs: tensor([5.7920e-04, 3.6153e-04, 3.5571e-04, 2.3671e-04, 1.7825e-04, 1.4529e-04,
        1.3605e-04, 9.2221e-05, 8.3769e-05, 5.7901e-05, 5.4649e-05, 3.4037e-05,
        2.0267e-05, 1.2088e-05, 1.0001e-05, 8.4044e-06, 7.1518e-06, 4.8206e-06,
        4.7836e-06]) eigenvals: tensor([  1726.5267,   2766.0525,   2811.2441,   4224.5850,   5610.0732,
          6882.5786,   7350.2422,  10843.4785,  11937.6318,  17270.7793,
         18298.6152,  29379.8730,  49341.2305,  82729.4141,  99985.2266,
Epoch: 1, Loss: 0.0351:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                  | 465/1209 [22:28<5:56:49, 28.78s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.2646:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 469/1209 [22:30<1:30:03,  7.30s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.1893:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 473/1209 [22:32<26:15,  2.14s/it][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.6337:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 477/1209 [22:34<11:14,  1.09it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0493:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 481/1209 [22:36<07:21,  1.65it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0253:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 485/1209 [22:38<06:26,  1.88it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0456:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 489/1209 [22:40<06:15,  1.92it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.2379:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 492/1209 [22:42<06:37,  1.80it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0311:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 496/1209 [22:44<06:09,  1.93it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0310:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [22:45<06:01,  1.96it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0310:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [22:45<06:01,  1.96it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Epoch: 1, Loss: 0.0310:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 499/1209 [22:45<06:01,  1.96it/s][34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
Validation at Global Step: 500, Validation Loss: 2.6639: 100%|â–ˆ| 121/121 [00:03<00:00, 33.29it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
[33m[W 2024-05-11 18:52:46,190][39m Trial 61 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 33.29it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
[33m[W 2024-05-11 18:52:46,190][39m Trial 61 failed with value None.%|â–ˆ| 121/121 [00:03<00:00, 33.29it/s[34m[1mwandb[39m[22m: [33mWARNING[39m (User provided step: 250 is less than current step: 500. Dropping entry: {'LOSS/Train': 0.0624469555914402, 'F1_Macro/Train': 1.0, 'ACCURACY/Train': 1.0, 'PRECISION/Train': 1.0, 'RECALL/Train': 1.0, 'MAE/Train': 0.0, 'MCC/Train': 1.0, '_timestamp': 1715452885.684451}).715452099.3492355}).73.7074797}).
An exception occurred:
Returning None...