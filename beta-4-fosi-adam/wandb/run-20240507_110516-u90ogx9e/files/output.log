
Returned ESE function. Lanczos order (m) is 4 .
  0%|                                                                                                                                                 | 0/4 [00:00<?, ?it/s][38mic| logits: tensor([[0.1377, 0.2204],
[38m                    [0.0981, 0.1337],
[38m                    [0.1383, 0.1109]], grad_fn=<AddmmBackward0>)
[38mic| metrics: {'accuracy': 0.6666666666666666,
[38m              'f1': 0.8,
[38m              'loss': 0.6783782839775085,
[38m              'mae': 0.3333333333333333,
[38m              'precision': 1.0,
[38m              'recall': 0.6666666666666666}
Epoch: 1, Loss: 0.6784:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                    | 1/4 [00:08<00:25,  8.48s/it][38mic| logits: tensor([[-0.0041,  0.2733],
[38m                    [ 0.0515,  0.2201],
[38m                    [ 0.0371,  0.1713]], grad_fn=<AddmmBackward0>)
[38mic| metrics: {'accuracy': 0.6666666666666666,
[38m              'f1': 0.8,
[38m              'loss': 0.6463072896003723,
[38m              'mae': 0.3333333333333333,
[38m              'precision': 0.6666666666666666,
[38m              'recall': 1.0}
                                                                                                                                                                            [38mic| logits: tensor([[-0.0399,  0.2292],
[38m                    [-0.0017,  0.4324],[39m                                                                                                               | 0/4 [00:00<?, ?it/s]
[38m                    [-0.0878,  0.2735]])
  0%|                                                                                                                                                 | 0/4 [00:00<?, ?it/s]
Epoch: 1, Loss: 0.6784:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                    | 1/4 [00:17<00:53, 17.70s/it]
Traceback (most recent call last):
  File "/Users/pavlospoulos/Documents/nlp-optimizers/nlp-optimizers-aueb/beta-4-fosi-adam/main.py", line 107, in <module>
    trainer.train_val_test()
  File "/Users/pavlospoulos/Documents/nlp-optimizers/nlp-optimizers-aueb/beta-4-fosi-adam/trainer.py", line 79, in train_val_test
    total_val_loss = self.evaluate(val_loader=self.val_loader)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pavlospoulos/Documents/nlp-optimizers/nlp-optimizers-aueb/beta-4-fosi-adam/trainer.py", line 246, in evaluate
    progress_bar.set_description(f"Validation at Global Step: {self.global_step}, Validation Loss: {loss.item():.4f}")
                                                               ^^^^^^^^^^^^^^^^
AttributeError: 'CustomTrainer' object has no attribute 'global_step'