
Returned ESE function. Lanczos order (m) is 28 .




























Epoch: 1, Loss: 0.9222:   9%|███████████████▏                                                                                                                                                   | 187/1999 [01:24<4:27:36,  8.86s/it]































Epoch: 1, Loss: 0.5871:  19%|██████████████████████████████▊                                                                                                                                      | 373/1999 [02:25<08:52,  3.05it/s]





















Epoch: 1, Loss: 0.3585:  25%|█████████████████████████████████████████▏                                                                                                                           | 499/1999 [03:31<07:32,  3.31it/s]


Validation at Global Step: 500, Validation Loss: 0.6429:  98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎  | 196/200 [00:03<00:00, 52.39it/s]
Found Better model,
Saving model checkpoint at ./model_checkpoint.










Epoch: 1, Loss: 1.0429:  28%|██████████████████████████████████████████████▏                                                                                                                      | 560/1999 [04:03<07:39,  3.13it/s]
































Epoch: 1, Loss: 0.5867:  37%|████████████████████████████████████████████████████████████▉                                                                                                      | 748/1999 [05:58<2:50:43,  8.19s/it]





























Epoch: 1, Loss: 1.2327:  47%|█████████████████████████████████████████████████████████████████████████████                                                                                        | 934/1999 [06:54<05:14,  3.39it/s]












Epoch: 1, Loss: 0.2554:  50%|██████████████████████████████████████████████████████████████████████████████████▍                                                                                  | 999/1999 [07:43<05:34,  2.99it/s]



Epoch: 1, Loss: 0.5404:  50%|██████████████████████████████████████████████████████████████████████████████████                                                                                  | 1001/1999 [07:55<43:23,  2.61s/it]





















Epoch: 1, Loss: 0.8269:  56%|███████████████████████████████████████████████████████████████████████████████████████████▉                                                                        | 1121/1999 [08:35<04:54,  2.98it/s]





























Epoch: 1, Loss: 0.5651:  65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                        | 1308/1999 [09:59<03:31,  3.27it/s]




























Epoch: 1, Loss: 0.8392:  75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                         | 1495/1999 [11:19<02:24,  3.48it/s]


Epoch: 1, Loss: 1.0296:  75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                         | 1499/1999 [11:49<27:11,  3.26s/it]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(


Epoch: 1, Loss: 0.3537:  75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                         | 1500/1999 [12:01<47:48,  5.75s/it]































Epoch: 1, Loss: 0.5714:  84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                          | 1682/1999 [13:01<01:45,  3.01it/s]





























Epoch: 1, Loss: 0.7997:  94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌          | 1872/1999 [14:51<09:22,  4.43s/it]























Epoch: 1, Loss: 0.3701: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1999/1999 [15:38<00:00,  2.13it/s]
  0%|                                                                                                                                                                                                       | 0/1999 [00:00<?, ?it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(



Validation at Global Step: 2000, Validation Loss: 0.3559:  98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████  | 197/200 [00:03<00:00, 52.92it/s]
Found Better model,
Saving model checkpoint at ./model_checkpoint.











Epoch: 2, Loss: 0.5834:   3%|████▋                                                                                                                                                                 | 57/1999 [00:58<11:44,  2.76it/s]































Epoch: 2, Loss: 0.5712:  12%|████████████████████▏                                                                                                                                                | 244/1999 [02:27<09:13,  3.17it/s]






























Epoch: 2, Loss: 0.5581:  22%|███████████████████████████████████▍                                                                                                                               | 435/1999 [04:22<1:24:13,  3.23s/it]











Epoch: 2, Loss: 1.0127:  25%|█████████████████████████████████████████▎                                                                                                                           | 500/1999 [04:42<07:54,  3.16it/s]



Epoch: 2, Loss: 0.5647:  25%|████████████████████████████████████████▊                                                                                                                          | 501/1999 [04:54<1:29:57,  3.60s/it]




















Epoch: 2, Loss: 0.4747:  31%|██████████████████████████████████████████████████▍                                                                                                                | 619/1999 [05:58<3:10:18,  8.27s/it]



























Epoch: 2, Loss: 0.5575:  40%|██████████████████████████████████████████████████████████████████▍                                                                                                  | 805/1999 [06:51<05:40,  3.50it/s]




























Epoch: 2, Loss: 0.9422:  50%|█████████████████████████████████████████████████████████████████████████████████▏                                                                                 | 995/1999 [08:44<1:17:32,  4.63s/it]

Epoch: 2, Loss: 0.7605:  50%|██████████████████████████████████████████████████████████████████████████████████                                                                                  | 1000/1999 [08:45<16:45,  1.01s/it]


Validation at Global Step: 3000, Validation Loss: 0.8786:  98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████  | 197/200 [00:03<00:00, 51.90it/s]


























Epoch: 2, Loss: 0.5791:  59%|███████████████████████████████████████████████████████████████████████████████████████████████▊                                                                  | 1182/1999 [10:16<1:03:08,  4.64s/it]





























Epoch: 2, Loss: 0.7797:  68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                    | 1366/1999 [11:13<03:14,  3.25it/s]






















Epoch: 2, Loss: 0.5592:  75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                         | 1500/1999 [12:25<02:31,  3.29it/s]


Validation at Global Step: 3500, Validation Loss: 0.3609: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 199/200 [00:04<00:00, 51.06it/s]
Found Better model,
Saving model checkpoint at ./model_checkpoint.








Epoch: 2, Loss: 0.7840:  78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                    | 1553/1999 [13:18<02:07,  3.49it/s]



























Epoch: 2, Loss: 0.7757:  87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                     | 1740/1999 [14:39<01:14,  3.47it/s]



























Epoch: 2, Loss: 0.7747:  96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████      | 1927/1999 [16:03<00:20,  3.58it/s]










Epoch: 2, Loss: 0.8236: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1999/1999 [16:51<00:00,  1.98it/s]
Epoch: 3, Loss: 0.5910:   0%|                                                                                                            | 1/1999 [00:00<09:02,  3.68it/s]


Validation at Global Step: 4000, Validation Loss: 0.6419:  98%|███████████████████████████████████████████████████████████████████████▏ | 195/200 [00:03<00:00, 50.99it/s]
















Epoch: 3, Loss: 0.5988:   6%|██████                                                                                                    | 115/1999 [00:42<08:34,  3.66it/s]



























Epoch: 3, Loss: 0.9861:  15%|████████████████                                                                                          | 302/1999 [02:05<08:02,  3.52it/s]



























Epoch: 3, Loss: 0.7542:  24%|█████████████████████████▉                                                                                | 489/1999 [03:29<07:08,  3.52it/s]



Epoch: 3, Loss: 0.5470:  25%|██████████████████████████▌                                                                               | 501/1999 [04:02<11:16,  2.21it/s]



Validation at Global Step: 4500, Validation Loss: 0.6442:  98%|███████████████████████████████████████████████████████████████████████▌ | 196/200 [00:03<00:00, 50.96it/s]

























Epoch: 3, Loss: 0.7630:  34%|███████████████████████████████████▊                                                                      | 676/1999 [05:01<06:00,  3.67it/s]




























Epoch: 3, Loss: 0.7880:  43%|█████████████████████████████████████████████                                                           | 865/1999 [06:54<2:01:28,  6.43s/it]



















Epoch: 3, Loss: 0.8041:  50%|████████████████████████████████████████████████████▌                                                    | 1001/1999 [07:30<04:25,  3.76it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(



Epoch: 3, Loss: 0.7762:  50%|████████████████████████████████████████████████████▋                                                    | 1004/1999 [07:42<30:13,  1.82s/it]








Epoch: 3, Loss: 0.5748:  53%|██████████████████████████████████████████████████████▏                                                | 1052/1999 [08:24<1:40:27,  6.37s/it]




























Epoch: 3, Loss: 0.4013:  62%|███████████████████████████████████████████████████████████████▊                                       | 1238/1999 [09:48<1:57:07,  9.23s/it]



























Epoch: 3, Loss: 0.5911:  71%|██████████████████████████████████████████████████████████████████████████▊                              | 1424/1999 [10:41<02:42,  3.55it/s]












Epoch: 3, Loss: 0.5582:  75%|██████████████████████████████████████████████████████████████████████████████▊                          | 1501/1999 [11:32<02:32,  3.27it/s]


Validation at Global Step: 5500, Validation Loss: 0.3452:  98%|███████████████████████████████████████████████████████████████████████▏ | 195/200 [00:03<00:00, 50.52it/s]
Found Better model,

Epoch: 3, Loss: 0.7747:  75%|█████████████████████████████████████████████████████████████████████████████▍                         | 1502/1999 [12:10<1:35:48, 11.57s/it]
















Epoch: 3, Loss: 0.5942:  81%|████████████████████████████████████████████████████████████████████████████████████▌                    | 1611/1999 [12:41<01:48,  3.57it/s]




























Epoch: 3, Loss: 0.5742:  90%|██████████████████████████████████████████████████████████████████████████████████████████████▋          | 1802/1999 [14:34<10:46,  3.28s/it]




























Epoch: 3, Loss: 0.3387:  99%|████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 1986/1999 [15:57<01:54,  8.84s/it]

Epoch: 3, Loss: 0.1978: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 1999/1999 [16:01<00:00,  2.08it/s]

Epoch: 4, Loss: 0.9826:   0%|                                                                                                            | 2/1999 [00:00<10:49,  3.07it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(



Epoch: 4, Loss: 0.1825:   0%|▏                                                                                                         | 3/1999 [00:11<2:57:39,  5.34s/it]

























Epoch: 4, Loss: 0.7868:   9%|█████████▏                                                                                                | 173/1999 [01:00<09:30,  3.20it/s]



























Epoch: 4, Loss: 0.7866:  18%|██████████████████▊                                                                                     | 361/1999 [02:46<3:50:22,  8.44s/it]





















Epoch: 4, Loss: 0.7903:  25%|██████████████████████████▌                                                                               | 502/1999 [03:27<07:39,  3.26it/s]


Validation at Global Step: 6500, Validation Loss: 0.3720:  99%|████████████████████████████████████████████████████████████████████████▎| 198/200 [00:03<00:00, 51.63it/s]








Epoch: 4, Loss: 0.5676:  28%|████████████████████████████▌                                                                           | 550/1999 [04:20<1:46:32,  4.41s/it]


























Epoch: 4, Loss: 0.5580:  37%|██████████████████████████████████████▉                                                                   | 734/1999 [05:12<05:56,  3.54it/s]


























Epoch: 4, Loss: 0.7527:  46%|████████████████████████████████████████████████▊                                                         | 921/1999 [06:32<04:54,  3.66it/s]












Epoch: 4, Loss: 1.0397:  50%|████████████████████████████████████████████████████▋                                                    | 1002/1999 [07:23<04:42,  3.53it/s]



Epoch: 4, Loss: 0.9750:  50%|████████████████████████████████████████████████████▉                                                    | 1008/1999 [07:36<14:03,  1.17it/s]















Epoch: 4, Loss: 0.3644:  55%|██████████████████████████████████████████████████████████▏                                              | 1108/1999 [08:04<04:06,  3.61it/s]



























Epoch: 4, Loss: 0.7630:  65%|████████████████████████████████████████████████████████████████████▏                                    | 1299/1999 [09:52<36:37,  3.14s/it]




























Epoch: 4, Loss: 0.6085:  74%|██████████████████████████████████████████████████████████████████████████████                           | 1486/1999 [11:15<26:54,  3.15s/it]



Epoch: 4, Loss: 0.3756:  75%|██████████████████████████████████████████████████████████████████████████████▉                          | 1502/1999 [11:19<02:23,  3.46it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(


Validation at Global Step: 7500, Validation Loss: 0.6363:  98%|███████████████████████████████████████████████████████████████████████▏ | 195/200 [00:03<00:00, 52.76it/s]
Found Better model,

Epoch: 4, Loss: 0.9400:  75%|███████████████████████████████████████████████████████████████████████████████▏                         | 1508/1999 [11:58<17:48,  2.18s/it]
























Epoch: 4, Loss: 0.6133:  84%|███████████████████████████████████████████████████████████████████████████████████████▋                 | 1670/1999 [13:13<48:26,  8.84s/it]


























Epoch: 4, Loss: 0.5688:  93%|█████████████████████████████████████████████████████████████████████████████████████████████████▍       | 1856/1999 [14:04<00:39,  3.60it/s]




















Epoch: 4, Loss: 0.6265: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 1999/1999 [15:13<00:00,  2.19it/s]
Epoch: 5, Loss: 0.5659:   0%|▏                                                                                                           | 3/1999 [00:00<09:40,  3.44it/s]



Epoch: 5, Loss: 0.5769:   0%|▎                                                                                                         | 5/1999 [00:12<1:38:15,  2.96s/it]






Epoch: 5, Loss: 0.4123:   2%|██▎                                                                                                        | 44/1999 [00:22<09:05,  3.58it/s]




























Epoch: 5, Loss: 0.3635:  12%|████████████▏                                                                                             | 231/1999 [01:44<08:14,  3.57it/s]




























Epoch: 5, Loss: 0.5982:  21%|██████████████████████▏                                                                                   | 418/1999 [03:08<07:28,  3.52it/s]














Epoch: 5, Loss: 0.2902:  25%|██████████████████████████▋                                                                               | 503/1999 [04:03<07:50,  3.18it/s]


Validation at Global Step: 8500, Validation Loss: 0.6614:  98%|███████████████████████████████████████████████████████████████████████▉ | 197/200 [00:03<00:00, 51.97it/s]
















Epoch: 5, Loss: 0.2997:  30%|████████████████████████████████                                                                          | 605/1999 [04:46<07:12,  3.23it/s]




























Epoch: 5, Loss: 0.3498:  40%|█████████████████████████████████████████▉                                                                | 792/1999 [06:09<05:47,  3.48it/s]




























Epoch: 5, Loss: 0.3730:  49%|███████████████████████████████████████████████████▉                                                      | 979/1999 [07:31<04:47,  3.55it/s]




Epoch: 5, Loss: 0.8659:  50%|████████████████████████████████████████████████████▋                                                    | 1003/1999 [08:06<04:50,  3.43it/s]


Validation at Global Step: 9000, Validation Loss: 0.6432:  99%|████████████████████████████████████████████████████████████████████████▎| 198/200 [00:03<00:00, 52.60it/s]
























Epoch: 5, Loss: 0.7423:  58%|█████████████████████████████████████████████████████████████▏                                           | 1166/1999 [09:03<03:53,  3.56it/s]




























Epoch: 5, Loss: 0.8861:  68%|███████████████████████████████████████████████████████████████████████                                  | 1353/1999 [10:26<03:04,  3.51it/s]

























Epoch: 5, Loss: 0.7191:  75%|██████████████████████████████████████████████████████████████████████████████▉                          | 1503/1999 [11:41<02:41,  3.06it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

Validation at Global Step: 9500, Validation Loss: 0.6739: 100%|█████████████████████████████████████████████████████████████████████████| 200/200 [00:03<00:00, 51.61it/s]







Epoch: 5, Loss: 0.5885:  77%|████████████████████████████████████████████████████████████████████████████████▉                        | 1540/1999 [12:04<02:24,  3.17it/s]




























Epoch: 5, Loss: 0.5734:  86%|██████████████████████████████████████████████████████████████████████████████████████████▋              | 1727/1999 [13:25<01:20,  3.39it/s]




























Epoch: 5, Loss: 0.7494:  96%|████████████████████████████████████████████████████████████████████████████████████████████████████▌    | 1914/1999 [14:48<00:24,  3.52it/s]












Epoch: 5, Loss: 0.6386: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 1999/1999 [15:41<00:00,  2.12it/s]

Epoch: 6, Loss: 0.3307:   0%|▏                                                                                                           | 4/1999 [00:01<09:36,  3.46it/s]


Validation at Global Step: 10000, Validation Loss: 0.6571:  98%|██████████████████████████████████████████████████████████████████████▉ | 197/200 [00:04<00:00, 49.55it/s]















Epoch: 6, Loss: 0.7903:   5%|█████▍                                                                                                    | 102/1999 [00:40<09:28,  3.34it/s]





























Epoch: 6, Loss: 0.7903:  14%|███████████████▎                                                                                          | 289/1999 [02:05<08:24,  3.39it/s]





























Epoch: 6, Loss: 0.5703:  24%|█████████████████████████▏                                                                                | 476/1999 [03:31<07:39,  3.31it/s]





Epoch: 6, Loss: 0.3738:  25%|██████████████████████████▋                                                                               | 504/1999 [04:07<07:19,  3.40it/s]



Epoch: 6, Loss: 0.7533:  25%|██████████████████████████▉                                                                               | 507/1999 [04:18<45:45,  1.84s/it]
























Epoch: 6, Loss: 0.4526:  33%|███████████████████████████████████▏                                                                      | 663/1999 [05:04<06:31,  3.41it/s]




























Epoch: 6, Loss: 0.3911:  43%|████████████████████████████████████████████▎                                                           | 851/1999 [06:52<2:41:28,  8.44s/it]























Epoch: 6, Loss: 0.3683:  50%|████████████████████████████████████████████████████▋                                                    | 1004/1999 [07:36<04:57,  3.34it/s]


Validation at Global Step: 11000, Validation Loss: 1.2452:  98%|██████████████████████████████████████████████████████████████████████▌ | 196/200 [00:03<00:00, 49.17it/s]






Epoch: 6, Loss: 0.3428:  52%|█████████████████████████████████████████████████████▌                                                 | 1040/1999 [08:24<1:08:33,  4.29s/it]




























Epoch: 6, Loss: 0.7838:  61%|████████████████████████████████████████████████████████████████▌                                        | 1228/1999 [09:46<40:46,  3.17s/it]




























Epoch: 6, Loss: 0.3259:  71%|██████████████████████████████████████████████████████████████████████████                               | 1411/1999 [10:42<03:06,  3.15it/s]














Epoch: 6, Loss: 0.3491:  75%|██████████████████████████████████████████████████████████████████████████████▉                          | 1504/1999 [11:36<02:26,  3.38it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))


Validation at Global Step: 11500, Validation Loss: 0.3513: 100%|████████████████████████████████████████████████████████████████████████| 200/200 [00:03<00:00, 51.74it/s]















Epoch: 6, Loss: 0.7891:  80%|████████████████████████████████████████████████████████████████████████████████████                     | 1600/1999 [12:41<37:45,  5.68s/it]


























Epoch: 6, Loss: 0.5634:  89%|█████████████████████████████████████████████████████████████████████████████████████████████▊           | 1785/1999 [13:31<00:57,  3.74it/s]



























Epoch: 6, Loss: 0.5598:  99%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 1972/1999 [14:51<00:07,  3.56it/s]



Epoch: 6, Loss: 0.9664: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 1999/1999 [15:27<00:00,  2.16it/s]

Epoch: 7, Loss: 0.5625:   0%|▎                                                                                                           | 5/1999 [00:01<09:07,  3.64it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(



Epoch: 7, Loss: 0.7614:   0%|▎                                                                                                         | 7/1999 [00:12<1:29:03,  2.68s/it]






















Epoch: 7, Loss: 0.5639:   8%|████████▍                                                                                                 | 160/1999 [00:55<08:29,  3.61it/s]





























Epoch: 7, Loss: 0.9745:  18%|██████████████████▏                                                                                     | 350/1999 [02:44<1:56:37,  4.24s/it]























Epoch: 7, Loss: 0.6991:  25%|██████████████████████████▊                                                                               | 505/1999 [03:28<07:44,  3.21it/s]


Epoch: 7, Loss: 0.6662:  25%|██████████████████████████▉                                                                               | 508/1999 [03:40<47:46,  1.92s/it]





Epoch: 7, Loss: 0.3545:  27%|███████████████████████████▊                                                                            | 535/1999 [04:16<3:31:01,  8.65s/it]




























Epoch: 7, Loss: 0.5682:  36%|██████████████████████████████████████▏                                                                   | 721/1999 [05:12<06:21,  3.35it/s]































Epoch: 7, Loss: 0.5638:  45%|███████████████████████████████████████████████▎                                                        | 909/1999 [07:09<2:38:10,  8.71s/it]
















Epoch: 7, Loss: 0.5768:  50%|████████████████████████████████████████████████████▊                                                    | 1005/1999 [07:40<05:16,  3.14it/s]/home/pavlospoulos/miniconda3/envs/pavlosEnv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(



Epoch: 7, Loss: 0.5391:  50%|████████████████████████████████████████████████████▊                                                    | 1006/1999 [07:50<56:42,  3.43s/it]















Epoch: 7, Loss: 0.5698:  55%|█████████████████████████████████████████████████████████▌                                               | 1095/1999 [08:19<04:52,  3.09it/s]





























Epoch: 7, Loss: 0.3622:  64%|██████████████████████████████████████████████████████████████████                                     | 1283/1999 [10:12<1:43:26,  8.67s/it][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([1, 1, 0, 0])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
Epoch: 7, Loss: 0.3622:  64%|███████████████████████████████████████████████████████████████████▍                                     | 1283/1999 [10:12<05:42,  2.09it/s]
lambda_max: nan lrs: tensor([nan, nan, nan, nan, nan, nan, nan]) eigenvals: tensor([nan, nan, nan, nan, nan, nan, nan])
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
Removed the checkpoint file at ./model_checkpoint
Returned ESE function. Lanczos order (m) is 48 .
[33m[W 2024-05-09 12:31:36,238][39m Trial 7 failed with parameters: {'learning_rate': 4.009341537923728e-05, 'k_approx': 7, 'num_of_fosi_iterations': 187} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:36,238][39m Trial 7 failed with value None.
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([0, 1, 1, 0])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:36,557][39m Trial 8 failed with parameters: {'learning_rate': 9.100691839024809e-05, 'k_approx': 12, 'num_of_fosi_iterations': 198} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:36,557][39m Trial 8 failed with value None.
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([1, 1, 1, 1])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:36,971][39m Trial 9 failed with parameters: {'learning_rate': 4.701975120083602e-05, 'k_approx': 16, 'num_of_fosi_iterations': 130} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:36,971][39m Trial 9 failed with value None.
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([1, 1, 1, 1])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:37,130][39m Trial 10 failed with parameters: {'learning_rate': 5.186690769262611e-05, 'k_approx': 4, 'num_of_fosi_iterations': 142} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:37,130][39m Trial 10 failed with value None.
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([1, 1, 1, 0])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:37,351][39m Trial 11 failed with parameters: {'learning_rate': 8.554350397790668e-05, 'k_approx': 15, 'num_of_fosi_iterations': 179} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:37,351][39m Trial 11 failed with value None.
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([0, 1, 1, 1])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:37,688][39m Trial 12 failed with parameters: {'learning_rate': 5.232748567152949e-05, 'k_approx': 12, 'num_of_fosi_iterations': 132} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:37,688][39m Trial 12 failed with value None.
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([0, 0, 1, 1])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:37,831][39m Trial 13 failed with parameters: {'learning_rate': 5.2072339033521986e-05, 'k_approx': 0, 'num_of_fosi_iterations': 109} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:37,831][39m Trial 13 failed with value None.
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([0, 1, 1, 0])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:38,063][39m Trial 14 failed with parameters: {'learning_rate': 3.276267583559057e-05, 'k_approx': 15, 'num_of_fosi_iterations': 104} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:38,064][39m Trial 14 failed with value None.
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
Returned ESE function. Lanczos order (m) is 64 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
Returned ESE function. Lanczos order (m) is 16 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
Returned ESE function. Lanczos order (m) is 60 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
Returned ESE function. Lanczos order (m) is 48 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
Returned ESE function. Lanczos order (m) is 0 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
Returned ESE function. Lanczos order (m) is 60 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
Returned ESE function. Lanczos order (m) is 64 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([1, 1, 1, 1])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:38,467][39m Trial 15 failed with parameters: {'learning_rate': 4.6262752760179585e-06, 'k_approx': 16, 'num_of_fosi_iterations': 140} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:38,467][39m Trial 15 failed with value None.
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([1, 1, 0, 1])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:38,703][39m Trial 16 failed with parameters: {'learning_rate': 5.2306524727425455e-05, 'k_approx': 19, 'num_of_fosi_iterations': 73} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:38,703][39m Trial 16 failed with value None.
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([1, 0, 1, 1])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:38,880][39m Trial 17 failed with parameters: {'learning_rate': 3.2285499147177936e-05, 'k_approx': 7, 'num_of_fosi_iterations': 196} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:38,880][39m Trial 17 failed with value None.
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([1, 1, 1, 0])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:39,107][39m Trial 18 failed with parameters: {'learning_rate': 6.89782395284962e-05, 'k_approx': 18, 'num_of_fosi_iterations': 90} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:39,108][39m Trial 18 failed with value None.
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([0, 1, 1, 1])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:39,260][39m Trial 19 failed with parameters: {'learning_rate': 7.43803689982312e-05, 'k_approx': 4, 'num_of_fosi_iterations': 192} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:39,260][39m Trial 19 failed with value None.
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([1, 0, 1, 0])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:39,526][39m Trial 20 failed with parameters: {'learning_rate': 5.847780646036734e-05, 'k_approx': 17, 'num_of_fosi_iterations': 57} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:39,526][39m Trial 20 failed with value None.
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([1, 1, 1, 1])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:39,902][39m Trial 21 failed with parameters: {'learning_rate': 9.722053050089443e-05, 'k_approx': 11, 'num_of_fosi_iterations': 183} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:39,902][39m Trial 21 failed with value None.
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([1, 1, 1, 0])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:40,099][39m Trial 22 failed with parameters: {'learning_rate': 4.7732922217196275e-05, 'k_approx': 3, 'num_of_fosi_iterations': 180} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:40,100][39m Trial 22 failed with value None.
Returned ESE function. Lanczos order (m) is 76 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
Returned ESE function. Lanczos order (m) is 28 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
Returned ESE function. Lanczos order (m) is 72 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
Returned ESE function. Lanczos order (m) is 16 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
Returned ESE function. Lanczos order (m) is 68 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
Returned ESE function. Lanczos order (m) is 44 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
Returned ESE function. Lanczos order (m) is 12 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
Returned ESE function. Lanczos order (m) is 64 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
Returned ESE function. Lanczos order (m) is 8 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([1, 1, 0, 1])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:40,337][39m Trial 23 failed with parameters: {'learning_rate': 3.7116086035702564e-05, 'k_approx': 16, 'num_of_fosi_iterations': 95} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:40,337][39m Trial 23 failed with value None.
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([1, 1, 1, 0])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:40,498][39m Trial 24 failed with parameters: {'learning_rate': 8.864505505986855e-05, 'k_approx': 2, 'num_of_fosi_iterations': 176} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:40,498][39m Trial 24 failed with value None.
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([1, 1, 1, 1])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:40,716][39m Trial 25 failed with parameters: {'learning_rate': 8.123646393974374e-06, 'k_approx': 15, 'num_of_fosi_iterations': 121} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:40,716][39m Trial 25 failed with value None.
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([1, 1, 1, 0])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:40,905][39m Trial 26 failed with parameters: {'learning_rate': 9.82801498260761e-05, 'k_approx': 6, 'num_of_fosi_iterations': 114} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:40,905][39m Trial 26 failed with value None.
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([1, 1, 1, 0])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:41,138][39m Trial 27 failed with parameters: {'learning_rate': 5.413326933498892e-05, 'k_approx': 18, 'num_of_fosi_iterations': 99} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:41,138][39m Trial 27 failed with value None.
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([1, 1, 1, 0])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:41,324][39m Trial 28 failed with parameters: {'learning_rate': 1.6761596295154527e-05, 'k_approx': 4, 'num_of_fosi_iterations': 96} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:41,325][39m Trial 28 failed with value None.
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([1, 1, 1, 0])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:41,503][39m Trial 29 failed with parameters: {'learning_rate': 1.91691650486955e-05, 'k_approx': 7, 'num_of_fosi_iterations': 143} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:41,503][39m Trial 29 failed with value None.
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([0, 0, 1, 1])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:41,739][39m Trial 30 failed with parameters: {'learning_rate': 8.829408742995052e-05, 'k_approx': 20, 'num_of_fosi_iterations': 104} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:41,739][39m Trial 30 failed with value None.
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s][38mic| logits: tensor([[nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan],
[38m                    [nan, nan]], grad_fn=<AddmmBackward0>)
[38mic| labels: tensor([0, 1, 0, 0])
[38mic| loss: tensor(nan, grad_fn=<NllLossBackward0>)
[38mic| type(loss): <class 'torch.Tensor'>
  0%|                                                                                                                                            | 0/1999 [00:00<?, ?it/s]
[33m[W 2024-05-09 12:31:41,906][39m Trial 31 failed with parameters: {'learning_rate': 6.096562695546209e-05, 'k_approx': 3, 'num_of_fosi_iterations': 162} because of the following error: The value None could not be cast to float..
[33m[W 2024-05-09 12:31:41,906][39m Trial 31 failed with value None.
Returned ESE function. Lanczos order (m) is 60 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
Returned ESE function. Lanczos order (m) is 24 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
Returned ESE function. Lanczos order (m) is 72 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
Returned ESE function. Lanczos order (m) is 16 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
Returned ESE function. Lanczos order (m) is 28 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
Returned ESE function. Lanczos order (m) is 80 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...
Returned ESE function. Lanczos order (m) is 12 .
**************************************************
Loss is NaN, retrying to calculate one more time...
**************************************************
**************************************************
Loss is still NaN, raising an error...
**************************************************
An exception occurred:
Loss is NaN
Returning None...